<?xml version="1.0" encoding="UTF-8"?>
<testsuite name="kafka.network.SocketServerTest" tests="49" skipped="0" failures="0" errors="0" timestamp="2020-01-15T02:21:23" hostname="localhost" time="19.874">
  <properties/>
  <testcase name="testGracefulClose" classname="kafka.network.SocketServerTest" time="0.061"/>
  <testcase name="testClientDisconnectionWithOutstandingReceivesProcessedUntilFailedSend" classname="kafka.network.SocketServerTest" time="0.202"/>
  <testcase name="testSendActionResponseWithThrottledChannelWhereThrottlingAlreadyDone" classname="kafka.network.SocketServerTest" time="0.055"/>
  <testcase name="controlThrowable" classname="kafka.network.SocketServerTest" time="0.46"/>
  <testcase name="testRequestMetricsAfterStop" classname="kafka.network.SocketServerTest" time="0.017"/>
  <testcase name="testConnectionIdReuse" classname="kafka.network.SocketServerTest" time="0.89"/>
  <testcase name="testClientInformationWithOldestApiVersionsRequest" classname="kafka.network.SocketServerTest" time="0.177"/>
  <testcase name="testSaslReauthenticationFailureNoKip152SaslAuthenticate" classname="kafka.network.SocketServerTest" time="0.141"/>
  <testcase name="testClientDisconnectionUpdatesRequestMetrics" classname="kafka.network.SocketServerTest" time="0.256"/>
  <testcase name="testProcessorMetricsTags" classname="kafka.network.SocketServerTest" time="0.021"/>
  <testcase name="remoteCloseWithBufferedReceivesFailedSend" classname="kafka.network.SocketServerTest" time="0.669"/>
  <testcase name="testMaxConnectionsPerIp" classname="kafka.network.SocketServerTest" time="0.16"/>
  <testcase name="testConnectionId" classname="kafka.network.SocketServerTest" time="0.018"/>
  <testcase name="remoteCloseSendFailure" classname="kafka.network.SocketServerTest" time="0.894"/>
  <testcase name="testBrokerSendAfterChannelClosedUpdatesRequestMetrics" classname="kafka.network.SocketServerTest" time="0.442"/>
  <testcase name="testNoOpAction" classname="kafka.network.SocketServerTest" time="0.021"/>
  <testcase name="simpleRequest" classname="kafka.network.SocketServerTest" time="0.013"/>
  <testcase name="testSendActionResponseWithThrottledChannelWhereThrottlingInProgress" classname="kafka.network.SocketServerTest" time="0.115"/>
  <testcase name="testIdleConnection" classname="kafka.network.SocketServerTest" time="1.192"/>
  <testcase name="remoteCloseWithoutBufferedReceives" classname="kafka.network.SocketServerTest" time="0.56"/>
  <testcase name="remoteCloseWithCompleteAndIncompleteBufferedReceives" classname="kafka.network.SocketServerTest" time="0.81"/>
  <testcase name="testZeroMaxConnectionsPerIp" classname="kafka.network.SocketServerTest" time="0.136"/>
  <testcase name="testClientInformationWithLatestApiVersionsRequest" classname="kafka.network.SocketServerTest" time="0.119"/>
  <testcase name="testMetricCollectionAfterShutdown" classname="kafka.network.SocketServerTest" time="0.024"/>
  <testcase name="testSessionPrincipal" classname="kafka.network.SocketServerTest" time="0.014"/>
  <testcase name="configureNewConnectionException" classname="kafka.network.SocketServerTest" time="0.339"/>
  <testcase name="testSaslReauthenticationFailureWithKip152SaslAuthenticate" classname="kafka.network.SocketServerTest" time="0.151"/>
  <testcase name="testMaxConnectionsPerIpOverrides" classname="kafka.network.SocketServerTest" time="0.031"/>
  <testcase name="testControlPlaneRequest" classname="kafka.network.SocketServerTest" time="0.032"/>
  <testcase name="processNewResponseException" classname="kafka.network.SocketServerTest" time="0.339"/>
  <testcase name="remoteCloseWithIncompleteBufferedReceive" classname="kafka.network.SocketServerTest" time="0.721"/>
  <testcase name="testStagedListenerStartup" classname="kafka.network.SocketServerTest" time="2.043"/>
  <testcase name="testConnectionRateLimit" classname="kafka.network.SocketServerTest" time="0.576"/>
  <testcase name="processCompletedSendException" classname="kafka.network.SocketServerTest" time="0.447"/>
  <testcase name="processDisconnectedException" classname="kafka.network.SocketServerTest" time="0.301"/>
  <testcase name="closingChannelWithBufferedReceives" classname="kafka.network.SocketServerTest" time="0.983"/>
  <testcase name="sendCancelledKeyException" classname="kafka.network.SocketServerTest" time="0.344"/>
  <testcase name="processCompletedReceiveException" classname="kafka.network.SocketServerTest" time="0.239"/>
  <testcase name="closingChannelSendFailure" classname="kafka.network.SocketServerTest" time="0.589"/>
  <testcase name="idleExpiryWithBufferedReceives" classname="kafka.network.SocketServerTest" time="1.673"/>
  <testcase name="testSocketsCloseOnShutdown" classname="kafka.network.SocketServerTest" time="0.221"/>
  <testcase name="testNoOpActionResponseWithThrottledChannelWhereThrottlingAlreadyDone" classname="kafka.network.SocketServerTest" time="0.117"/>
  <testcase name="pollException" classname="kafka.network.SocketServerTest" time="0.538"/>
  <testcase name="closingChannelWithBufferedReceivesFailedSend" classname="kafka.network.SocketServerTest" time="0.547"/>
  <testcase name="remoteCloseWithBufferedReceives" classname="kafka.network.SocketServerTest" time="0.764"/>
  <testcase name="closingChannelWithCompleteAndIncompleteBufferedReceives" classname="kafka.network.SocketServerTest" time="0.625"/>
  <testcase name="testSslSocketServer" classname="kafka.network.SocketServerTest" time="0.656"/>
  <testcase name="tooBigRequestIsRejected" classname="kafka.network.SocketServerTest" time="0.011"/>
  <testcase name="testNoOpActionResponseWithThrottledChannelWhereThrottlingInProgress" classname="kafka.network.SocketServerTest" time="0.116"/>
  <system-out><![CDATA[[2020-01-15 10:21:23,732] DEBUG Accepted connection from /127.0.0.1:59082 on /127.0.0.1:59081 and assigned it to processor 0, sendBufferSize [actual|requested]: [300000|300000] recvBufferSize [actual|requested]: [310308|300000] (kafka.network.Acceptor:62)
[2020-01-15 10:21:23,733] DEBUG Processor 0 listening to new connection from /127.0.0.1:59082 (kafka.network.Processor:62)
[2020-01-15 10:21:23,734] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:23,735] TRACE Not sending PRODUCE response to client  as it's not required. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:23,735] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response: from connection 127.0.0.1:59081-127.0.0.1:59082-0;totalTime:1.527,requestQueueTime:0.0,localTime:6.1085471026E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.893,sendTime:0.009,securityProtocol:PLAINTEXT,principal:User:ANONYMOUS,listener:PLAINTEXT,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:23,736] TRACE Socket server received empty response to send, registering for read: Response(type=NoOp, request=Request(processor=0, connectionId=127.0.0.1:59081-127.0.0.1:59082-0, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(PLAINTEXT), securityProtocol=PLAINTEXT, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22])) (kafka.network.Processor:54)
[2020-01-15 10:21:23,736] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:23,740] TRACE Not sending PRODUCE response to client  as it's not required. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:23,741] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response: from connection 127.0.0.1:59081-127.0.0.1:59082-0;totalTime:4.608,requestQueueTime:0.0,localTime:6.1085476448E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:1.245,sendTime:0.006,securityProtocol:PLAINTEXT,principal:User:ANONYMOUS,listener:PLAINTEXT,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:23,741] TRACE Socket server received empty response to send, registering for read: Response(type=NoOp, request=Request(processor=0, connectionId=127.0.0.1:59081-127.0.0.1:59082-0, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(PLAINTEXT), securityProtocol=PLAINTEXT, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22])) (kafka.network.Processor:54)
[2020-01-15 10:21:23,742] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:23,742] TRACE Not sending PRODUCE response to client  as it's not required. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:23,744] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response: from connection 127.0.0.1:59081-127.0.0.1:59082-0;totalTime:2.663,requestQueueTime:0.0,localTime:6.1085478911E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:2.174,sendTime:0.022,securityProtocol:PLAINTEXT,principal:User:ANONYMOUS,listener:PLAINTEXT,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:23,745] TRACE Socket server received empty response to send, registering for read: Response(type=NoOp, request=Request(processor=0, connectionId=127.0.0.1:59081-127.0.0.1:59082-0, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(PLAINTEXT), securityProtocol=PLAINTEXT, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22])) (kafka.network.Processor:54)
[2020-01-15 10:21:23,745] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:23,746] TRACE Not sending PRODUCE response to client  as it's not required. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:23,749] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response: from connection 127.0.0.1:59081-127.0.0.1:59082-0;totalTime:3.349,requestQueueTime:0.0,localTime:6.1085482648E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:2.698,sendTime:0.005,securityProtocol:PLAINTEXT,principal:User:ANONYMOUS,listener:PLAINTEXT,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:23,749] TRACE Socket server received empty response to send, registering for read: Response(type=NoOp, request=Request(processor=0, connectionId=127.0.0.1:59081-127.0.0.1:59082-0, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(PLAINTEXT), securityProtocol=PLAINTEXT, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22])) (kafka.network.Processor:54)
[2020-01-15 10:21:23,749] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:23,749] TRACE Not sending PRODUCE response to client  as it's not required. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:23,750] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response: from connection 127.0.0.1:59081-127.0.0.1:59082-0;totalTime:0.669,requestQueueTime:0.0,localTime:6.1085485851E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.489,sendTime:0.008,securityProtocol:PLAINTEXT,principal:User:ANONYMOUS,listener:PLAINTEXT,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:23,750] TRACE Socket server received empty response to send, registering for read: Response(type=NoOp, request=Request(processor=0, connectionId=127.0.0.1:59081-127.0.0.1:59082-0, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(PLAINTEXT), securityProtocol=PLAINTEXT, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22])) (kafka.network.Processor:54)
[2020-01-15 10:21:23,750] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:23,750] TRACE Not sending PRODUCE response to client  as it's not required. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:23,751] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response: from connection 127.0.0.1:59081-127.0.0.1:59082-0;totalTime:0.683,requestQueueTime:0.0,localTime:6.1085486972E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.468,sendTime:0.004,securityProtocol:PLAINTEXT,principal:User:ANONYMOUS,listener:PLAINTEXT,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:23,751] TRACE Socket server received empty response to send, registering for read: Response(type=NoOp, request=Request(processor=0, connectionId=127.0.0.1:59081-127.0.0.1:59082-0, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(PLAINTEXT), securityProtocol=PLAINTEXT, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22])) (kafka.network.Processor:54)
[2020-01-15 10:21:23,751] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:23,751] TRACE Not sending PRODUCE response to client  as it's not required. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:23,752] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response: from connection 127.0.0.1:59081-127.0.0.1:59082-0;totalTime:0.94,requestQueueTime:0.0,localTime:6.1085488067E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.622,sendTime:0.012,securityProtocol:PLAINTEXT,principal:User:ANONYMOUS,listener:PLAINTEXT,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:23,753] TRACE Socket server received empty response to send, registering for read: Response(type=NoOp, request=Request(processor=0, connectionId=127.0.0.1:59081-127.0.0.1:59082-0, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(PLAINTEXT), securityProtocol=PLAINTEXT, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22])) (kafka.network.Processor:54)
[2020-01-15 10:21:23,753] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:23,754] TRACE Not sending PRODUCE response to client  as it's not required. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:23,755] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response: from connection 127.0.0.1:59081-127.0.0.1:59082-0;totalTime:1.274,requestQueueTime:0.0,localTime:6.1085490686E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.878,sendTime:0.005,securityProtocol:PLAINTEXT,principal:User:ANONYMOUS,listener:PLAINTEXT,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:23,755] TRACE Socket server received empty response to send, registering for read: Response(type=NoOp, request=Request(processor=0, connectionId=127.0.0.1:59081-127.0.0.1:59082-0, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(PLAINTEXT), securityProtocol=PLAINTEXT, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22])) (kafka.network.Processor:54)
[2020-01-15 10:21:23,755] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:23,755] TRACE Not sending PRODUCE response to client  as it's not required. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:23,756] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response: from connection 127.0.0.1:59081-127.0.0.1:59082-0;totalTime:0.998,requestQueueTime:0.0,localTime:6.1085492364E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.788,sendTime:0.007,securityProtocol:PLAINTEXT,principal:User:ANONYMOUS,listener:PLAINTEXT,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:23,757] TRACE Socket server received empty response to send, registering for read: Response(type=NoOp, request=Request(processor=0, connectionId=127.0.0.1:59081-127.0.0.1:59082-0, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(PLAINTEXT), securityProtocol=PLAINTEXT, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22])) (kafka.network.Processor:54)
[2020-01-15 10:21:23,757] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:23,757] TRACE Not sending PRODUCE response to client  as it's not required. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:23,757] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer:66)
[2020-01-15 10:21:23,758] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:23,757] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response: from connection 127.0.0.1:59081-127.0.0.1:59082-0;totalTime:0.567,requestQueueTime:0.0,localTime:6.1085493777E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.426,sendTime:0.003,securityProtocol:PLAINTEXT,principal:User:ANONYMOUS,listener:PLAINTEXT,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:23,758] TRACE Socket server received empty response to send, registering for read: Response(type=NoOp, request=Request(processor=0, connectionId=127.0.0.1:59081-127.0.0.1:59082-0, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(PLAINTEXT), securityProtocol=PLAINTEXT, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22])) (kafka.network.Processor:54)
[2020-01-15 10:21:23,758] DEBUG Closing server socket and selector. (kafka.network.Acceptor:62)
[2020-01-15 10:21:23,760] DEBUG Closing selector - processor 0 (kafka.network.Processor:62)
[2020-01-15 10:21:23,761] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:23,768] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer:66)
[2020-01-15 10:21:23,830] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 60000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1500
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/b3/bhnnh3l53jjdfgphtx91qd1h0000gn/T/kafka-6013254070707516523
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections = 2147483647
	max.connections.per.ip = 5
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 1
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 50
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1500
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 300000
	socket.request.max.bytes = 100
	socket.send.buffer.bytes = 300000
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:1
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig:347)
[2020-01-15 10:21:23,836] INFO Awaiting socket connections on localhost:59086. (kafka.network.Acceptor:66)
[2020-01-15 10:21:23,843] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(localhost,0,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServerTest$$anon$5:66)
[2020-01-15 10:21:23,843] DEBUG [SocketServer brokerId=0] Wait for authorizer to complete start up on listener ListenerName(PLAINTEXT) (kafka.network.SocketServerTest$$anon$5:62)
[2020-01-15 10:21:23,843] DEBUG [SocketServer brokerId=0] Start processors on listener ListenerName(PLAINTEXT) (kafka.network.SocketServerTest$$anon$5:62)
[2020-01-15 10:21:23,844] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServerTest$$anon$5:66)
[2020-01-15 10:21:23,844] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServerTest$$anon$5:66)
[2020-01-15 10:21:23,848] DEBUG Accepted connection from /127.0.0.1:59087 on /127.0.0.1:59086 and assigned it to processor 0, sendBufferSize [actual|requested]: [300000|300000] recvBufferSize [actual|requested]: [310308|300000] (kafka.network.Acceptor:62)
[2020-01-15 10:21:23,848] DEBUG Processor 0 listening to new connection from /127.0.0.1:59087 (kafka.network.SocketServerTest$$anon$5$$anon$6:62)
[2020-01-15 10:21:23,850] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:23,850] TRACE Not sending PRODUCE response to client  as it's not required. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:23,852] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response: from connection 127.0.0.1:59086-127.0.0.1:59087-0;totalTime:1.439,requestQueueTime:0.0,localTime:6.1085587131E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:1.12,sendTime:0.004,securityProtocol:PLAINTEXT,principal:User:ANONYMOUS,listener:PLAINTEXT,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:23,852] TRACE Socket server received empty response to send, registering for read: Response(type=NoOp, request=Request(processor=0, connectionId=127.0.0.1:59086-127.0.0.1:59087-0, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(PLAINTEXT), securityProtocol=PLAINTEXT, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22])) (kafka.network.SocketServerTest$$anon$5$$anon$6:54)
[2020-01-15 10:21:23,853] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:23,853] TRACE Not sending PRODUCE response to client  as it's not required. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:23,854] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response: from connection 127.0.0.1:59086-127.0.0.1:59087-0;totalTime:0.777,requestQueueTime:0.0,localTime:6.1085590252E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.562,sendTime:0.022,securityProtocol:PLAINTEXT,principal:User:ANONYMOUS,listener:PLAINTEXT,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:23,854] TRACE Socket server received empty response to send, registering for read: Response(type=NoOp, request=Request(processor=0, connectionId=127.0.0.1:59086-127.0.0.1:59087-0, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(PLAINTEXT), securityProtocol=PLAINTEXT, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22])) (kafka.network.SocketServerTest$$anon$5$$anon$6:54)
[2020-01-15 10:21:23,854] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:23,854] TRACE Sending PRODUCE response to client  of 26 bytes. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:23,855] TRACE Socket server received response to send to 127.0.0.1:59086-127.0.0.1:59087-0, registering for write and sending data: Response(type=Send, request=Request(processor=0, connectionId=127.0.0.1:59086-127.0.0.1:59087-0, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(PLAINTEXT), securityProtocol=PLAINTEXT, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22]), send=org.apache.kafka.common.network.NetworkSend@45b89acd, asString=Some(RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1))) (kafka.network.SocketServerTest$$anon$5$$anon$6:54)
[2020-01-15 10:21:23,856] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) from connection 127.0.0.1:59086-127.0.0.1:59087-0;totalTime:2.133,requestQueueTime:0.0,localTime:6.1085591381E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.366,sendTime:1.564,securityProtocol:PLAINTEXT,principal:User:ANONYMOUS,listener:PLAINTEXT,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:23,959] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServerTest$$anon$5:66)
[2020-01-15 10:21:23,959] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServerTest$$anon$5:66)
[2020-01-15 10:21:23,959] DEBUG Closing server socket and selector. (kafka.network.Acceptor:62)
[2020-01-15 10:21:23,960] DEBUG Closing selector - processor 0 (kafka.network.SocketServerTest$$anon$5$$anon$6:62)
[2020-01-15 10:21:23,961] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServerTest$$anon$5:66)
[2020-01-15 10:21:23,965] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServerTest$$anon$5:66)
[2020-01-15 10:21:23,965] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer:66)
[2020-01-15 10:21:23,965] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:23,966] DEBUG Closing server socket and selector. (kafka.network.Acceptor:62)
[2020-01-15 10:21:23,966] DEBUG Closing selector - processor 0 (kafka.network.Processor:62)
[2020-01-15 10:21:23,967] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:23,971] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer:66)
[2020-01-15 10:21:24,006] DEBUG Accepted connection from /127.0.0.1:59097 on /127.0.0.1:59096 and assigned it to processor 0, sendBufferSize [actual|requested]: [300000|300000] recvBufferSize [actual|requested]: [310308|300000] (kafka.network.Acceptor:62)
[2020-01-15 10:21:24,007] DEBUG Processor 0 listening to new connection from /127.0.0.1:59097 (kafka.network.Processor:62)
[2020-01-15 10:21:24,007] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:24,012] TRACE Notifying channel throttling has started for client  for PRODUCE (kafka.network.RequestChannel:54)
[2020-01-15 10:21:24,013] TRACE Sending PRODUCE response to client  of 26 bytes. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:24,013] TRACE Socket server received response to send to 127.0.0.1:59096-127.0.0.1:59097-0, registering for write and sending data: Response(type=Send, request=Request(processor=0, connectionId=127.0.0.1:59096-127.0.0.1:59097-0, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(PLAINTEXT), securityProtocol=PLAINTEXT, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22]), send=org.apache.kafka.common.network.NetworkSend@70d5b791, asString=Some(RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1))) (kafka.network.Processor:54)
[2020-01-15 10:21:24,013] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) from connection 127.0.0.1:59096-127.0.0.1:59097-0;totalTime:5.8,requestQueueTime:0.0,localTime:6.1085749117E7,remoteTime:0.298,throttleTime:0.0,responseQueueTime:0.22,sendTime:0.298,securityProtocol:PLAINTEXT,principal:User:ANONYMOUS,listener:PLAINTEXT,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:24,013] TRACE Channel throttled for: 100 ms (kafka.server.ThrottledChannel:54)
[2020-01-15 10:21:24,014] TRACE Notifying channel throttling has ended for client  for PRODUCE (kafka.network.RequestChannel:54)
[2020-01-15 10:21:24,019] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer:66)
[2020-01-15 10:21:24,019] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:24,019] DEBUG Closing server socket and selector. (kafka.network.Acceptor:62)
[2020-01-15 10:21:24,019] DEBUG Closing selector - processor 0 (kafka.network.Processor:62)
[2020-01-15 10:21:24,019] DEBUG Closing selector connection 127.0.0.1:59096-127.0.0.1:59097-0 (kafka.network.Processor:62)
[2020-01-15 10:21:24,020] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:24,026] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer:66)
[2020-01-15 10:21:24,045] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 60000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1500
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/b3/bhnnh3l53jjdfgphtx91qd1h0000gn/T/kafka-7655453349364568477
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections = 2147483647
	max.connections.per.ip = 5
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 1
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 50
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1500
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 300000
	socket.request.max.bytes = 100
	socket.send.buffer.bytes = 300000
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:1
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig:347)
[2020-01-15 10:21:24,051] INFO Awaiting socket connections on localhost:59103. (kafka.network.Acceptor:66)
[2020-01-15 10:21:24,053] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(localhost,0,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:24,053] DEBUG [SocketServer brokerId=0] Wait for authorizer to complete start up on listener ListenerName(PLAINTEXT) (kafka.network.SocketServerTest$TestableSocketServer:62)
[2020-01-15 10:21:24,053] DEBUG [SocketServer brokerId=0] Start processors on listener ListenerName(PLAINTEXT) (kafka.network.SocketServerTest$TestableSocketServer:62)
[2020-01-15 10:21:24,053] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:24,054] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:24,056] DEBUG Accepted connection from /127.0.0.1:59104 on /127.0.0.1:59103 and assigned it to processor 0, sendBufferSize [actual|requested]: [300000|300000] recvBufferSize [actual|requested]: [310308|300000] (kafka.network.Acceptor:62)
[2020-01-15 10:21:24,056] DEBUG Processor 0 listening to new connection from /127.0.0.1:59104 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:24,056] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:24,057] TRACE Sending PRODUCE response to client  of 26 bytes. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:24,057] TRACE Socket server received response to send to 127.0.0.1:59103-127.0.0.1:59104-0, registering for write and sending data: Response(type=Send, request=Request(processor=0, connectionId=127.0.0.1:59103-127.0.0.1:59104-0, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(PLAINTEXT), securityProtocol=PLAINTEXT, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22]), send=org.apache.kafka.common.network.NetworkSend@735135fb, asString=Some(RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1))) (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:54)
[2020-01-15 10:21:24,058] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) from connection 127.0.0.1:59103-127.0.0.1:59104-0;totalTime:1.005,requestQueueTime:0.0,localTime:6.108579346E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.273,sendTime:0.604,securityProtocol:PLAINTEXT,principal:User:ANONYMOUS,listener:PLAINTEXT,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:24,360] DEBUG Closing selector - processor 0 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:24,360] DEBUG Closing selector connection 127.0.0.1:59103-127.0.0.1:59104-0 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:24,373] ERROR Uncaught exception in thread 'data-plane-kafka-network-thread-0-ListenerName(PLAINTEXT)-PLAINTEXT-0': (org.apache.kafka.common.utils.KafkaThread:49)
kafka.network.SocketServerTest$$anon$7
[2020-01-15 10:21:24,476] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:24,476] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:24,476] DEBUG Closing server socket and selector. (kafka.network.Acceptor:62)
[2020-01-15 10:21:24,477] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:24,481] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:24,482] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer:66)
[2020-01-15 10:21:24,482] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:24,482] DEBUG Closing server socket and selector. (kafka.network.Acceptor:62)
[2020-01-15 10:21:24,482] DEBUG Closing selector - processor 0 (kafka.network.Processor:62)
[2020-01-15 10:21:24,483] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:24,485] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer:66)
[2020-01-15 10:21:24,492] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:24,492] DEBUG Closing server socket and selector. (kafka.network.Acceptor:62)
[2020-01-15 10:21:24,492] DEBUG Closing selector - processor 0 (kafka.network.Processor:62)
[2020-01-15 10:21:24,492] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:24,494] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer:66)
[2020-01-15 10:21:24,499] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer:66)
[2020-01-15 10:21:24,499] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer:66)
[2020-01-15 10:21:24,502] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer:66)
[2020-01-15 10:21:24,590] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 60000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1500
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = SSL://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/b3/bhnnh3l53jjdfgphtx91qd1h0000gn/T/kafka-5236193485268472019
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections = 2147483647
	max.connections.per.ip = 5
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 1
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 50
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1500
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = SSL
	security.providers = null
	socket.receive.buffer.bytes = 300000
	socket.request.max.bytes = 100
	socket.send.buffer.bytes = 300000
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = [hidden]
	ssl.keymanager.algorithm = PKIX
	ssl.keystore.location = /var/folders/b3/bhnnh3l53jjdfgphtx91qd1h0000gn/T/serverKS2147581432065293624.jks
	ssl.keystore.password = [hidden]
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = /var/folders/b3/bhnnh3l53jjdfgphtx91qd1h0000gn/T/truststore7374093607953365594.jks
	ssl.truststore.password = [hidden]
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:1
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig:347)
[2020-01-15 10:21:24,595] INFO Awaiting socket connections on localhost:59120. (kafka.network.Acceptor:66)
[2020-01-15 10:21:24,618] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(localhost,0,ListenerName(SSL),SSL) (kafka.network.SocketServerTest$$anon$1:66)
[2020-01-15 10:21:24,618] DEBUG [SocketServer brokerId=0] Wait for authorizer to complete start up on listener ListenerName(SSL) (kafka.network.SocketServerTest$$anon$1:62)
[2020-01-15 10:21:24,619] DEBUG [SocketServer brokerId=0] Start processors on listener ListenerName(SSL) (kafka.network.SocketServerTest$$anon$1:62)
[2020-01-15 10:21:24,619] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServerTest$$anon$1:66)
[2020-01-15 10:21:24,619] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServerTest$$anon$1:66)
[2020-01-15 10:21:24,625] DEBUG Accepted connection from /127.0.0.1:59123 on /127.0.0.1:59120 and assigned it to processor 0, sendBufferSize [actual|requested]: [300000|300000] recvBufferSize [actual|requested]: [310308|300000] (kafka.network.Acceptor:62)
[2020-01-15 10:21:24,625] DEBUG Processor 0 listening to new connection from /127.0.0.1:59123 (kafka.network.SocketServerTest$$anon$1$$anon$2:62)
[2020-01-15 10:21:24,730] DEBUG Accepted connection from /127.0.0.1:59128 on /127.0.0.1:59120 and assigned it to processor 0, sendBufferSize [actual|requested]: [300000|300000] recvBufferSize [actual|requested]: [310308|300000] (kafka.network.Acceptor:62)
[2020-01-15 10:21:24,730] DEBUG Processor 0 listening to new connection from /127.0.0.1:59128 (kafka.network.SocketServerTest$$anon$1$$anon$2:62)
[2020-01-15 10:21:24,730] DEBUG Closing connection from /127.0.0.1:59128 (kafka.network.SocketServerTest$$anon$1$$anon$2:62)
[2020-01-15 10:21:24,731] ERROR Processor 0 closed connection from /127.0.0.1:59128 (kafka.network.SocketServerTest$$anon$1$$anon$2:76)
java.lang.IllegalStateException: There is already a connection for id 127.0.0.1:1-127.0.0.1:2-0
	at org.apache.kafka.common.network.Selector.ensureNotRegistered(Selector.java:322)
	at org.apache.kafka.common.network.Selector.register(Selector.java:310)
	at kafka.network.SocketServerTest$TestableSelector.super$register(SocketServerTest.scala:1823)
	at kafka.network.SocketServerTest$TestableSelector.$anonfun$register$2(SocketServerTest.scala:1823)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at kafka.network.SocketServerTest$TestableSelector.runOp(SocketServerTest.scala:1817)
	at kafka.network.SocketServerTest$TestableSelector.register(SocketServerTest.scala:1823)
	at kafka.network.Processor.configureNewConnections(SocketServer.scala:1024)
	at kafka.network.Processor.run(SocketServer.scala:757)
	at java.lang.Thread.run(Thread.java:748)
[2020-01-15 10:21:24,933] DEBUG Accepted connection from /127.0.0.1:59137 on /127.0.0.1:59120 and assigned it to processor 0, sendBufferSize [actual|requested]: [300000|300000] recvBufferSize [actual|requested]: [310308|300000] (kafka.network.Acceptor:62)
[2020-01-15 10:21:24,933] DEBUG Processor 0 listening to new connection from /127.0.0.1:59137 (kafka.network.SocketServerTest$$anon$1$$anon$2:62)
[2020-01-15 10:21:24,969] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:25,073] TRACE Not sending PRODUCE response to client  as it's not required. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:25,074] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response: from connection 127.0.0.1:1-127.0.0.1:2-0;totalTime:564.272,requestQueueTime:0.0,localTime:6.1086809837E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.599,sendTime:0.006,securityProtocol:SSL,principal:User:ANONYMOUS,listener:SSL,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:25,074] TRACE Socket server received empty response to send, registering for read: Response(type=NoOp, request=Request(processor=0, connectionId=127.0.0.1:1-127.0.0.1:2-0, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(SSL), securityProtocol=SSL, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22])) (kafka.network.SocketServerTest$$anon$1$$anon$2:54)
[2020-01-15 10:21:25,074] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:25,076] DEBUG Accepted connection from /127.0.0.1:59140 on /127.0.0.1:59120 and assigned it to processor 0, sendBufferSize [actual|requested]: [300000|300000] recvBufferSize [actual|requested]: [310308|300000] (kafka.network.Acceptor:62)
[2020-01-15 10:21:25,076] DEBUG Processor 0 listening to new connection from /127.0.0.1:59140 (kafka.network.SocketServerTest$$anon$1$$anon$2:62)
[2020-01-15 10:21:25,076] DEBUG Closing connection from /127.0.0.1:59140 (kafka.network.SocketServerTest$$anon$1$$anon$2:62)
[2020-01-15 10:21:25,076] ERROR Processor 0 closed connection from /127.0.0.1:59140 (kafka.network.SocketServerTest$$anon$1$$anon$2:76)
java.lang.IllegalStateException: There is already a connection for id 127.0.0.1:1-127.0.0.1:2-0
	at org.apache.kafka.common.network.Selector.ensureNotRegistered(Selector.java:322)
	at org.apache.kafka.common.network.Selector.register(Selector.java:310)
	at kafka.network.SocketServerTest$TestableSelector.super$register(SocketServerTest.scala:1823)
	at kafka.network.SocketServerTest$TestableSelector.$anonfun$register$2(SocketServerTest.scala:1823)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at kafka.network.SocketServerTest$TestableSelector.runOp(SocketServerTest.scala:1817)
	at kafka.network.SocketServerTest$TestableSelector.register(SocketServerTest.scala:1823)
	at kafka.network.Processor.configureNewConnections(SocketServer.scala:1024)
	at kafka.network.Processor.run(SocketServer.scala:757)
	at java.lang.Thread.run(Thread.java:748)
[2020-01-15 10:21:25,178] TRACE Sending PRODUCE response to client  of 26 bytes. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:25,179] TRACE Socket server received response to send to 127.0.0.1:1-127.0.0.1:2-0, registering for write and sending data: Response(type=Send, request=Request(processor=0, connectionId=127.0.0.1:1-127.0.0.1:2-0, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(SSL), securityProtocol=SSL, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22]), send=org.apache.kafka.common.network.NetworkSend@922b58d, asString=Some(RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1))) (kafka.network.SocketServerTest$$anon$1$$anon$2:54)
[2020-01-15 10:21:25,179] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) from connection 127.0.0.1:1-127.0.0.1:2-0;totalTime:670.127,requestQueueTime:0.0,localTime:6.1086915301E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.5,sendTime:0.496,securityProtocol:SSL,principal:User:ANONYMOUS,listener:SSL,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:25,281] DEBUG Accepted connection from /127.0.0.1:59141 on /127.0.0.1:59120 and assigned it to processor 0, sendBufferSize [actual|requested]: [300000|300000] recvBufferSize [actual|requested]: [310308|300000] (kafka.network.Acceptor:62)
[2020-01-15 10:21:25,281] DEBUG Processor 0 listening to new connection from /127.0.0.1:59141 (kafka.network.SocketServerTest$$anon$1$$anon$2:62)
[2020-01-15 10:21:25,381] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServerTest$$anon$1:66)
[2020-01-15 10:21:25,382] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServerTest$$anon$1:66)
[2020-01-15 10:21:25,382] DEBUG Closing server socket and selector. (kafka.network.Acceptor:62)
[2020-01-15 10:21:25,382] DEBUG Closing selector - processor 0 (kafka.network.SocketServerTest$$anon$1$$anon$2:62)
[2020-01-15 10:21:25,382] DEBUG Closing selector connection 127.0.0.1:1-127.0.0.1:2-0 (kafka.network.SocketServerTest$$anon$1$$anon$2:62)
[2020-01-15 10:21:25,383] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServerTest$$anon$1:66)
[2020-01-15 10:21:25,386] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServerTest$$anon$1:66)
[2020-01-15 10:21:25,386] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer:66)
[2020-01-15 10:21:25,387] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:25,387] DEBUG Closing server socket and selector. (kafka.network.Acceptor:62)
[2020-01-15 10:21:25,387] DEBUG Closing selector - processor 0 (kafka.network.Processor:62)
[2020-01-15 10:21:25,387] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:25,392] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer:66)
[2020-01-15 10:21:25,459] DEBUG Accepted connection from /127.0.0.1:59147 on /127.0.0.1:59144 and assigned it to processor 0, sendBufferSize [actual|requested]: [300000|300000] recvBufferSize [actual|requested]: [310308|300000] (kafka.network.Acceptor:62)
[2020-01-15 10:21:25,459] DEBUG Processor 0 listening to new connection from /127.0.0.1:59147 (kafka.network.Processor:62)
[2020-01-15 10:21:25,459] TRACE Processor 0 received request: RequestHeader(apiKey=API_VERSIONS, apiVersion=0, clientId=clientId, correlationId=-1) -- {} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:25,459] TRACE Not sending API_VERSIONS response to client clientId as it's not required. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:25,460] DEBUG Completed request:RequestHeader(apiKey=API_VERSIONS, apiVersion=0, clientId=clientId, correlationId=-1) -- {},response: from connection 127.0.0.1:59144-127.0.0.1:59147-0;totalTime:0.408,requestQueueTime:0.0,localTime:6.1087196378E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.2,sendTime:0.001,securityProtocol:PLAINTEXT,principal:User:ANONYMOUS,listener:PLAINTEXT,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:25,460] TRACE Socket server received empty response to send, registering for read: Response(type=NoOp, request=Request(processor=0, connectionId=127.0.0.1:59144-127.0.0.1:59147-0, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(PLAINTEXT), securityProtocol=PLAINTEXT, buffer=null)) (kafka.network.Processor:54)
[2020-01-15 10:21:25,460] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:25,460] TRACE Not sending PRODUCE response to client  as it's not required. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:25,461] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response: from connection 127.0.0.1:59144-127.0.0.1:59147-0;totalTime:0.338,requestQueueTime:0.0,localTime:6.1087197181E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.218,sendTime:0.0,securityProtocol:PLAINTEXT,principal:User:ANONYMOUS,listener:PLAINTEXT,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:25,461] TRACE Socket server received empty response to send, registering for read: Response(type=NoOp, request=Request(processor=0, connectionId=127.0.0.1:59144-127.0.0.1:59147-0, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(PLAINTEXT), securityProtocol=PLAINTEXT, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22])) (kafka.network.Processor:54)
[2020-01-15 10:21:25,565] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer:66)
[2020-01-15 10:21:25,565] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:25,565] DEBUG Closing server socket and selector. (kafka.network.Acceptor:62)
[2020-01-15 10:21:25,566] DEBUG Closing selector - processor 0 (kafka.network.Processor:62)
[2020-01-15 10:21:25,566] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:25,570] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer:66)
[2020-01-15 10:21:25,576] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer:66)
[2020-01-15 10:21:25,577] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:25,577] DEBUG Closing server socket and selector. (kafka.network.Acceptor:62)
[2020-01-15 10:21:25,577] DEBUG Closing selector - processor 0 (kafka.network.Processor:62)
[2020-01-15 10:21:25,577] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:25,581] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer:66)
[2020-01-15 10:21:25,582] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 1500
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1500
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = SASL_PLAINTEXT://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/b3/bhnnh3l53jjdfgphtx91qd1h0000gn/T/kafka-8083482946888432348
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 1
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1500
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = PLAIN
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = SASL_PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:1
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig:347)
[2020-01-15 10:21:25,588] INFO Awaiting socket connections on localhost:59150. (kafka.network.Acceptor:66)
[2020-01-15 10:21:25,590] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(localhost,0,ListenerName(SASL_PLAINTEXT),SASL_PLAINTEXT) (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:25,590] DEBUG [SocketServer brokerId=0] Wait for authorizer to complete start up on listener ListenerName(SASL_PLAINTEXT) (kafka.network.SocketServerTest$TestableSocketServer:62)
[2020-01-15 10:21:25,590] DEBUG [SocketServer brokerId=0] Start processors on listener ListenerName(SASL_PLAINTEXT) (kafka.network.SocketServerTest$TestableSocketServer:62)
[2020-01-15 10:21:25,590] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:25,591] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:25,592] DEBUG Accepted connection from /127.0.0.1:59151 on /127.0.0.1:59150 and assigned it to processor 0, sendBufferSize [actual|requested]: [102400|102400] recvBufferSize [actual|requested]: [375636|102400] (kafka.network.Acceptor:62)
[2020-01-15 10:21:25,592] DEBUG Processor 0 listening to new connection from /127.0.0.1:59151 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:25,595] DEBUG Disconnecting expired channel: org.apache.kafka.common.network.KafkaChannel@25f64fcc id=127.0.0.1:59150-127.0.0.1:59151-0 : RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:25,595] DEBUG Closing selector connection 127.0.0.1:59150-127.0.0.1:59151-0 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:25,698] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:25,698] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:25,698] DEBUG Closing server socket and selector. (kafka.network.Acceptor:62)
[2020-01-15 10:21:25,698] DEBUG Closing selector - processor 0 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:25,699] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:25,705] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:25,705] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer:66)
[2020-01-15 10:21:25,711] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer:66)
[2020-01-15 10:21:25,724] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1500
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/b3/bhnnh3l53jjdfgphtx91qd1h0000gn/T/kafka-9041966118190769474
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1500
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:1
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig:347)
[2020-01-15 10:21:25,728] INFO Awaiting socket connections on localhost:59156. (kafka.network.Acceptor:66)
[2020-01-15 10:21:25,729] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(localhost,0,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServerTest$$anon$3:66)
[2020-01-15 10:21:25,729] DEBUG [SocketServer brokerId=0] Wait for authorizer to complete start up on listener ListenerName(PLAINTEXT) (kafka.network.SocketServerTest$$anon$3:62)
[2020-01-15 10:21:25,729] DEBUG [SocketServer brokerId=0] Start processors on listener ListenerName(PLAINTEXT) (kafka.network.SocketServerTest$$anon$3:62)
[2020-01-15 10:21:25,730] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServerTest$$anon$3:66)
[2020-01-15 10:21:25,730] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServerTest$$anon$3:66)
[2020-01-15 10:21:25,731] DEBUG Accepted connection from /127.0.0.1:59157 on /127.0.0.1:59156 and assigned it to processor 0, sendBufferSize [actual|requested]: [102400|102400] recvBufferSize [actual|requested]: [375636|102400] (kafka.network.Acceptor:62)
[2020-01-15 10:21:25,731] DEBUG Processor 0 listening to new connection from /127.0.0.1:59157 (kafka.network.SocketServerTest$$anon$3$$anon$4:62)
[2020-01-15 10:21:25,731] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:25,732] TRACE Sending PRODUCE response to client  of 4 bytes. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:25,732] TRACE Socket server received response to send to 127.0.0.1:59156-127.0.0.1:59157-0, registering for write and sending data: Response(type=Send, request=Request(processor=0, connectionId=127.0.0.1:59156-127.0.0.1:59157-0, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(PLAINTEXT), securityProtocol=PLAINTEXT, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22]), send=org.apache.kafka.common.network.NetworkSend@153b4317, asString=Some(someResponse)) (kafka.network.SocketServerTest$$anon$3$$anon$4:54)
[2020-01-15 10:21:25,732] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response:someResponse from connection 127.0.0.1:59156-127.0.0.1:59157-0;totalTime:0.598,requestQueueTime:0.0,localTime:6.1087468526E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.213,sendTime:0.225,securityProtocol:PLAINTEXT,principal:User:ANONYMOUS,listener:PLAINTEXT,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:25,836] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServerTest$$anon$3:66)
[2020-01-15 10:21:25,836] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServerTest$$anon$3:66)
[2020-01-15 10:21:25,837] DEBUG Closing server socket and selector. (kafka.network.Acceptor:62)
[2020-01-15 10:21:25,837] DEBUG Closing selector - processor 0 (kafka.network.SocketServerTest$$anon$3$$anon$4:62)
[2020-01-15 10:21:25,838] DEBUG Closing selector - processor 1 (kafka.network.SocketServerTest$$anon$3$$anon$4:62)
[2020-01-15 10:21:25,838] DEBUG Closing selector - processor 2 (kafka.network.SocketServerTest$$anon$3$$anon$4:62)
[2020-01-15 10:21:25,839] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServerTest$$anon$3:66)
[2020-01-15 10:21:25,843] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServerTest$$anon$3:66)
[2020-01-15 10:21:25,843] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1500
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/b3/bhnnh3l53jjdfgphtx91qd1h0000gn/T/kafka-5637376557097289099
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1500
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:1
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig:347)
[2020-01-15 10:21:25,849] INFO Awaiting socket connections on localhost:59159. (kafka.network.Acceptor:66)
[2020-01-15 10:21:25,850] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(localhost,0,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServerTest$$anon$3:66)
[2020-01-15 10:21:25,850] DEBUG [SocketServer brokerId=0] Wait for authorizer to complete start up on listener ListenerName(PLAINTEXT) (kafka.network.SocketServerTest$$anon$3:62)
[2020-01-15 10:21:25,850] DEBUG [SocketServer brokerId=0] Start processors on listener ListenerName(PLAINTEXT) (kafka.network.SocketServerTest$$anon$3:62)
[2020-01-15 10:21:25,851] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServerTest$$anon$3:66)
[2020-01-15 10:21:25,851] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServerTest$$anon$3:66)
[2020-01-15 10:21:25,852] DEBUG Accepted connection from /127.0.0.1:59161 on /127.0.0.1:59159 and assigned it to processor 0, sendBufferSize [actual|requested]: [102400|102400] recvBufferSize [actual|requested]: [375636|102400] (kafka.network.Acceptor:62)
[2020-01-15 10:21:25,852] DEBUG Processor 0 listening to new connection from /127.0.0.1:59161 (kafka.network.SocketServerTest$$anon$3$$anon$4:62)
[2020-01-15 10:21:25,853] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:25,853] TRACE Sending PRODUCE response to client  of 550004 bytes. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:25,853] TRACE Socket server received response to send to 127.0.0.1:59159-127.0.0.1:59161-0, registering for write and sending data: Response(type=Send, request=Request(processor=0, connectionId=127.0.0.1:59159-127.0.0.1:59161-0, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(PLAINTEXT), securityProtocol=PLAINTEXT, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22]), send=org.apache.kafka.common.network.NetworkSend@643ffada, asString=Some(someResponse)) (kafka.network.SocketServerTest$$anon$3$$anon$4:54)
[2020-01-15 10:21:25,854] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response:someResponse from connection 127.0.0.1:59159-127.0.0.1:59161-0;totalTime:1.693,requestQueueTime:0.0,localTime:6.1087589751E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.272,sendTime:1.189,securityProtocol:PLAINTEXT,principal:User:ANONYMOUS,listener:PLAINTEXT,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:25,954] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServerTest$$anon$3:66)
[2020-01-15 10:21:25,955] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServerTest$$anon$3:66)
[2020-01-15 10:21:25,955] DEBUG Closing server socket and selector. (kafka.network.Acceptor:62)
[2020-01-15 10:21:25,956] DEBUG Closing selector - processor 0 (kafka.network.SocketServerTest$$anon$3$$anon$4:62)
[2020-01-15 10:21:25,957] DEBUG Closing selector - processor 1 (kafka.network.SocketServerTest$$anon$3$$anon$4:62)
[2020-01-15 10:21:25,957] DEBUG Closing selector - processor 2 (kafka.network.SocketServerTest$$anon$3$$anon$4:62)
[2020-01-15 10:21:25,957] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServerTest$$anon$3:66)
[2020-01-15 10:21:25,962] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServerTest$$anon$3:66)
[2020-01-15 10:21:25,962] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer:66)
[2020-01-15 10:21:25,962] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:25,963] DEBUG Closing server socket and selector. (kafka.network.Acceptor:62)
[2020-01-15 10:21:25,963] DEBUG Closing selector - processor 0 (kafka.network.Processor:62)
[2020-01-15 10:21:25,963] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:25,966] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer:66)
[2020-01-15 10:21:25,982] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer:66)
[2020-01-15 10:21:25,982] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:25,982] DEBUG Closing server socket and selector. (kafka.network.Acceptor:62)
[2020-01-15 10:21:25,983] DEBUG Closing selector - processor 0 (kafka.network.Processor:62)
[2020-01-15 10:21:25,983] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:25,987] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer:66)
[2020-01-15 10:21:26,149] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 60000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1500
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = SSL://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/b3/bhnnh3l53jjdfgphtx91qd1h0000gn/T/kafka-1028705382092494084
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections = 2147483647
	max.connections.per.ip = 5
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 1
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 50
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1500
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = SSL
	security.providers = null
	socket.receive.buffer.bytes = 300000
	socket.request.max.bytes = 100
	socket.send.buffer.bytes = 300000
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = [hidden]
	ssl.keymanager.algorithm = PKIX
	ssl.keystore.location = /var/folders/b3/bhnnh3l53jjdfgphtx91qd1h0000gn/T/serverKS73173512295870931.jks
	ssl.keystore.password = [hidden]
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = /var/folders/b3/bhnnh3l53jjdfgphtx91qd1h0000gn/T/truststore7226075850021812855.jks
	ssl.truststore.password = [hidden]
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:1
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig:347)
[2020-01-15 10:21:26,153] INFO Awaiting socket connections on localhost:59171. (kafka.network.Acceptor:66)
[2020-01-15 10:21:26,179] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(localhost,0,ListenerName(SSL),SSL) (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:26,179] DEBUG [SocketServer brokerId=0] Wait for authorizer to complete start up on listener ListenerName(SSL) (kafka.network.SocketServerTest$TestableSocketServer:62)
[2020-01-15 10:21:26,180] DEBUG [SocketServer brokerId=0] Start processors on listener ListenerName(SSL) (kafka.network.SocketServerTest$TestableSocketServer:62)
[2020-01-15 10:21:26,180] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:26,181] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:26,182] DEBUG Accepted connection from /127.0.0.1:59174 on /127.0.0.1:59171 and assigned it to processor 0, sendBufferSize [actual|requested]: [300000|300000] recvBufferSize [actual|requested]: [310308|300000] (kafka.network.Acceptor:62)
[2020-01-15 10:21:26,182] DEBUG Processor 0 listening to new connection from /127.0.0.1:59174 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:26,209] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:26,313] TRACE Not sending PRODUCE response to client  as it's not required. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:26,314] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response: from connection 127.0.0.1:59171-127.0.0.1:59174-0;totalTime:104.871,requestQueueTime:0.0,localTime:6.108804971E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.557,sendTime:0.003,securityProtocol:SSL,principal:User:ANONYMOUS,listener:SSL,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:26,314] TRACE Socket server received empty response to send, registering for read: Response(type=NoOp, request=Request(processor=0, connectionId=127.0.0.1:59171-127.0.0.1:59174-0, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(SSL), securityProtocol=SSL, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22])) (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:54)
[2020-01-15 10:21:26,314] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:26,314] TRACE Not sending PRODUCE response to client  as it's not required. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:26,315] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response: from connection 127.0.0.1:59171-127.0.0.1:59174-0;totalTime:0.673,requestQueueTime:0.0,localTime:6.108805104E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.527,sendTime:0.002,securityProtocol:SSL,principal:User:ANONYMOUS,listener:SSL,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:26,315] TRACE Socket server received empty response to send, registering for read: Response(type=NoOp, request=Request(processor=0, connectionId=127.0.0.1:59171-127.0.0.1:59174-0, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(SSL), securityProtocol=SSL, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22])) (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:54)
[2020-01-15 10:21:26,315] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:26,315] TRACE Sending PRODUCE response to client  of 26 bytes. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:26,316] TRACE Socket server received response to send to 127.0.0.1:59171-127.0.0.1:59174-0, registering for write and sending data: Response(type=Send, request=Request(processor=0, connectionId=127.0.0.1:59171-127.0.0.1:59174-0, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(SSL), securityProtocol=SSL, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22]), send=org.apache.kafka.common.network.NetworkSend@733fcfc9, asString=Some(RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1))) (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:54)
[2020-01-15 10:21:26,316] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) from connection 127.0.0.1:59171-127.0.0.1:59174-0;totalTime:0.953,requestQueueTime:0.0,localTime:6.108805219E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.433,sendTime:0.365,securityProtocol:SSL,principal:User:ANONYMOUS,listener:SSL,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:26,418] DEBUG Accepted connection from /127.0.0.1:59179 on /127.0.0.1:59171 and assigned it to processor 0, sendBufferSize [actual|requested]: [300000|300000] recvBufferSize [actual|requested]: [310308|300000] (kafka.network.Acceptor:62)
[2020-01-15 10:21:26,418] DEBUG Processor 0 listening to new connection from /127.0.0.1:59179 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:26,431] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:26,431] TRACE Sending PRODUCE response to client  of 26 bytes. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:26,432] TRACE Socket server received response to send to 127.0.0.1:59171-127.0.0.1:59179-1, registering for write and sending data: Response(type=Send, request=Request(processor=0, connectionId=127.0.0.1:59171-127.0.0.1:59179-1, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(SSL), securityProtocol=SSL, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22]), send=org.apache.kafka.common.network.NetworkSend@3202c5f2, asString=Some(RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1))) (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:54)
[2020-01-15 10:21:26,432] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) from connection 127.0.0.1:59171-127.0.0.1:59179-1;totalTime:0.752,requestQueueTime:0.0,localTime:6.1088168319E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.266,sendTime:0.272,securityProtocol:SSL,principal:User:ANONYMOUS,listener:SSL,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:26,533] DEBUG Accepted connection from /127.0.0.1:59182 on /127.0.0.1:59171 and assigned it to processor 0, sendBufferSize [actual|requested]: [300000|300000] recvBufferSize [actual|requested]: [310308|300000] (kafka.network.Acceptor:62)
[2020-01-15 10:21:26,533] DEBUG Processor 0 listening to new connection from /127.0.0.1:59182 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:26,543] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:26,543] TRACE Sending PRODUCE response to client  of 26 bytes. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:26,543] TRACE Socket server received response to send to 127.0.0.1:59171-127.0.0.1:59182-2, registering for write and sending data: Response(type=Send, request=Request(processor=0, connectionId=127.0.0.1:59171-127.0.0.1:59182-2, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(SSL), securityProtocol=SSL, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22]), send=org.apache.kafka.common.network.NetworkSend@3fa1222, asString=Some(RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1))) (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:54)
[2020-01-15 10:21:26,543] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) from connection 127.0.0.1:59171-127.0.0.1:59182-2;totalTime:0.725,requestQueueTime:0.0,localTime:6.1088279686E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.296,sendTime:0.239,securityProtocol:SSL,principal:User:ANONYMOUS,listener:SSL,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:26,646] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:26,646] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:26,646] DEBUG Closing server socket and selector. (kafka.network.Acceptor:62)
[2020-01-15 10:21:26,646] DEBUG Closing selector - processor 0 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:26,647] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:26,652] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:26,652] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer:66)
[2020-01-15 10:21:26,652] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:26,652] DEBUG Closing server socket and selector. (kafka.network.Acceptor:62)
[2020-01-15 10:21:26,652] DEBUG Closing selector - processor 0 (kafka.network.Processor:62)
[2020-01-15 10:21:26,653] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:26,656] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer:66)
[2020-01-15 10:21:26,706] DEBUG Accepted connection from /127.0.0.1:59189 on /127.0.0.1:59188 and assigned it to processor 0, sendBufferSize [actual|requested]: [300000|300000] recvBufferSize [actual|requested]: [310308|300000] (kafka.network.Acceptor:62)
[2020-01-15 10:21:26,706] DEBUG Processor 0 listening to new connection from /127.0.0.1:59189 (kafka.network.Processor:62)
[2020-01-15 10:21:26,706] DEBUG Accepted connection from /127.0.0.1:59191 on /127.0.0.1:59188 and assigned it to processor 0, sendBufferSize [actual|requested]: [300000|300000] recvBufferSize [actual|requested]: [310308|300000] (kafka.network.Acceptor:62)
[2020-01-15 10:21:26,706] DEBUG Processor 0 listening to new connection from /127.0.0.1:59191 (kafka.network.Processor:62)
[2020-01-15 10:21:26,706] DEBUG Accepted connection from /127.0.0.1:59192 on /127.0.0.1:59188 and assigned it to processor 0, sendBufferSize [actual|requested]: [300000|300000] recvBufferSize [actual|requested]: [310308|300000] (kafka.network.Acceptor:62)
[2020-01-15 10:21:26,706] DEBUG Processor 0 listening to new connection from /127.0.0.1:59192 (kafka.network.Processor:62)
[2020-01-15 10:21:26,706] DEBUG Accepted connection from /127.0.0.1:59193 on /127.0.0.1:59188 and assigned it to processor 0, sendBufferSize [actual|requested]: [300000|300000] recvBufferSize [actual|requested]: [310308|300000] (kafka.network.Acceptor:62)
[2020-01-15 10:21:26,706] DEBUG Processor 0 listening to new connection from /127.0.0.1:59193 (kafka.network.Processor:62)
[2020-01-15 10:21:26,707] DEBUG Accepted connection from /127.0.0.1:59194 on /127.0.0.1:59188 and assigned it to processor 0, sendBufferSize [actual|requested]: [300000|300000] recvBufferSize [actual|requested]: [310308|300000] (kafka.network.Acceptor:62)
[2020-01-15 10:21:26,707] DEBUG Processor 0 listening to new connection from /127.0.0.1:59194 (kafka.network.Processor:62)
[2020-01-15 10:21:26,707] INFO Rejected connection from /127.0.0.1, address already has the configured maximum of 5 connections. (kafka.network.Acceptor:66)
[2020-01-15 10:21:26,708] DEBUG Closing connection from /127.0.0.1:59195 (kafka.network.Acceptor:62)
[2020-01-15 10:21:26,808] DEBUG Processor 0 listening to new connection from /127.0.0.1:59196 (kafka.network.Processor:62)
[2020-01-15 10:21:26,808] DEBUG Accepted connection from /127.0.0.1:59196 on /127.0.0.1:59188 and assigned it to processor 0, sendBufferSize [actual|requested]: [300000|300000] recvBufferSize [actual|requested]: [310308|300000] (kafka.network.Acceptor:62)
[2020-01-15 10:21:26,809] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:26,809] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer:66)
[2020-01-15 10:21:26,809] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:26,809] DEBUG Closing server socket and selector. (kafka.network.Acceptor:62)
[2020-01-15 10:21:26,809] DEBUG Closing selector - processor 0 (kafka.network.Processor:62)
[2020-01-15 10:21:26,809] DEBUG Closing selector connection 127.0.0.1:59188-127.0.0.1:59192-2 (kafka.network.Processor:62)
[2020-01-15 10:21:26,810] DEBUG Closing selector connection 127.0.0.1:59188-127.0.0.1:59193-3 (kafka.network.Processor:62)
[2020-01-15 10:21:26,810] DEBUG Closing selector connection 127.0.0.1:59188-127.0.0.1:59194-4 (kafka.network.Processor:62)
[2020-01-15 10:21:26,810] DEBUG Closing selector connection 127.0.0.1:59188-127.0.0.1:59196-5 (kafka.network.Processor:62)
[2020-01-15 10:21:26,810] DEBUG Closing selector connection 127.0.0.1:59188-127.0.0.1:59191-1 (kafka.network.Processor:62)
[2020-01-15 10:21:26,811] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:26,816] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer:66)
[2020-01-15 10:21:26,825] DEBUG Processor 0 listening to new connection from /127.0.0.1:59198 (kafka.network.Processor:62)
[2020-01-15 10:21:26,825] DEBUG Accepted connection from /127.0.0.1:59198 on /127.0.0.1:59197 and assigned it to processor 0, sendBufferSize [actual|requested]: [300000|300000] recvBufferSize [actual|requested]: [310308|300000] (kafka.network.Acceptor:62)
[2020-01-15 10:21:26,826] DEBUG Processor 0 listening to new connection from /127.0.0.1:59199 (kafka.network.Processor:62)
[2020-01-15 10:21:26,826] DEBUG Accepted connection from /127.0.0.1:59199 on /127.0.0.1:59197 and assigned it to processor 0, sendBufferSize [actual|requested]: [300000|300000] recvBufferSize [actual|requested]: [310308|300000] (kafka.network.Acceptor:62)
[2020-01-15 10:21:26,826] DEBUG Accepted connection from /127.0.0.1:59200 on /127.0.0.1:59197 and assigned it to processor 0, sendBufferSize [actual|requested]: [300000|300000] recvBufferSize [actual|requested]: [310308|300000] (kafka.network.Acceptor:62)
[2020-01-15 10:21:26,826] DEBUG Processor 0 listening to new connection from /127.0.0.1:59200 (kafka.network.Processor:62)
[2020-01-15 10:21:26,826] DEBUG Accepted connection from /127.0.0.1:59201 on /127.0.0.1:59197 and assigned it to processor 0, sendBufferSize [actual|requested]: [300000|300000] recvBufferSize [actual|requested]: [310308|300000] (kafka.network.Acceptor:62)
[2020-01-15 10:21:26,826] DEBUG Processor 0 listening to new connection from /127.0.0.1:59201 (kafka.network.Processor:62)
[2020-01-15 10:21:26,826] DEBUG Processor 0 listening to new connection from /127.0.0.1:59202 (kafka.network.Processor:62)
[2020-01-15 10:21:26,826] DEBUG Accepted connection from /127.0.0.1:59202 on /127.0.0.1:59197 and assigned it to processor 0, sendBufferSize [actual|requested]: [300000|300000] recvBufferSize [actual|requested]: [310308|300000] (kafka.network.Acceptor:62)
[2020-01-15 10:21:26,827] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:26,827] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:26,827] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:26,828] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:26,828] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:26,829] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer:66)
[2020-01-15 10:21:26,829] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:26,829] DEBUG Closing server socket and selector. (kafka.network.Acceptor:62)
[2020-01-15 10:21:26,829] DEBUG Closing selector - processor 0 (kafka.network.Processor:62)
[2020-01-15 10:21:26,829] DEBUG Closing selector connection 127.0.0.1:59197-127.0.0.1:59200-2 (kafka.network.Processor:62)
[2020-01-15 10:21:26,829] DEBUG Closing selector connection 127.0.0.1:59197-127.0.0.1:59202-4 (kafka.network.Processor:62)
[2020-01-15 10:21:26,829] DEBUG Closing selector connection 127.0.0.1:59197-127.0.0.1:59198-0 (kafka.network.Processor:62)
[2020-01-15 10:21:26,829] DEBUG Closing selector connection 127.0.0.1:59197-127.0.0.1:59201-3 (kafka.network.Processor:62)
[2020-01-15 10:21:26,829] DEBUG Closing selector connection 127.0.0.1:59197-127.0.0.1:59199-1 (kafka.network.Processor:62)
[2020-01-15 10:21:26,830] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:26,834] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer:66)
[2020-01-15 10:21:27,189] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 60000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1500
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = SSL://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/b3/bhnnh3l53jjdfgphtx91qd1h0000gn/T/kafka-4943174210149424743
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections = 2147483647
	max.connections.per.ip = 5
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 1
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 50
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1500
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = SSL
	security.providers = null
	socket.receive.buffer.bytes = 300000
	socket.request.max.bytes = 100
	socket.send.buffer.bytes = 300000
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = [hidden]
	ssl.keymanager.algorithm = PKIX
	ssl.keystore.location = /var/folders/b3/bhnnh3l53jjdfgphtx91qd1h0000gn/T/serverKS950990399455336936.jks
	ssl.keystore.password = [hidden]
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = /var/folders/b3/bhnnh3l53jjdfgphtx91qd1h0000gn/T/truststore668567431729164359.jks
	ssl.truststore.password = [hidden]
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:1
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig:347)
[2020-01-15 10:21:27,199] INFO Awaiting socket connections on localhost:59223. (kafka.network.Acceptor:66)
[2020-01-15 10:21:27,258] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(localhost,0,ListenerName(SSL),SSL) (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:27,258] DEBUG [SocketServer brokerId=0] Wait for authorizer to complete start up on listener ListenerName(SSL) (kafka.network.SocketServerTest$TestableSocketServer:62)
[2020-01-15 10:21:27,258] DEBUG [SocketServer brokerId=0] Start processors on listener ListenerName(SSL) (kafka.network.SocketServerTest$TestableSocketServer:62)
[2020-01-15 10:21:27,258] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:27,259] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:27,260] DEBUG Accepted connection from /127.0.0.1:59228 on /127.0.0.1:59223 and assigned it to processor 0, sendBufferSize [actual|requested]: [300000|300000] recvBufferSize [actual|requested]: [310308|300000] (kafka.network.Acceptor:62)
[2020-01-15 10:21:27,260] DEBUG Processor 0 listening to new connection from /127.0.0.1:59228 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:27,286] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:27,388] TRACE Not sending PRODUCE response to client  as it's not required. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:27,389] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response: from connection 127.0.0.1:59223-127.0.0.1:59228-0;totalTime:102.651,requestQueueTime:0.0,localTime:6.1089124877E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.499,sendTime:0.012,securityProtocol:SSL,principal:User:ANONYMOUS,listener:SSL,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:27,389] TRACE Socket server received empty response to send, registering for read: Response(type=NoOp, request=Request(processor=0, connectionId=127.0.0.1:59223-127.0.0.1:59228-0, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(SSL), securityProtocol=SSL, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22])) (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:54)
[2020-01-15 10:21:27,389] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:27,390] DEBUG Accepted connection from /127.0.0.1:59241 on /127.0.0.1:59223 and assigned it to processor 0, sendBufferSize [actual|requested]: [300000|300000] recvBufferSize [actual|requested]: [310308|300000] (kafka.network.Acceptor:62)
[2020-01-15 10:21:27,390] DEBUG Processor 0 listening to new connection from /127.0.0.1:59241 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:27,401] TRACE Sending PRODUCE response to client  of 26 bytes. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:27,401] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:27,401] TRACE Sending PRODUCE response to client  of 26 bytes. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:27,401] TRACE Socket server received response to send to 127.0.0.1:59223-127.0.0.1:59228-0, registering for write and sending data: Response(type=Send, request=Request(processor=0, connectionId=127.0.0.1:59223-127.0.0.1:59228-0, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(SSL), securityProtocol=SSL, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22]), send=org.apache.kafka.common.network.NetworkSend@42f9748, asString=Some(RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1))) (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:54)
[2020-01-15 10:21:27,402] TRACE Socket server received response to send to 127.0.0.1:59223-127.0.0.1:59241-1, registering for write and sending data: Response(type=Send, request=Request(processor=0, connectionId=127.0.0.1:59223-127.0.0.1:59241-1, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(SSL), securityProtocol=SSL, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22]), send=org.apache.kafka.common.network.NetworkSend@412d09a9, asString=Some(RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1))) (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:54)
[2020-01-15 10:21:27,402] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) from connection 127.0.0.1:59223-127.0.0.1:59241-1;totalTime:0.938,requestQueueTime:0.0,localTime:6.1089138276E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.281,sendTime:0.278,securityProtocol:SSL,principal:User:ANONYMOUS,listener:SSL,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:27,402] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) from connection 127.0.0.1:59223-127.0.0.1:59228-0;totalTime:12.977,requestQueueTime:0.0,localTime:6.1089137861E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.393,sendTime:0.746,securityProtocol:SSL,principal:User:ANONYMOUS,listener:SSL,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:27,502] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:27,502] TRACE Sending PRODUCE response to client  of 26 bytes. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:27,503] TRACE Socket server received response to send to 127.0.0.1:59223-127.0.0.1:59241-1, registering for write and sending data: Response(type=Send, request=Request(processor=0, connectionId=127.0.0.1:59223-127.0.0.1:59241-1, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(SSL), securityProtocol=SSL, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22]), send=org.apache.kafka.common.network.NetworkSend@70aa1b88, asString=Some(RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1))) (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:54)
[2020-01-15 10:21:27,503] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) from connection 127.0.0.1:59223-127.0.0.1:59241-1;totalTime:1.013,requestQueueTime:0.0,localTime:6.1089239162E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.442,sendTime:0.372,securityProtocol:SSL,principal:User:ANONYMOUS,listener:SSL,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:27,604] DEBUG Accepted connection from /127.0.0.1:59251 on /127.0.0.1:59223 and assigned it to processor 0, sendBufferSize [actual|requested]: [300000|300000] recvBufferSize [actual|requested]: [310308|300000] (kafka.network.Acceptor:62)
[2020-01-15 10:21:27,604] DEBUG Processor 0 listening to new connection from /127.0.0.1:59251 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:27,616] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:27,616] TRACE Sending PRODUCE response to client  of 26 bytes. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:27,616] TRACE Socket server received response to send to 127.0.0.1:59223-127.0.0.1:59251-2, registering for write and sending data: Response(type=Send, request=Request(processor=0, connectionId=127.0.0.1:59223-127.0.0.1:59251-2, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(SSL), securityProtocol=SSL, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22]), send=org.apache.kafka.common.network.NetworkSend@8cbc617, asString=Some(RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1))) (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:54)
[2020-01-15 10:21:27,617] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) from connection 127.0.0.1:59223-127.0.0.1:59251-2;totalTime:0.766,requestQueueTime:0.0,localTime:6.1089353003E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.331,sendTime:0.191,securityProtocol:SSL,principal:User:ANONYMOUS,listener:SSL,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:27,719] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:27,719] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:27,719] DEBUG Closing server socket and selector. (kafka.network.Acceptor:62)
[2020-01-15 10:21:27,720] DEBUG Closing selector - processor 0 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:27,720] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:27,723] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:27,723] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer:66)
[2020-01-15 10:21:27,724] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:27,724] DEBUG Closing server socket and selector. (kafka.network.Acceptor:62)
[2020-01-15 10:21:27,724] DEBUG Closing selector - processor 0 (kafka.network.Processor:62)
[2020-01-15 10:21:27,724] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:27,728] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer:66)
[2020-01-15 10:21:27,736] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 110
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1500
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/b3/bhnnh3l53jjdfgphtx91qd1h0000gn/T/kafka-8704872036050775194
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1500
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:1
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig:347)
[2020-01-15 10:21:27,742] INFO Awaiting socket connections on localhost:59268. (kafka.network.Acceptor:66)
[2020-01-15 10:21:27,744] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(localhost,0,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer:66)
[2020-01-15 10:21:27,744] DEBUG [SocketServer brokerId=0] Wait for authorizer to complete start up on listener ListenerName(PLAINTEXT) (kafka.network.SocketServer:62)
[2020-01-15 10:21:27,744] DEBUG [SocketServer brokerId=0] Start processors on listener ListenerName(PLAINTEXT) (kafka.network.SocketServer:62)
[2020-01-15 10:21:27,744] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServer:66)
[2020-01-15 10:21:27,745] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer:66)
[2020-01-15 10:21:27,746] DEBUG Accepted connection from /127.0.0.1:59269 on /127.0.0.1:59268 and assigned it to processor 0, sendBufferSize [actual|requested]: [102400|102400] recvBufferSize [actual|requested]: [375636|102400] (kafka.network.Acceptor:62)
[2020-01-15 10:21:27,746] DEBUG Processor 0 listening to new connection from /127.0.0.1:59269 (kafka.network.Processor:62)
[2020-01-15 10:21:27,746] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:28,058] TRACE Sending PRODUCE response to client  of 26 bytes. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:28,059] TRACE Socket server received response to send to 127.0.0.1:59268-127.0.0.1:59269-0, registering for write and sending data: Response(type=Send, request=Request(processor=0, connectionId=127.0.0.1:59268-127.0.0.1:59269-0, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(PLAINTEXT), securityProtocol=PLAINTEXT, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22]), send=org.apache.kafka.common.network.NetworkSend@2a5b8b0b, asString=Some(RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1))) (kafka.network.Processor:54)
[2020-01-15 10:21:28,059] WARN Attempting to send response via channel for which there is no open connection, connection id 127.0.0.1:59268-127.0.0.1:59269-0 (kafka.network.Processor:70)
[2020-01-15 10:21:28,059] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) from connection 127.0.0.1:59268-127.0.0.1:59269-0;totalTime:313.215,requestQueueTime:0.0,localTime:6.1089795051E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.454,sendTime:0.578,securityProtocol:PLAINTEXT,principal:User:ANONYMOUS,listener:PLAINTEXT,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:28,161] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer:66)
[2020-01-15 10:21:28,162] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:28,162] DEBUG Closing server socket and selector. (kafka.network.Acceptor:62)
[2020-01-15 10:21:28,162] DEBUG Closing selector - processor 0 (kafka.network.Processor:62)
[2020-01-15 10:21:28,162] DEBUG Closing selector - processor 1 (kafka.network.Processor:62)
[2020-01-15 10:21:28,163] DEBUG Closing selector - processor 2 (kafka.network.Processor:62)
[2020-01-15 10:21:28,163] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:28,167] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer:66)
[2020-01-15 10:21:28,167] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer:66)
[2020-01-15 10:21:28,167] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:28,167] DEBUG Closing server socket and selector. (kafka.network.Acceptor:62)
[2020-01-15 10:21:28,168] DEBUG Closing selector - processor 0 (kafka.network.Processor:62)
[2020-01-15 10:21:28,168] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:28,171] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer:66)
[2020-01-15 10:21:28,184] DEBUG Accepted connection from /127.0.0.1:59322 on /127.0.0.1:59321 and assigned it to processor 0, sendBufferSize [actual|requested]: [300000|300000] recvBufferSize [actual|requested]: [310308|300000] (kafka.network.Acceptor:62)
[2020-01-15 10:21:28,184] DEBUG Processor 0 listening to new connection from /127.0.0.1:59322 (kafka.network.Processor:62)
[2020-01-15 10:21:28,185] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:28,185] TRACE Not sending PRODUCE response to client  as it's not required. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:28,186] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response: from connection 127.0.0.1:59321-127.0.0.1:59322-0;totalTime:0.489,requestQueueTime:0.0,localTime:6.1089921966E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.318,sendTime:0.001,securityProtocol:PLAINTEXT,principal:User:ANONYMOUS,listener:PLAINTEXT,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:28,186] TRACE Socket server received empty response to send, registering for read: Response(type=NoOp, request=Request(processor=0, connectionId=127.0.0.1:59321-127.0.0.1:59322-0, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(PLAINTEXT), securityProtocol=PLAINTEXT, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22])) (kafka.network.Processor:54)
[2020-01-15 10:21:28,186] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:28,186] TRACE Not sending PRODUCE response to client  as it's not required. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:28,186] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response: from connection 127.0.0.1:59321-127.0.0.1:59322-0;totalTime:0.375,requestQueueTime:0.0,localTime:6.1089922769E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.216,sendTime:0.0,securityProtocol:PLAINTEXT,principal:User:ANONYMOUS,listener:PLAINTEXT,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:28,186] TRACE Socket server received empty response to send, registering for read: Response(type=NoOp, request=Request(processor=0, connectionId=127.0.0.1:59321-127.0.0.1:59322-0, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(PLAINTEXT), securityProtocol=PLAINTEXT, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22])) (kafka.network.Processor:54)
[2020-01-15 10:21:28,186] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:28,186] TRACE Not sending PRODUCE response to client  as it's not required. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:28,187] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response: from connection 127.0.0.1:59321-127.0.0.1:59322-0;totalTime:0.276,requestQueueTime:0.0,localTime:6.1089923294E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.199,sendTime:0.0,securityProtocol:PLAINTEXT,principal:User:ANONYMOUS,listener:PLAINTEXT,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:28,187] TRACE Socket server received empty response to send, registering for read: Response(type=NoOp, request=Request(processor=0, connectionId=127.0.0.1:59321-127.0.0.1:59322-0, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(PLAINTEXT), securityProtocol=PLAINTEXT, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22])) (kafka.network.Processor:54)
[2020-01-15 10:21:28,187] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer:66)
[2020-01-15 10:21:28,187] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:28,187] DEBUG Closing server socket and selector. (kafka.network.Acceptor:62)
[2020-01-15 10:21:28,188] DEBUG Closing selector - processor 0 (kafka.network.Processor:62)
[2020-01-15 10:21:28,188] DEBUG Closing selector connection 127.0.0.1:59321-127.0.0.1:59322-0 (kafka.network.Processor:62)
[2020-01-15 10:21:28,188] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:28,192] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer:66)
[2020-01-15 10:21:28,199] DEBUG Accepted connection from /127.0.0.1:59324 on /127.0.0.1:59323 and assigned it to processor 0, sendBufferSize [actual|requested]: [300000|300000] recvBufferSize [actual|requested]: [310308|300000] (kafka.network.Acceptor:62)
[2020-01-15 10:21:28,199] DEBUG Processor 0 listening to new connection from /127.0.0.1:59324 (kafka.network.Processor:62)
[2020-01-15 10:21:28,199] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:28,199] TRACE Sending PRODUCE response to client  of 26 bytes. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:28,200] TRACE Socket server received response to send to 127.0.0.1:59323-127.0.0.1:59324-0, registering for write and sending data: Response(type=Send, request=Request(processor=0, connectionId=127.0.0.1:59323-127.0.0.1:59324-0, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(PLAINTEXT), securityProtocol=PLAINTEXT, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22]), send=org.apache.kafka.common.network.NetworkSend@3b08ce91, asString=Some(RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1))) (kafka.network.Processor:54)
[2020-01-15 10:21:28,200] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) from connection 127.0.0.1:59323-127.0.0.1:59324-0;totalTime:0.653,requestQueueTime:0.0,localTime:6.1089936384E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.192,sendTime:0.286,securityProtocol:PLAINTEXT,principal:User:ANONYMOUS,listener:PLAINTEXT,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:28,201] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer:66)
[2020-01-15 10:21:28,201] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:28,201] DEBUG Closing server socket and selector. (kafka.network.Acceptor:62)
[2020-01-15 10:21:28,201] DEBUG Closing selector - processor 0 (kafka.network.Processor:62)
[2020-01-15 10:21:28,201] DEBUG Closing selector connection 127.0.0.1:59323-127.0.0.1:59324-0 (kafka.network.Processor:62)
[2020-01-15 10:21:28,202] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:28,205] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer:66)
[2020-01-15 10:21:28,213] DEBUG Accepted connection from /127.0.0.1:59329 on /127.0.0.1:59328 and assigned it to processor 0, sendBufferSize [actual|requested]: [300000|300000] recvBufferSize [actual|requested]: [310308|300000] (kafka.network.Acceptor:62)
[2020-01-15 10:21:28,213] DEBUG Processor 0 listening to new connection from /127.0.0.1:59329 (kafka.network.Processor:62)
[2020-01-15 10:21:28,214] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:28,214] TRACE Notifying channel throttling has started for client  for PRODUCE (kafka.network.RequestChannel:54)
[2020-01-15 10:21:28,214] TRACE Sending PRODUCE response to client  of 26 bytes. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:28,214] TRACE Socket server received response to send to 127.0.0.1:59328-127.0.0.1:59329-0, registering for write and sending data: Response(type=Send, request=Request(processor=0, connectionId=127.0.0.1:59328-127.0.0.1:59329-0, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(PLAINTEXT), securityProtocol=PLAINTEXT, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22]), send=org.apache.kafka.common.network.NetworkSend@1545351, asString=Some(RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1))) (kafka.network.Processor:54)
[2020-01-15 10:21:28,215] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) from connection 127.0.0.1:59328-127.0.0.1:59329-0;totalTime:0.808,requestQueueTime:0.0,localTime:6.1089950758E7,remoteTime:0.248,throttleTime:0.0,responseQueueTime:0.182,sendTime:0.191,securityProtocol:PLAINTEXT,principal:User:ANONYMOUS,listener:PLAINTEXT,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:28,316] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer:66)
[2020-01-15 10:21:28,316] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:28,316] DEBUG Closing server socket and selector. (kafka.network.Acceptor:62)
[2020-01-15 10:21:28,316] DEBUG Closing selector - processor 0 (kafka.network.Processor:62)
[2020-01-15 10:21:28,316] DEBUG Closing selector connection 127.0.0.1:59328-127.0.0.1:59329-0 (kafka.network.Processor:62)
[2020-01-15 10:21:28,317] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:28,320] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer:66)
[2020-01-15 10:21:28,367] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 60000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1500
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/b3/bhnnh3l53jjdfgphtx91qd1h0000gn/T/kafka-7908788210945278285
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections = 2147483647
	max.connections.per.ip = 5
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 1
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 50
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1500
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 300000
	socket.request.max.bytes = 100
	socket.send.buffer.bytes = 300000
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:1
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig:347)
[2020-01-15 10:21:28,371] INFO Awaiting socket connections on localhost:59342. (kafka.network.Acceptor:66)
[2020-01-15 10:21:28,371] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(localhost,0,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer:66)
[2020-01-15 10:21:28,372] DEBUG [SocketServer brokerId=0] Wait for authorizer to complete start up on listener ListenerName(PLAINTEXT) (kafka.network.SocketServer:62)
[2020-01-15 10:21:28,372] DEBUG [SocketServer brokerId=0] Start processors on listener ListenerName(PLAINTEXT) (kafka.network.SocketServer:62)
[2020-01-15 10:21:28,372] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServer:66)
[2020-01-15 10:21:28,372] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer:66)
[2020-01-15 10:21:28,373] DEBUG Accepted connection from /127.0.0.1:59343 on /127.0.0.1:59342 and assigned it to processor 0, sendBufferSize [actual|requested]: [300000|300000] recvBufferSize [actual|requested]: [310308|300000] (kafka.network.Acceptor:62)
[2020-01-15 10:21:28,373] DEBUG Processor 0 listening to new connection from /127.0.0.1:59343 (kafka.network.Processor:62)
[2020-01-15 10:21:28,374] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:28,374] TRACE Sending PRODUCE response to client  of 26 bytes. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:28,374] TRACE Socket server received response to send to 127.0.0.1:59342-127.0.0.1:59343-0, registering for write and sending data: Response(type=Send, request=Request(processor=0, connectionId=127.0.0.1:59342-127.0.0.1:59343-0, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(PLAINTEXT), securityProtocol=PLAINTEXT, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22]), send=org.apache.kafka.common.network.NetworkSend@3f7d872e, asString=Some(RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1))) (kafka.network.Processor:54)
[2020-01-15 10:21:28,374] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) from connection 127.0.0.1:59342-127.0.0.1:59343-0;totalTime:7.62,requestQueueTime:0.0,localTime:6.1090110747E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.261,sendTime:0.248,securityProtocol:PLAINTEXT,principal:User:ANONYMOUS,listener:PLAINTEXT,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:28,685] DEBUG Accepted connection from /127.0.0.1:59371 on /127.0.0.1:59342 and assigned it to processor 0, sendBufferSize [actual|requested]: [300000|300000] recvBufferSize [actual|requested]: [310308|300000] (kafka.network.Acceptor:62)
[2020-01-15 10:21:28,685] DEBUG Processor 0 listening to new connection from /127.0.0.1:59371 (kafka.network.Processor:62)
[2020-01-15 10:21:28,686] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:28,992] TRACE Sending PRODUCE response to client  of 26 bytes. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:28,992] TRACE Socket server received response to send to 127.0.0.1:59342-127.0.0.1:59371-1, registering for write and sending data: Response(type=Send, request=Request(processor=0, connectionId=127.0.0.1:59342-127.0.0.1:59371-1, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(PLAINTEXT), securityProtocol=PLAINTEXT, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22]), send=org.apache.kafka.common.network.NetworkSend@7e408d15, asString=Some(RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1))) (kafka.network.Processor:54)
[2020-01-15 10:21:28,992] WARN Attempting to send response via channel for which there is no open connection, connection id 127.0.0.1:59342-127.0.0.1:59371-1 (kafka.network.Processor:70)
[2020-01-15 10:21:28,992] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) from connection 127.0.0.1:59342-127.0.0.1:59371-1;totalTime:0.0,requestQueueTime:0.0,localTime:6.1090728674E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.262,sendTime:0.32,securityProtocol:PLAINTEXT,principal:User:ANONYMOUS,listener:PLAINTEXT,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:28,993] DEBUG Accepted connection from /127.0.0.1:59391 on /127.0.0.1:59342 and assigned it to processor 0, sendBufferSize [actual|requested]: [300000|300000] recvBufferSize [actual|requested]: [310308|300000] (kafka.network.Acceptor:62)
[2020-01-15 10:21:28,993] DEBUG Processor 0 listening to new connection from /127.0.0.1:59391 (kafka.network.Processor:62)
[2020-01-15 10:21:28,993] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:29,303] TRACE Sending PRODUCE response to client  of 26 bytes. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:29,304] TRACE Socket server received response to send to 127.0.0.1:59342-127.0.0.1:59391-2, registering for write and sending data: Response(type=Send, request=Request(processor=0, connectionId=127.0.0.1:59342-127.0.0.1:59391-2, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(PLAINTEXT), securityProtocol=PLAINTEXT, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22]), send=org.apache.kafka.common.network.NetworkSend@4f74d4d6, asString=Some(RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1))) (kafka.network.Processor:54)
[2020-01-15 10:21:29,304] WARN Attempting to send response via channel for which there is no open connection, connection id 127.0.0.1:59342-127.0.0.1:59391-2 (kafka.network.Processor:70)
[2020-01-15 10:21:29,304] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) from connection 127.0.0.1:59342-127.0.0.1:59391-2;totalTime:0.0,requestQueueTime:0.0,localTime:6.1091039742E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.844,sendTime:0.28,securityProtocol:PLAINTEXT,principal:User:ANONYMOUS,listener:PLAINTEXT,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:29,504] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer:66)
[2020-01-15 10:21:29,504] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:29,505] DEBUG Closing server socket and selector. (kafka.network.Acceptor:62)
[2020-01-15 10:21:29,505] DEBUG Closing selector - processor 0 (kafka.network.Processor:62)
[2020-01-15 10:21:29,505] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:29,508] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer:66)
[2020-01-15 10:21:29,508] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer:66)
[2020-01-15 10:21:29,509] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:29,509] DEBUG Closing server socket and selector. (kafka.network.Acceptor:62)
[2020-01-15 10:21:29,509] DEBUG Closing selector - processor 0 (kafka.network.Processor:62)
[2020-01-15 10:21:29,509] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:29,512] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer:66)
[2020-01-15 10:21:29,585] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 60000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1500
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = SSL://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/b3/bhnnh3l53jjdfgphtx91qd1h0000gn/T/kafka-4531879738770085783
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections = 2147483647
	max.connections.per.ip = 5
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 1
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 50
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1500
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = SSL
	security.providers = null
	socket.receive.buffer.bytes = 300000
	socket.request.max.bytes = 100
	socket.send.buffer.bytes = 300000
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = [hidden]
	ssl.keymanager.algorithm = PKIX
	ssl.keystore.location = /var/folders/b3/bhnnh3l53jjdfgphtx91qd1h0000gn/T/serverKS263484473251192468.jks
	ssl.keystore.password = [hidden]
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = /var/folders/b3/bhnnh3l53jjdfgphtx91qd1h0000gn/T/truststore1692037346431145995.jks
	ssl.truststore.password = [hidden]
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:1
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig:347)
[2020-01-15 10:21:29,591] INFO Awaiting socket connections on localhost:59422. (kafka.network.Acceptor:66)
[2020-01-15 10:21:29,611] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(localhost,0,ListenerName(SSL),SSL) (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:29,611] DEBUG [SocketServer brokerId=0] Wait for authorizer to complete start up on listener ListenerName(SSL) (kafka.network.SocketServerTest$TestableSocketServer:62)
[2020-01-15 10:21:29,612] DEBUG [SocketServer brokerId=0] Start processors on listener ListenerName(SSL) (kafka.network.SocketServerTest$TestableSocketServer:62)
[2020-01-15 10:21:29,612] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:29,612] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:29,614] DEBUG Accepted connection from /127.0.0.1:59428 on /127.0.0.1:59422 and assigned it to processor 0, sendBufferSize [actual|requested]: [300000|300000] recvBufferSize [actual|requested]: [310308|300000] (kafka.network.Acceptor:62)
[2020-01-15 10:21:29,614] DEBUG Processor 0 listening to new connection from /127.0.0.1:59428 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:29,638] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:29,742] TRACE Not sending PRODUCE response to client  as it's not required. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:29,747] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response: from connection 127.0.0.1:59422-127.0.0.1:59428-0;totalTime:104.35,requestQueueTime:0.0,localTime:6.1091478875E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.536,sendTime:0.019,securityProtocol:SSL,principal:User:ANONYMOUS,listener:SSL,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:29,747] TRACE Socket server received empty response to send, registering for read: Response(type=NoOp, request=Request(processor=0, connectionId=127.0.0.1:59422-127.0.0.1:59428-0, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(SSL), securityProtocol=SSL, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22])) (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:54)
[2020-01-15 10:21:29,844] DEBUG Accepted connection from /127.0.0.1:59437 on /127.0.0.1:59422 and assigned it to processor 0, sendBufferSize [actual|requested]: [300000|300000] recvBufferSize [actual|requested]: [310308|300000] (kafka.network.Acceptor:62)
[2020-01-15 10:21:29,844] DEBUG Processor 0 listening to new connection from /127.0.0.1:59437 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:29,851] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:29,852] TRACE Sending PRODUCE response to client  of 26 bytes. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:29,852] TRACE Socket server received response to send to 127.0.0.1:59422-127.0.0.1:59437-1, registering for write and sending data: Response(type=Send, request=Request(processor=0, connectionId=127.0.0.1:59422-127.0.0.1:59437-1, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(SSL), securityProtocol=SSL, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22]), send=org.apache.kafka.common.network.NetworkSend@4f7f9746, asString=Some(RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1))) (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:54)
[2020-01-15 10:21:29,852] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) from connection 127.0.0.1:59422-127.0.0.1:59437-1;totalTime:0.879,requestQueueTime:0.0,localTime:6.1091588463E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.359,sendTime:0.302,securityProtocol:SSL,principal:User:ANONYMOUS,listener:SSL,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:29,953] DEBUG Accepted connection from /127.0.0.1:59443 on /127.0.0.1:59422 and assigned it to processor 0, sendBufferSize [actual|requested]: [300000|300000] recvBufferSize [actual|requested]: [310308|300000] (kafka.network.Acceptor:62)
[2020-01-15 10:21:29,953] DEBUG Processor 0 listening to new connection from /127.0.0.1:59443 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:29,961] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:29,961] TRACE Sending PRODUCE response to client  of 26 bytes. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:29,962] TRACE Socket server received response to send to 127.0.0.1:59422-127.0.0.1:59443-2, registering for write and sending data: Response(type=Send, request=Request(processor=0, connectionId=127.0.0.1:59422-127.0.0.1:59443-2, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(SSL), securityProtocol=SSL, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22]), send=org.apache.kafka.common.network.NetworkSend@70613bf8, asString=Some(RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1))) (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:54)
[2020-01-15 10:21:29,962] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) from connection 127.0.0.1:59422-127.0.0.1:59443-2;totalTime:0.824,requestQueueTime:0.0,localTime:6.1091698183E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.332,sendTime:0.251,securityProtocol:SSL,principal:User:ANONYMOUS,listener:SSL,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:30,064] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:30,064] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:30,065] DEBUG Closing server socket and selector. (kafka.network.Acceptor:62)
[2020-01-15 10:21:30,065] DEBUG Closing selector - processor 0 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:30,065] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:30,069] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:30,069] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer:66)
[2020-01-15 10:21:30,069] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:30,069] DEBUG Closing server socket and selector. (kafka.network.Acceptor:62)
[2020-01-15 10:21:30,069] DEBUG Closing selector - processor 0 (kafka.network.Processor:62)
[2020-01-15 10:21:30,070] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:30,072] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer:66)
[2020-01-15 10:21:30,389] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 60000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1500
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = SSL://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/b3/bhnnh3l53jjdfgphtx91qd1h0000gn/T/kafka-6641449701592983322
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections = 2147483647
	max.connections.per.ip = 5
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 1
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 50
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1500
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = SSL
	security.providers = null
	socket.receive.buffer.bytes = 300000
	socket.request.max.bytes = 100
	socket.send.buffer.bytes = 300000
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = [hidden]
	ssl.keymanager.algorithm = PKIX
	ssl.keystore.location = /var/folders/b3/bhnnh3l53jjdfgphtx91qd1h0000gn/T/serverKS3845754002986574349.jks
	ssl.keystore.password = [hidden]
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = /var/folders/b3/bhnnh3l53jjdfgphtx91qd1h0000gn/T/truststore1258126721965874921.jks
	ssl.truststore.password = [hidden]
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:1
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig:347)
[2020-01-15 10:21:30,394] INFO Awaiting socket connections on localhost:59462. (kafka.network.Acceptor:66)
[2020-01-15 10:21:30,413] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(localhost,0,ListenerName(SSL),SSL) (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:30,413] DEBUG [SocketServer brokerId=0] Wait for authorizer to complete start up on listener ListenerName(SSL) (kafka.network.SocketServerTest$TestableSocketServer:62)
[2020-01-15 10:21:30,413] DEBUG [SocketServer brokerId=0] Start processors on listener ListenerName(SSL) (kafka.network.SocketServerTest$TestableSocketServer:62)
[2020-01-15 10:21:30,414] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:30,414] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:30,416] DEBUG Accepted connection from /127.0.0.1:59464 on /127.0.0.1:59462 and assigned it to processor 0, sendBufferSize [actual|requested]: [300000|300000] recvBufferSize [actual|requested]: [310308|300000] (kafka.network.Acceptor:62)
[2020-01-15 10:21:30,416] DEBUG Processor 0 listening to new connection from /127.0.0.1:59464 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:30,437] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:30,541] TRACE Not sending PRODUCE response to client  as it's not required. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:30,542] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response: from connection 127.0.0.1:59462-127.0.0.1:59464-0;totalTime:104.557,requestQueueTime:0.0,localTime:6.1092278032E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.705,sendTime:0.004,securityProtocol:SSL,principal:User:ANONYMOUS,listener:SSL,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:30,542] TRACE Socket server received empty response to send, registering for read: Response(type=NoOp, request=Request(processor=0, connectionId=127.0.0.1:59462-127.0.0.1:59464-0, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(SSL), securityProtocol=SSL, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22])) (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:54)
[2020-01-15 10:21:30,543] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:30,543] TRACE Not sending PRODUCE response to client  as it's not required. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:30,543] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response: from connection 127.0.0.1:59462-127.0.0.1:59464-0;totalTime:0.545,requestQueueTime:0.0,localTime:6.1092279921E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.387,sendTime:0.0,securityProtocol:SSL,principal:User:ANONYMOUS,listener:SSL,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:30,544] TRACE Socket server received empty response to send, registering for read: Response(type=NoOp, request=Request(processor=0, connectionId=127.0.0.1:59462-127.0.0.1:59464-0, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(SSL), securityProtocol=SSL, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22])) (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:54)
[2020-01-15 10:21:30,544] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:30,544] TRACE Not sending PRODUCE response to client  as it's not required. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:30,544] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response: from connection 127.0.0.1:59462-127.0.0.1:59464-0;totalTime:0.45,requestQueueTime:0.0,localTime:6.1092280778E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.258,sendTime:0.0,securityProtocol:SSL,principal:User:ANONYMOUS,listener:SSL,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:30,544] TRACE Socket server received empty response to send, registering for read: Response(type=NoOp, request=Request(processor=0, connectionId=127.0.0.1:59462-127.0.0.1:59464-0, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(SSL), securityProtocol=SSL, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22])) (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:54)
[2020-01-15 10:21:30,544] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:30,545] TRACE Not sending PRODUCE response to client  as it's not required. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:30,545] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response: from connection 127.0.0.1:59462-127.0.0.1:59464-0;totalTime:0.842,requestQueueTime:0.0,localTime:6.1092281895E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.267,sendTime:0.024,securityProtocol:SSL,principal:User:ANONYMOUS,listener:SSL,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:30,546] TRACE Socket server received empty response to send, registering for read: Response(type=NoOp, request=Request(processor=0, connectionId=127.0.0.1:59462-127.0.0.1:59464-0, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(SSL), securityProtocol=SSL, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22])) (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:54)
[2020-01-15 10:21:30,649] DEBUG Accepted connection from /127.0.0.1:59475 on /127.0.0.1:59462 and assigned it to processor 0, sendBufferSize [actual|requested]: [300000|300000] recvBufferSize [actual|requested]: [310308|300000] (kafka.network.Acceptor:62)
[2020-01-15 10:21:30,649] DEBUG Processor 0 listening to new connection from /127.0.0.1:59475 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:30,656] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:30,656] TRACE Sending PRODUCE response to client  of 26 bytes. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:30,657] TRACE Socket server received response to send to 127.0.0.1:59462-127.0.0.1:59475-1, registering for write and sending data: Response(type=Send, request=Request(processor=0, connectionId=127.0.0.1:59462-127.0.0.1:59475-1, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(SSL), securityProtocol=SSL, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22]), send=org.apache.kafka.common.network.NetworkSend@2ed56c8b, asString=Some(RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1))) (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:54)
[2020-01-15 10:21:30,657] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) from connection 127.0.0.1:59462-127.0.0.1:59475-1;totalTime:0.77,requestQueueTime:0.0,localTime:6.1092393085E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.282,sendTime:0.248,securityProtocol:SSL,principal:User:ANONYMOUS,listener:SSL,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:30,759] DEBUG Accepted connection from /127.0.0.1:59483 on /127.0.0.1:59462 and assigned it to processor 0, sendBufferSize [actual|requested]: [300000|300000] recvBufferSize [actual|requested]: [310308|300000] (kafka.network.Acceptor:62)
[2020-01-15 10:21:30,759] DEBUG Processor 0 listening to new connection from /127.0.0.1:59483 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:30,766] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:30,766] TRACE Sending PRODUCE response to client  of 26 bytes. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:30,767] TRACE Socket server received response to send to 127.0.0.1:59462-127.0.0.1:59483-2, registering for write and sending data: Response(type=Send, request=Request(processor=0, connectionId=127.0.0.1:59462-127.0.0.1:59483-2, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(SSL), securityProtocol=SSL, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22]), send=org.apache.kafka.common.network.NetworkSend@2789276b, asString=Some(RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1))) (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:54)
[2020-01-15 10:21:30,767] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) from connection 127.0.0.1:59462-127.0.0.1:59483-2;totalTime:0.751,requestQueueTime:0.0,localTime:6.1092503384E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.316,sendTime:0.236,securityProtocol:SSL,principal:User:ANONYMOUS,listener:SSL,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:30,871] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:30,871] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:30,871] DEBUG Closing server socket and selector. (kafka.network.Acceptor:62)
[2020-01-15 10:21:30,872] DEBUG Closing selector - processor 0 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:30,872] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:30,876] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:30,876] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer:66)
[2020-01-15 10:21:30,877] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:30,877] DEBUG Closing server socket and selector. (kafka.network.Acceptor:62)
[2020-01-15 10:21:30,878] DEBUG Closing selector - processor 0 (kafka.network.Processor:62)
[2020-01-15 10:21:30,878] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:30,882] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer:66)
[2020-01-15 10:21:30,890] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1500
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/b3/bhnnh3l53jjdfgphtx91qd1h0000gn/T/kafka-6817870297983580040
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections = 2147483647
	max.connections.per.ip = 0
	max.connections.per.ip.overrides = 127.0.0.1:5
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1500
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:1
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig:347)
[2020-01-15 10:21:30,895] INFO Awaiting socket connections on localhost:59492. (kafka.network.Acceptor:66)
[2020-01-15 10:21:30,896] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(localhost,0,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer:66)
[2020-01-15 10:21:30,896] DEBUG [SocketServer brokerId=0] Wait for authorizer to complete start up on listener ListenerName(PLAINTEXT) (kafka.network.SocketServer:62)
[2020-01-15 10:21:30,896] DEBUG [SocketServer brokerId=0] Start processors on listener ListenerName(PLAINTEXT) (kafka.network.SocketServer:62)
[2020-01-15 10:21:30,897] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServer:66)
[2020-01-15 10:21:30,897] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer:66)
[2020-01-15 10:21:30,898] DEBUG Accepted connection from /127.0.0.1:59493 on /127.0.0.1:59492 and assigned it to processor 0, sendBufferSize [actual|requested]: [102400|102400] recvBufferSize [actual|requested]: [375636|102400] (kafka.network.Acceptor:62)
[2020-01-15 10:21:30,898] DEBUG Processor 0 listening to new connection from /127.0.0.1:59493 (kafka.network.Processor:62)
[2020-01-15 10:21:30,899] DEBUG Accepted connection from /127.0.0.1:59494 on /127.0.0.1:59492 and assigned it to processor 1, sendBufferSize [actual|requested]: [102400|102400] recvBufferSize [actual|requested]: [375636|102400] (kafka.network.Acceptor:62)
[2020-01-15 10:21:30,899] DEBUG Processor 1 listening to new connection from /127.0.0.1:59494 (kafka.network.Processor:62)
[2020-01-15 10:21:30,899] DEBUG Accepted connection from /127.0.0.1:59495 on /127.0.0.1:59492 and assigned it to processor 2, sendBufferSize [actual|requested]: [102400|102400] recvBufferSize [actual|requested]: [375636|102400] (kafka.network.Acceptor:62)
[2020-01-15 10:21:30,899] DEBUG Processor 2 listening to new connection from /127.0.0.1:59495 (kafka.network.Processor:62)
[2020-01-15 10:21:30,899] DEBUG Accepted connection from /127.0.0.1:59496 on /127.0.0.1:59492 and assigned it to processor 0, sendBufferSize [actual|requested]: [102400|102400] recvBufferSize [actual|requested]: [375636|102400] (kafka.network.Acceptor:62)
[2020-01-15 10:21:30,899] DEBUG Processor 0 listening to new connection from /127.0.0.1:59496 (kafka.network.Processor:62)
[2020-01-15 10:21:30,899] DEBUG Accepted connection from /127.0.0.1:59497 on /127.0.0.1:59492 and assigned it to processor 1, sendBufferSize [actual|requested]: [102400|102400] recvBufferSize [actual|requested]: [375636|102400] (kafka.network.Acceptor:62)
[2020-01-15 10:21:30,899] DEBUG Processor 1 listening to new connection from /127.0.0.1:59497 (kafka.network.Processor:62)
[2020-01-15 10:21:30,900] INFO Rejected connection from /127.0.0.1, address already has the configured maximum of 5 connections. (kafka.network.Acceptor:66)
[2020-01-15 10:21:30,900] DEBUG Closing connection from /127.0.0.1:59498 (kafka.network.Acceptor:62)
[2020-01-15 10:21:31,005] DEBUG Accepted connection from /127.0.0.1:59503 on /127.0.0.1:59492 and assigned it to processor 2, sendBufferSize [actual|requested]: [102400|102400] recvBufferSize [actual|requested]: [375636|102400] (kafka.network.Acceptor:62)
[2020-01-15 10:21:31,005] DEBUG Processor 2 listening to new connection from /127.0.0.1:59503 (kafka.network.Processor:62)
[2020-01-15 10:21:31,005] TRACE Processor 2 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:31,006] INFO Rejected connection from /127.0.0.1, address already has the configured maximum of 5 connections. (kafka.network.Acceptor:66)
[2020-01-15 10:21:31,006] DEBUG Closing connection from /127.0.0.1:59504 (kafka.network.Acceptor:62)
[2020-01-15 10:21:31,006] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer:66)
[2020-01-15 10:21:31,007] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:31,007] DEBUG Closing server socket and selector. (kafka.network.Acceptor:62)
[2020-01-15 10:21:31,007] DEBUG Closing selector - processor 0 (kafka.network.Processor:62)
[2020-01-15 10:21:31,007] DEBUG Closing selector connection 127.0.0.1:59492-127.0.0.1:59496-1 (kafka.network.Processor:62)
[2020-01-15 10:21:31,008] DEBUG Closing selector - processor 1 (kafka.network.Processor:62)
[2020-01-15 10:21:31,009] DEBUG Closing selector connection 127.0.0.1:59492-127.0.0.1:59494-0 (kafka.network.Processor:62)
[2020-01-15 10:21:31,009] DEBUG Closing selector connection 127.0.0.1:59492-127.0.0.1:59497-1 (kafka.network.Processor:62)
[2020-01-15 10:21:31,009] DEBUG Closing selector - processor 2 (kafka.network.Processor:62)
[2020-01-15 10:21:31,009] DEBUG Closing selector connection 127.0.0.1:59492-127.0.0.1:59495-0 (kafka.network.Processor:62)
[2020-01-15 10:21:31,009] DEBUG Closing selector connection 127.0.0.1:59492-127.0.0.1:59503-1 (kafka.network.Processor:62)
[2020-01-15 10:21:31,010] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:31,014] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer:66)
[2020-01-15 10:21:31,014] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer:66)
[2020-01-15 10:21:31,015] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:31,015] DEBUG Closing server socket and selector. (kafka.network.Acceptor:62)
[2020-01-15 10:21:31,015] DEBUG Closing selector - processor 0 (kafka.network.Processor:62)
[2020-01-15 10:21:31,016] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:31,018] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer:66)
[2020-01-15 10:21:31,027] DEBUG Accepted connection from /127.0.0.1:59506 on /127.0.0.1:59505 and assigned it to processor 0, sendBufferSize [actual|requested]: [300000|300000] recvBufferSize [actual|requested]: [310308|300000] (kafka.network.Acceptor:62)
[2020-01-15 10:21:31,028] DEBUG Processor 0 listening to new connection from /127.0.0.1:59506 (kafka.network.Processor:62)
[2020-01-15 10:21:31,028] TRACE Processor 0 received request: RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=clientId, correlationId=-1) -- {client_software_name=apache-kafka-java,client_software_version=2.5.0-SNAPSHOT,_tagged_fields={}} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:31,028] TRACE Not sending API_VERSIONS response to client clientId as it's not required. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:31,028] DEBUG Completed request:RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=clientId, correlationId=-1) -- {client_software_name=apache-kafka-java,client_software_version=2.5.0-SNAPSHOT,_tagged_fields={}},response: from connection 127.0.0.1:59505-127.0.0.1:59506-0;totalTime:0.429,requestQueueTime:0.0,localTime:6.1092764935E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.238,sendTime:0.001,securityProtocol:PLAINTEXT,principal:User:ANONYMOUS,listener:PLAINTEXT,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:31,028] TRACE Socket server received empty response to send, registering for read: Response(type=NoOp, request=Request(processor=0, connectionId=127.0.0.1:59505-127.0.0.1:59506-0, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(PLAINTEXT), securityProtocol=PLAINTEXT, buffer=null)) (kafka.network.Processor:54)
[2020-01-15 10:21:31,029] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:31,029] TRACE Not sending PRODUCE response to client  as it's not required. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:31,029] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response: from connection 127.0.0.1:59505-127.0.0.1:59506-0;totalTime:0.369,requestQueueTime:0.0,localTime:6.1092765619E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.212,sendTime:0.0,securityProtocol:PLAINTEXT,principal:User:ANONYMOUS,listener:PLAINTEXT,clientInformation:ClientInformation(softwareName=apache-kafka-java, softwareVersion=2.5.0-SNAPSHOT) (kafka.request.logger:205)
[2020-01-15 10:21:31,029] TRACE Socket server received empty response to send, registering for read: Response(type=NoOp, request=Request(processor=0, connectionId=127.0.0.1:59505-127.0.0.1:59506-0, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(PLAINTEXT), securityProtocol=PLAINTEXT, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22])) (kafka.network.Processor:54)
[2020-01-15 10:21:31,132] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer:66)
[2020-01-15 10:21:31,132] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:31,132] DEBUG Closing server socket and selector. (kafka.network.Acceptor:62)
[2020-01-15 10:21:31,133] DEBUG Closing selector - processor 0 (kafka.network.Processor:62)
[2020-01-15 10:21:31,133] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:31,138] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer:66)
[2020-01-15 10:21:31,147] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer:66)
[2020-01-15 10:21:31,147] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:31,147] DEBUG Closing server socket and selector. (kafka.network.Acceptor:62)
[2020-01-15 10:21:31,148] DEBUG Closing selector - processor 0 (kafka.network.Processor:62)
[2020-01-15 10:21:31,148] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:31,154] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer:66)
[2020-01-15 10:21:31,159] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer:66)
[2020-01-15 10:21:31,162] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer:66)
[2020-01-15 10:21:31,170] DEBUG Accepted connection from /127.0.0.1:59513 on /127.0.0.1:59512 and assigned it to processor 0, sendBufferSize [actual|requested]: [300000|300000] recvBufferSize [actual|requested]: [310308|300000] (kafka.network.Acceptor:62)
[2020-01-15 10:21:31,170] DEBUG Processor 0 listening to new connection from /127.0.0.1:59513 (kafka.network.Processor:62)
[2020-01-15 10:21:31,171] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=0, clientId=, correlationId=0) -- {acks=0,timeout=0,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:31,171] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer:66)
[2020-01-15 10:21:31,171] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:31,171] DEBUG Closing server socket and selector. (kafka.network.Acceptor:62)
[2020-01-15 10:21:31,172] DEBUG Closing selector - processor 0 (kafka.network.Processor:62)
[2020-01-15 10:21:31,172] DEBUG Closing selector connection 127.0.0.1:59512-127.0.0.1:59513-0 (kafka.network.Processor:62)
[2020-01-15 10:21:31,172] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:31,176] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer:66)
[2020-01-15 10:21:31,182] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 60000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1500
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/b3/bhnnh3l53jjdfgphtx91qd1h0000gn/T/kafka-1881074330238451063
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections = 2147483647
	max.connections.per.ip = 5
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 1
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 50
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1500
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 300000
	socket.request.max.bytes = 100
	socket.send.buffer.bytes = 300000
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:1
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig:347)
[2020-01-15 10:21:31,186] INFO Awaiting socket connections on localhost:59515. (kafka.network.Acceptor:66)
[2020-01-15 10:21:31,187] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(localhost,0,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:31,187] DEBUG [SocketServer brokerId=0] Wait for authorizer to complete start up on listener ListenerName(PLAINTEXT) (kafka.network.SocketServerTest$TestableSocketServer:62)
[2020-01-15 10:21:31,187] DEBUG [SocketServer brokerId=0] Start processors on listener ListenerName(PLAINTEXT) (kafka.network.SocketServerTest$TestableSocketServer:62)
[2020-01-15 10:21:31,188] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:31,189] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:31,192] DEBUG Accepted connection from /127.0.0.1:59516 on /127.0.0.1:59515 and assigned it to processor 0, sendBufferSize [actual|requested]: [300000|300000] recvBufferSize [actual|requested]: [310308|300000] (kafka.network.Acceptor:62)
[2020-01-15 10:21:31,193] DEBUG Accepted connection from /127.0.0.1:59517 on /127.0.0.1:59515 and assigned it to processor 0, sendBufferSize [actual|requested]: [300000|300000] recvBufferSize [actual|requested]: [310308|300000] (kafka.network.Acceptor:62)
[2020-01-15 10:21:31,193] DEBUG Processor 0 listening to new connection from /127.0.0.1:59516 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:31,193] DEBUG Closing connection from /127.0.0.1:59516 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:31,193] ERROR Processor 0 closed connection from /127.0.0.1:59516 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:76)
java.lang.IllegalStateException: Test exception during Register
	at kafka.network.SocketServerTest$TestableSelector.$anonfun$addFailure$1(SocketServerTest.scala:1797)
	at kafka.network.SocketServerTest$TestableSelector.addFailure(SocketServerTest.scala:1797)
	at kafka.network.SocketServerTest.$anonfun$configureNewConnectionException$1(SocketServerTest.scala:1163)
	at kafka.network.SocketServerTest.configureNewConnectionException(SocketServerTest.scala:1159)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecutor.runTestClass(JUnitTestClassExecutor.java:110)
	at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecutor.execute(JUnitTestClassExecutor.java:58)
	at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecutor.execute(JUnitTestClassExecutor.java:38)
	at org.gradle.api.internal.tasks.testing.junit.AbstractJUnitTestClassProcessor.processTestClass(AbstractJUnitTestClassProcessor.java:62)
	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.processTestClass(SuiteTestClassProcessor.java:51)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36)
	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)
	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:33)
	at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:94)
	at com.sun.proxy.$Proxy2.processTestClass(Unknown Source)
	at org.gradle.api.internal.tasks.testing.worker.TestWorker.processTestClass(TestWorker.java:118)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36)
	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)
	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:182)
	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:164)
	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:412)
	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:64)
	at org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:48)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at org.gradle.internal.concurrent.ThreadFactoryImpl$ManagedThreadRunnable.run(ThreadFactoryImpl.java:56)
	at java.lang.Thread.run(Thread.java:748)
[2020-01-15 10:21:31,194] DEBUG Processor 0 listening to new connection from /127.0.0.1:59517 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:31,294] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:31,294] TRACE Sending PRODUCE response to client  of 26 bytes. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:31,294] TRACE Socket server received response to send to 127.0.0.1:59515-127.0.0.1:59517-1, registering for write and sending data: Response(type=Send, request=Request(processor=0, connectionId=127.0.0.1:59515-127.0.0.1:59517-1, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(PLAINTEXT), securityProtocol=PLAINTEXT, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22]), send=org.apache.kafka.common.network.NetworkSend@5390e6bb, asString=Some(RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1))) (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:54)
[2020-01-15 10:21:31,294] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) from connection 127.0.0.1:59515-127.0.0.1:59517-1;totalTime:0.803,requestQueueTime:0.0,localTime:6.1093030579E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.355,sendTime:0.25,securityProtocol:PLAINTEXT,principal:User:ANONYMOUS,listener:PLAINTEXT,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:31,396] DEBUG Accepted connection from /127.0.0.1:59524 on /127.0.0.1:59515 and assigned it to processor 0, sendBufferSize [actual|requested]: [300000|300000] recvBufferSize [actual|requested]: [310308|300000] (kafka.network.Acceptor:62)
[2020-01-15 10:21:31,397] DEBUG Processor 0 listening to new connection from /127.0.0.1:59524 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:31,397] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:31,397] TRACE Sending PRODUCE response to client  of 26 bytes. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:31,397] TRACE Socket server received response to send to 127.0.0.1:59515-127.0.0.1:59524-2, registering for write and sending data: Response(type=Send, request=Request(processor=0, connectionId=127.0.0.1:59515-127.0.0.1:59524-2, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(PLAINTEXT), securityProtocol=PLAINTEXT, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22]), send=org.apache.kafka.common.network.NetworkSend@628952d6, asString=Some(RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1))) (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:54)
[2020-01-15 10:21:31,398] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) from connection 127.0.0.1:59515-127.0.0.1:59524-2;totalTime:0.701,requestQueueTime:0.0,localTime:6.1093133988E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.3,sendTime:0.207,securityProtocol:PLAINTEXT,principal:User:ANONYMOUS,listener:PLAINTEXT,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:31,502] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:31,502] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:31,502] DEBUG Closing server socket and selector. (kafka.network.Acceptor:62)
[2020-01-15 10:21:31,502] DEBUG Closing selector - processor 0 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:31,503] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:31,507] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:31,507] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer:66)
[2020-01-15 10:21:31,507] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:31,508] DEBUG Closing server socket and selector. (kafka.network.Acceptor:62)
[2020-01-15 10:21:31,508] DEBUG Closing selector - processor 0 (kafka.network.Processor:62)
[2020-01-15 10:21:31,509] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:31,515] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer:66)
[2020-01-15 10:21:31,524] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer:66)
[2020-01-15 10:21:31,524] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:31,524] DEBUG Closing server socket and selector. (kafka.network.Acceptor:62)
[2020-01-15 10:21:31,525] DEBUG Closing selector - processor 0 (kafka.network.Processor:62)
[2020-01-15 10:21:31,525] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:31,529] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer:66)
[2020-01-15 10:21:31,543] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 1500
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1500
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = SASL_PLAINTEXT://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/b3/bhnnh3l53jjdfgphtx91qd1h0000gn/T/kafka-687741077985116410
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 1
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1500
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = PLAIN
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = SASL_PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:1
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig:347)
[2020-01-15 10:21:31,548] INFO Awaiting socket connections on localhost:59534. (kafka.network.Acceptor:66)
[2020-01-15 10:21:31,550] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(localhost,0,ListenerName(SASL_PLAINTEXT),SASL_PLAINTEXT) (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:31,550] DEBUG [SocketServer brokerId=0] Wait for authorizer to complete start up on listener ListenerName(SASL_PLAINTEXT) (kafka.network.SocketServerTest$TestableSocketServer:62)
[2020-01-15 10:21:31,550] DEBUG [SocketServer brokerId=0] Start processors on listener ListenerName(SASL_PLAINTEXT) (kafka.network.SocketServerTest$TestableSocketServer:62)
[2020-01-15 10:21:31,550] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:31,551] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:31,552] DEBUG Accepted connection from /127.0.0.1:59535 on /127.0.0.1:59534 and assigned it to processor 0, sendBufferSize [actual|requested]: [102400|102400] recvBufferSize [actual|requested]: [375636|102400] (kafka.network.Acceptor:62)
[2020-01-15 10:21:31,552] DEBUG Processor 0 listening to new connection from /127.0.0.1:59535 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:31,553] DEBUG Disconnecting expired channel: org.apache.kafka.common.network.KafkaChannel@bff78460 id=127.0.0.1:59534-127.0.0.1:59535-0 : RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:31,554] DEBUG Closing selector connection 127.0.0.1:59534-127.0.0.1:59535-0 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:31,658] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:31,658] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:31,658] DEBUG Closing server socket and selector. (kafka.network.Acceptor:62)
[2020-01-15 10:21:31,658] DEBUG Closing selector - processor 0 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:31,659] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:31,663] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:31,663] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer:66)
[2020-01-15 10:21:31,666] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer:66)
[2020-01-15 10:21:31,678] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1500
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/b3/bhnnh3l53jjdfgphtx91qd1h0000gn/T/kafka-2245506295443790289
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = localhost:6
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1500
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:1
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig:347)
[2020-01-15 10:21:31,682] INFO Awaiting socket connections on localhost:59540. (kafka.network.Acceptor:66)
[2020-01-15 10:21:31,683] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(localhost,0,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer:66)
[2020-01-15 10:21:31,683] DEBUG [SocketServer brokerId=0] Wait for authorizer to complete start up on listener ListenerName(PLAINTEXT) (kafka.network.SocketServer:62)
[2020-01-15 10:21:31,683] DEBUG [SocketServer brokerId=0] Start processors on listener ListenerName(PLAINTEXT) (kafka.network.SocketServer:62)
[2020-01-15 10:21:31,684] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServer:66)
[2020-01-15 10:21:31,684] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer:66)
[2020-01-15 10:21:31,686] DEBUG Accepted connection from /127.0.0.1:59541 on /127.0.0.1:59540 and assigned it to processor 0, sendBufferSize [actual|requested]: [102400|102400] recvBufferSize [actual|requested]: [375636|102400] (kafka.network.Acceptor:62)
[2020-01-15 10:21:31,687] DEBUG Processor 0 listening to new connection from /127.0.0.1:59541 (kafka.network.Processor:62)
[2020-01-15 10:21:31,687] DEBUG Accepted connection from /127.0.0.1:59542 on /127.0.0.1:59540 and assigned it to processor 1, sendBufferSize [actual|requested]: [102400|102400] recvBufferSize [actual|requested]: [375636|102400] (kafka.network.Acceptor:62)
[2020-01-15 10:21:31,687] DEBUG Processor 1 listening to new connection from /127.0.0.1:59542 (kafka.network.Processor:62)
[2020-01-15 10:21:31,687] DEBUG Accepted connection from /127.0.0.1:59543 on /127.0.0.1:59540 and assigned it to processor 2, sendBufferSize [actual|requested]: [102400|102400] recvBufferSize [actual|requested]: [375636|102400] (kafka.network.Acceptor:62)
[2020-01-15 10:21:31,687] DEBUG Processor 2 listening to new connection from /127.0.0.1:59543 (kafka.network.Processor:62)
[2020-01-15 10:21:31,687] DEBUG Accepted connection from /127.0.0.1:59544 on /127.0.0.1:59540 and assigned it to processor 0, sendBufferSize [actual|requested]: [102400|102400] recvBufferSize [actual|requested]: [375636|102400] (kafka.network.Acceptor:62)
[2020-01-15 10:21:31,687] DEBUG Processor 0 listening to new connection from /127.0.0.1:59544 (kafka.network.Processor:62)
[2020-01-15 10:21:31,687] DEBUG Accepted connection from /127.0.0.1:59545 on /127.0.0.1:59540 and assigned it to processor 1, sendBufferSize [actual|requested]: [102400|102400] recvBufferSize [actual|requested]: [375636|102400] (kafka.network.Acceptor:62)
[2020-01-15 10:21:31,687] DEBUG Processor 1 listening to new connection from /127.0.0.1:59545 (kafka.network.Processor:62)
[2020-01-15 10:21:31,687] DEBUG Accepted connection from /127.0.0.1:59546 on /127.0.0.1:59540 and assigned it to processor 2, sendBufferSize [actual|requested]: [102400|102400] recvBufferSize [actual|requested]: [375636|102400] (kafka.network.Acceptor:62)
[2020-01-15 10:21:31,687] DEBUG Processor 2 listening to new connection from /127.0.0.1:59546 (kafka.network.Processor:62)
[2020-01-15 10:21:31,687] TRACE Processor 2 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:31,688] INFO Rejected connection from /127.0.0.1, address already has the configured maximum of 6 connections. (kafka.network.Acceptor:66)
[2020-01-15 10:21:31,688] DEBUG Closing connection from /127.0.0.1:59547 (kafka.network.Acceptor:62)
[2020-01-15 10:21:31,688] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer:66)
[2020-01-15 10:21:31,688] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:31,688] DEBUG Closing server socket and selector. (kafka.network.Acceptor:62)
[2020-01-15 10:21:31,688] DEBUG Closing selector - processor 0 (kafka.network.Processor:62)
[2020-01-15 10:21:31,688] DEBUG Closing selector connection 127.0.0.1:59540-127.0.0.1:59541-0 (kafka.network.Processor:62)
[2020-01-15 10:21:31,689] DEBUG Closing selector connection 127.0.0.1:59540-127.0.0.1:59544-1 (kafka.network.Processor:62)
[2020-01-15 10:21:31,689] DEBUG Closing selector - processor 1 (kafka.network.Processor:62)
[2020-01-15 10:21:31,689] DEBUG Closing selector connection 127.0.0.1:59540-127.0.0.1:59542-0 (kafka.network.Processor:62)
[2020-01-15 10:21:31,689] DEBUG Closing selector connection 127.0.0.1:59540-127.0.0.1:59545-1 (kafka.network.Processor:62)
[2020-01-15 10:21:31,689] DEBUG Closing selector - processor 2 (kafka.network.Processor:62)
[2020-01-15 10:21:31,689] DEBUG Closing selector connection 127.0.0.1:59540-127.0.0.1:59543-0 (kafka.network.Processor:62)
[2020-01-15 10:21:31,689] DEBUG Closing selector connection 127.0.0.1:59540-127.0.0.1:59546-1 (kafka.network.Processor:62)
[2020-01-15 10:21:31,690] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:31,693] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer:66)
[2020-01-15 10:21:31,694] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer:66)
[2020-01-15 10:21:31,694] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:31,694] DEBUG Closing server socket and selector. (kafka.network.Acceptor:62)
[2020-01-15 10:21:31,694] DEBUG Closing selector - processor 0 (kafka.network.Processor:62)
[2020-01-15 10:21:31,694] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:31,697] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer:66)
[2020-01-15 10:21:31,703] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 60000
	connections.max.reauth.ms = 0
	control.plane.listener.name = CONTROLLER
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1500
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,CONTROLLER:PLAINTEXT
	listeners = PLAINTEXT://localhost:0,CONTROLLER://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/b3/bhnnh3l53jjdfgphtx91qd1h0000gn/T/kafka-6274344233968269741
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections = 2147483647
	max.connections.per.ip = 5
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 1
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 50
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1500
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 300000
	socket.request.max.bytes = 100
	socket.send.buffer.bytes = 300000
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:1
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig:347)
[2020-01-15 10:21:31,711] INFO Awaiting socket connections on localhost:59549. (kafka.network.Acceptor:66)
[2020-01-15 10:21:31,712] INFO [SocketServer brokerId=0] Created control-plane acceptor and processor for endpoint : EndPoint(localhost,0,ListenerName(CONTROLLER),PLAINTEXT) (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:31,712] INFO Awaiting socket connections on localhost:59550. (kafka.network.Acceptor:66)
[2020-01-15 10:21:31,713] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(localhost,0,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:31,714] INFO [SocketServer brokerId=0] Started control-plane processor for the control-plane acceptor (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:31,714] DEBUG [SocketServer brokerId=0] Wait for authorizer to complete start up on listener ListenerName(PLAINTEXT) (kafka.network.SocketServerTest$TestableSocketServer:62)
[2020-01-15 10:21:31,714] DEBUG [SocketServer brokerId=0] Start processors on listener ListenerName(PLAINTEXT) (kafka.network.SocketServerTest$TestableSocketServer:62)
[2020-01-15 10:21:31,714] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:31,715] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:31,715] INFO [SocketServer brokerId=0] Started control-plane acceptor thread (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:31,716] DEBUG Accepted connection from /127.0.0.1:59551 on /127.0.0.1:59549 and assigned it to processor 0, sendBufferSize [actual|requested]: [300000|300000] recvBufferSize [actual|requested]: [310308|300000] (kafka.network.Acceptor:62)
[2020-01-15 10:21:31,716] DEBUG Processor 0 listening to new connection from /127.0.0.1:59551 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:31,717] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:31,717] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:31,717] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:31,717] DEBUG Closing server socket and selector. (kafka.network.Acceptor:62)
[2020-01-15 10:21:31,717] DEBUG Closing selector - processor 1 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:31,717] DEBUG Closing server socket and selector. (kafka.network.Acceptor:62)
[2020-01-15 10:21:31,718] DEBUG Closing selector - processor 0 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:31,718] DEBUG Closing selector connection 127.0.0.1:59549-127.0.0.1:59551-0 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:31,718] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:31,726] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:31,726] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer:66)
[2020-01-15 10:21:31,726] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:31,726] DEBUG Closing server socket and selector. (kafka.network.Acceptor:62)
[2020-01-15 10:21:31,726] DEBUG Closing selector - processor 0 (kafka.network.Processor:62)
[2020-01-15 10:21:31,727] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:31,729] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer:66)
[2020-01-15 10:21:31,736] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 60000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1500
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/b3/bhnnh3l53jjdfgphtx91qd1h0000gn/T/kafka-817790219490382075
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections = 2147483647
	max.connections.per.ip = 5
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 1
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 50
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1500
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 300000
	socket.request.max.bytes = 100
	socket.send.buffer.bytes = 300000
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:1
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig:347)
[2020-01-15 10:21:31,740] INFO Awaiting socket connections on localhost:59553. (kafka.network.Acceptor:66)
[2020-01-15 10:21:31,740] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(localhost,0,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:31,741] DEBUG [SocketServer brokerId=0] Wait for authorizer to complete start up on listener ListenerName(PLAINTEXT) (kafka.network.SocketServerTest$TestableSocketServer:62)
[2020-01-15 10:21:31,741] DEBUG [SocketServer brokerId=0] Start processors on listener ListenerName(PLAINTEXT) (kafka.network.SocketServerTest$TestableSocketServer:62)
[2020-01-15 10:21:31,741] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:31,742] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:31,743] DEBUG Accepted connection from /127.0.0.1:59555 on /127.0.0.1:59553 and assigned it to processor 0, sendBufferSize [actual|requested]: [300000|300000] recvBufferSize [actual|requested]: [310308|300000] (kafka.network.Acceptor:62)
[2020-01-15 10:21:31,743] DEBUG Accepted connection from /127.0.0.1:59556 on /127.0.0.1:59553 and assigned it to processor 0, sendBufferSize [actual|requested]: [300000|300000] recvBufferSize [actual|requested]: [310308|300000] (kafka.network.Acceptor:62)
[2020-01-15 10:21:31,743] DEBUG Processor 0 listening to new connection from /127.0.0.1:59555 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:31,744] DEBUG Processor 0 listening to new connection from /127.0.0.1:59556 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:31,744] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:31,744] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:31,744] TRACE Sending PRODUCE response to client  of 26 bytes. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:31,744] TRACE Sending PRODUCE response to client  of 26 bytes. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:31,745] TRACE Socket server received response to send to 127.0.0.1:59553-127.0.0.1:59555-0, registering for write and sending data: Response(type=Send, request=Request(processor=0, connectionId=127.0.0.1:59553-127.0.0.1:59555-0, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(PLAINTEXT), securityProtocol=PLAINTEXT, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22]), send=org.apache.kafka.common.network.NetworkSend@760be785, asString=Some(RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1))) (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:54)
[2020-01-15 10:21:31,745] ERROR Closing socket for 127.0.0.1:59553-127.0.0.1:59555-0 because of error (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:76)
java.lang.IllegalStateException: Test exception during Send
	at kafka.network.SocketServerTest$TestableSelector.$anonfun$addFailure$1(SocketServerTest.scala:1797)
	at kafka.network.SocketServerTest$TestableSelector.addFailure(SocketServerTest.scala:1797)
	at kafka.network.SocketServerTest.$anonfun$processNewResponseException$1(SocketServerTest.scala:1191)
	at kafka.network.SocketServerTest.processNewResponseException(SocketServerTest.scala:1184)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecutor.runTestClass(JUnitTestClassExecutor.java:110)
	at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecutor.execute(JUnitTestClassExecutor.java:58)
	at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecutor.execute(JUnitTestClassExecutor.java:38)
	at org.gradle.api.internal.tasks.testing.junit.AbstractJUnitTestClassProcessor.processTestClass(AbstractJUnitTestClassProcessor.java:62)
	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.processTestClass(SuiteTestClassProcessor.java:51)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36)
	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)
	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:33)
	at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:94)
	at com.sun.proxy.$Proxy2.processTestClass(Unknown Source)
	at org.gradle.api.internal.tasks.testing.worker.TestWorker.processTestClass(TestWorker.java:118)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36)
	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)
	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:182)
	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:164)
	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:412)
	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:64)
	at org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:48)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at org.gradle.internal.concurrent.ThreadFactoryImpl$ManagedThreadRunnable.run(ThreadFactoryImpl.java:56)
	at java.lang.Thread.run(Thread.java:748)
[2020-01-15 10:21:31,746] DEBUG Closing selector connection 127.0.0.1:59553-127.0.0.1:59555-0 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:31,746] ERROR Exception while processing response for 127.0.0.1:59553-127.0.0.1:59555-0 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:76)
java.lang.IllegalStateException: Test exception during Send
	at kafka.network.SocketServerTest$TestableSelector.$anonfun$addFailure$1(SocketServerTest.scala:1797)
	at kafka.network.SocketServerTest$TestableSelector.addFailure(SocketServerTest.scala:1797)
	at kafka.network.SocketServerTest.$anonfun$processNewResponseException$1(SocketServerTest.scala:1191)
	at kafka.network.SocketServerTest.processNewResponseException(SocketServerTest.scala:1184)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecutor.runTestClass(JUnitTestClassExecutor.java:110)
	at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecutor.execute(JUnitTestClassExecutor.java:58)
	at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecutor.execute(JUnitTestClassExecutor.java:38)
	at org.gradle.api.internal.tasks.testing.junit.AbstractJUnitTestClassProcessor.processTestClass(AbstractJUnitTestClassProcessor.java:62)
	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.processTestClass(SuiteTestClassProcessor.java:51)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36)
	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)
	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:33)
	at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:94)
	at com.sun.proxy.$Proxy2.processTestClass(Unknown Source)
	at org.gradle.api.internal.tasks.testing.worker.TestWorker.processTestClass(TestWorker.java:118)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36)
	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)
	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:182)
	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:164)
	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:412)
	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:64)
	at org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:48)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at org.gradle.internal.concurrent.ThreadFactoryImpl$ManagedThreadRunnable.run(ThreadFactoryImpl.java:56)
	at java.lang.Thread.run(Thread.java:748)
[2020-01-15 10:21:31,746] TRACE Socket server received response to send to 127.0.0.1:59553-127.0.0.1:59556-1, registering for write and sending data: Response(type=Send, request=Request(processor=0, connectionId=127.0.0.1:59553-127.0.0.1:59556-1, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(PLAINTEXT), securityProtocol=PLAINTEXT, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22]), send=org.apache.kafka.common.network.NetworkSend@2b6e5a55, asString=Some(RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1))) (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:54)
[2020-01-15 10:21:31,746] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) from connection 127.0.0.1:59553-127.0.0.1:59556-1;totalTime:2.146,requestQueueTime:0.0,localTime:6.1093481231E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:1.611,sendTime:0.189,securityProtocol:PLAINTEXT,principal:User:ANONYMOUS,listener:PLAINTEXT,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:31,846] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:31,846] TRACE Sending PRODUCE response to client  of 26 bytes. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:31,847] TRACE Socket server received response to send to 127.0.0.1:59553-127.0.0.1:59556-1, registering for write and sending data: Response(type=Send, request=Request(processor=0, connectionId=127.0.0.1:59553-127.0.0.1:59556-1, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(PLAINTEXT), securityProtocol=PLAINTEXT, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22]), send=org.apache.kafka.common.network.NetworkSend@5326886f, asString=Some(RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1))) (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:54)
[2020-01-15 10:21:31,847] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) from connection 127.0.0.1:59553-127.0.0.1:59556-1;totalTime:1.232,requestQueueTime:0.0,localTime:6.1093582813E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.527,sendTime:0.4,securityProtocol:PLAINTEXT,principal:User:ANONYMOUS,listener:PLAINTEXT,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:31,952] DEBUG Accepted connection from /127.0.0.1:59566 on /127.0.0.1:59553 and assigned it to processor 0, sendBufferSize [actual|requested]: [300000|300000] recvBufferSize [actual|requested]: [310308|300000] (kafka.network.Acceptor:62)
[2020-01-15 10:21:31,952] DEBUG Processor 0 listening to new connection from /127.0.0.1:59566 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:31,953] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:31,953] TRACE Sending PRODUCE response to client  of 26 bytes. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:31,953] TRACE Socket server received response to send to 127.0.0.1:59553-127.0.0.1:59566-2, registering for write and sending data: Response(type=Send, request=Request(processor=0, connectionId=127.0.0.1:59553-127.0.0.1:59566-2, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(PLAINTEXT), securityProtocol=PLAINTEXT, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22]), send=org.apache.kafka.common.network.NetworkSend@690f77ec, asString=Some(RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1))) (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:54)
[2020-01-15 10:21:31,953] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) from connection 127.0.0.1:59553-127.0.0.1:59566-2;totalTime:0.55,requestQueueTime:0.0,localTime:6.1093689834E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.19,sendTime:0.173,securityProtocol:PLAINTEXT,principal:User:ANONYMOUS,listener:PLAINTEXT,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:32,057] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:32,058] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:32,058] DEBUG Closing server socket and selector. (kafka.network.Acceptor:62)
[2020-01-15 10:21:32,059] DEBUG Closing selector - processor 0 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:32,059] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:32,065] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:32,065] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer:66)
[2020-01-15 10:21:32,065] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:32,065] DEBUG Closing server socket and selector. (kafka.network.Acceptor:62)
[2020-01-15 10:21:32,065] DEBUG Closing selector - processor 0 (kafka.network.Processor:62)
[2020-01-15 10:21:32,066] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:32,068] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer:66)
[2020-01-15 10:21:32,281] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 60000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1500
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = SSL://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/b3/bhnnh3l53jjdfgphtx91qd1h0000gn/T/kafka-3005039360307861667
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections = 2147483647
	max.connections.per.ip = 5
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 1
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 50
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1500
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = SSL
	security.providers = null
	socket.receive.buffer.bytes = 300000
	socket.request.max.bytes = 100
	socket.send.buffer.bytes = 300000
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = [hidden]
	ssl.keymanager.algorithm = PKIX
	ssl.keystore.location = /var/folders/b3/bhnnh3l53jjdfgphtx91qd1h0000gn/T/serverKS307737869510901752.jks
	ssl.keystore.password = [hidden]
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = /var/folders/b3/bhnnh3l53jjdfgphtx91qd1h0000gn/T/truststore7921023688544127792.jks
	ssl.truststore.password = [hidden]
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:1
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig:347)
[2020-01-15 10:21:32,285] INFO Awaiting socket connections on localhost:59583. (kafka.network.Acceptor:66)
[2020-01-15 10:21:32,323] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(localhost,0,ListenerName(SSL),SSL) (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:32,323] DEBUG [SocketServer brokerId=0] Wait for authorizer to complete start up on listener ListenerName(SSL) (kafka.network.SocketServerTest$TestableSocketServer:62)
[2020-01-15 10:21:32,323] DEBUG [SocketServer brokerId=0] Start processors on listener ListenerName(SSL) (kafka.network.SocketServerTest$TestableSocketServer:62)
[2020-01-15 10:21:32,324] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:32,324] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:32,326] DEBUG Accepted connection from /127.0.0.1:59585 on /127.0.0.1:59583 and assigned it to processor 0, sendBufferSize [actual|requested]: [300000|300000] recvBufferSize [actual|requested]: [310308|300000] (kafka.network.Acceptor:62)
[2020-01-15 10:21:32,326] DEBUG Processor 0 listening to new connection from /127.0.0.1:59585 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:32,353] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:32,456] TRACE Not sending PRODUCE response to client  as it's not required. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:32,456] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response: from connection 127.0.0.1:59583-127.0.0.1:59585-0;totalTime:103.105,requestQueueTime:0.0,localTime:6.1094192577E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.419,sendTime:0.006,securityProtocol:SSL,principal:User:ANONYMOUS,listener:SSL,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:32,456] TRACE Socket server received empty response to send, registering for read: Response(type=NoOp, request=Request(processor=0, connectionId=127.0.0.1:59583-127.0.0.1:59585-0, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(SSL), securityProtocol=SSL, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22])) (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:54)
[2020-01-15 10:21:32,558] DEBUG Accepted connection from /127.0.0.1:59596 on /127.0.0.1:59583 and assigned it to processor 0, sendBufferSize [actual|requested]: [300000|300000] recvBufferSize [actual|requested]: [310308|300000] (kafka.network.Acceptor:62)
[2020-01-15 10:21:32,558] DEBUG Processor 0 listening to new connection from /127.0.0.1:59596 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:32,566] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:32,566] TRACE Sending PRODUCE response to client  of 26 bytes. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:32,566] TRACE Socket server received response to send to 127.0.0.1:59583-127.0.0.1:59596-1, registering for write and sending data: Response(type=Send, request=Request(processor=0, connectionId=127.0.0.1:59583-127.0.0.1:59596-1, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(SSL), securityProtocol=SSL, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22]), send=org.apache.kafka.common.network.NetworkSend@5acaaaf3, asString=Some(RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1))) (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:54)
[2020-01-15 10:21:32,566] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) from connection 127.0.0.1:59583-127.0.0.1:59596-1;totalTime:0.793,requestQueueTime:0.0,localTime:6.1094302635E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.304,sendTime:0.217,securityProtocol:SSL,principal:User:ANONYMOUS,listener:SSL,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:32,671] DEBUG Accepted connection from /127.0.0.1:59600 on /127.0.0.1:59583 and assigned it to processor 0, sendBufferSize [actual|requested]: [300000|300000] recvBufferSize [actual|requested]: [310308|300000] (kafka.network.Acceptor:62)
[2020-01-15 10:21:32,671] DEBUG Processor 0 listening to new connection from /127.0.0.1:59600 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:32,678] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:32,678] TRACE Sending PRODUCE response to client  of 26 bytes. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:32,678] TRACE Socket server received response to send to 127.0.0.1:59583-127.0.0.1:59600-2, registering for write and sending data: Response(type=Send, request=Request(processor=0, connectionId=127.0.0.1:59583-127.0.0.1:59600-2, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(SSL), securityProtocol=SSL, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22]), send=org.apache.kafka.common.network.NetworkSend@5930cb6d, asString=Some(RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1))) (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:54)
[2020-01-15 10:21:32,679] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) from connection 127.0.0.1:59583-127.0.0.1:59600-2;totalTime:0.717,requestQueueTime:0.0,localTime:6.1094414996E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.307,sendTime:0.222,securityProtocol:SSL,principal:User:ANONYMOUS,listener:SSL,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:32,781] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:32,781] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:32,782] DEBUG Closing server socket and selector. (kafka.network.Acceptor:62)
[2020-01-15 10:21:32,782] DEBUG Closing selector - processor 0 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:32,782] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:32,785] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:32,785] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer:66)
[2020-01-15 10:21:32,786] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:32,786] DEBUG Closing server socket and selector. (kafka.network.Acceptor:62)
[2020-01-15 10:21:32,786] DEBUG Closing selector - processor 0 (kafka.network.Processor:62)
[2020-01-15 10:21:32,786] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:32,790] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer:66)
[2020-01-15 10:21:32,796] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 60000
	connections.max.reauth.ms = 0
	control.plane.listener.name = CONTROLLER
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1500
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = INTERNAL
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = EXTERNAL:PLAINTEXT,INTERNAL:PLAINTEXT,CONTROLLER:PLAINTEXT
	listeners = EXTERNAL://localhost:0,INTERNAL://localhost:0,CONTROLLER://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/b3/bhnnh3l53jjdfgphtx91qd1h0000gn/T/kafka-8960654401640227567
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections = 2147483647
	max.connections.per.ip = 5
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 1
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 50
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1500
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 300000
	socket.request.max.bytes = 100
	socket.send.buffer.bytes = 300000
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:1
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig:347)
[2020-01-15 10:21:32,803] INFO Awaiting socket connections on localhost:59613. (kafka.network.Acceptor:66)
[2020-01-15 10:21:32,803] INFO [SocketServer brokerId=0] Created control-plane acceptor and processor for endpoint : EndPoint(localhost,0,ListenerName(CONTROLLER),PLAINTEXT) (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:32,804] INFO Awaiting socket connections on localhost:59614. (kafka.network.Acceptor:66)
[2020-01-15 10:21:32,804] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(localhost,0,ListenerName(EXTERNAL),PLAINTEXT) (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:32,804] INFO Awaiting socket connections on localhost:59615. (kafka.network.Acceptor:66)
[2020-01-15 10:21:32,805] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(localhost,0,ListenerName(INTERNAL),PLAINTEXT) (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:32,805] INFO [SocketServer brokerId=0] Started 2 acceptor threads for data-plane (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:32,805] INFO [SocketServer brokerId=0] Started control-plane acceptor thread (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:32,806] INFO [SocketServer brokerId=0] Started control-plane processor for the control-plane acceptor (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:32,808] DEBUG Accepted connection from /127.0.0.1:59616 on /127.0.0.1:59613 and assigned it to processor 0, sendBufferSize [actual|requested]: [300000|300000] recvBufferSize [actual|requested]: [310308|300000] (kafka.network.Acceptor:62)
[2020-01-15 10:21:32,808] DEBUG Processor 0 listening to new connection from /127.0.0.1:59616 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:32,808] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:32,809] DEBUG [SocketServer brokerId=0] Wait for authorizer to complete start up on listener ListenerName(INTERNAL) (kafka.network.SocketServerTest$TestableSocketServer:62)
[2020-01-15 10:21:32,810] DEBUG [SocketServer brokerId=0] Start processors on listener ListenerName(INTERNAL) (kafka.network.SocketServerTest$TestableSocketServer:62)
[2020-01-15 10:21:32,810] DEBUG [SocketServer brokerId=0] Wait for authorizer to complete start up on listener ListenerName(EXTERNAL) (kafka.network.SocketServerTest$TestableSocketServer:62)
[2020-01-15 10:21:32,810] DEBUG Accepted connection from /127.0.0.1:59617 on /127.0.0.1:59615 and assigned it to processor 2, sendBufferSize [actual|requested]: [300000|300000] recvBufferSize [actual|requested]: [310308|300000] (kafka.network.Acceptor:62)
[2020-01-15 10:21:32,810] DEBUG Processor 2 listening to new connection from /127.0.0.1:59617 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:32,810] TRACE Processor 2 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:32,811] DEBUG Accepted connection from /127.0.0.1:59618 on /127.0.0.1:59614 and assigned it to processor 1, sendBufferSize [actual|requested]: [300000|300000] recvBufferSize [actual|requested]: [310308|300000] (kafka.network.Acceptor:62)
[2020-01-15 10:21:34,818] DEBUG [SocketServer brokerId=0] Start processors on listener ListenerName(EXTERNAL) (kafka.network.SocketServerTest$TestableSocketServer:62)
[2020-01-15 10:21:34,818] INFO [SocketServer brokerId=0] Started data-plane processors for 2 acceptors (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:34,818] DEBUG Processor 1 listening to new connection from /127.0.0.1:59618 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:34,819] DEBUG Accepted connection from /127.0.0.1:59690 on /127.0.0.1:59614 and assigned it to processor 1, sendBufferSize [actual|requested]: [300000|300000] recvBufferSize [actual|requested]: [310308|300000] (kafka.network.Acceptor:62)
[2020-01-15 10:21:34,819] TRACE Processor 1 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:34,819] DEBUG Processor 1 listening to new connection from /127.0.0.1:59690 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:34,819] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:34,819] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:34,819] TRACE Processor 1 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:34,819] DEBUG Closing server socket and selector. (kafka.network.Acceptor:62)
[2020-01-15 10:21:34,820] DEBUG Closing selector - processor 1 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:34,820] DEBUG Closing selector connection 127.0.0.1:59614-127.0.0.1:59618-0 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:34,820] DEBUG Closing selector connection 127.0.0.1:59614-127.0.0.1:59690-1 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:34,820] DEBUG Closing server socket and selector. (kafka.network.Acceptor:62)
[2020-01-15 10:21:34,820] DEBUG Closing selector - processor 2 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:34,821] DEBUG Closing selector connection 127.0.0.1:59615-127.0.0.1:59617-0 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:34,821] DEBUG Closing server socket and selector. (kafka.network.Acceptor:62)
[2020-01-15 10:21:34,821] DEBUG Closing selector - processor 0 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:34,821] DEBUG Closing selector connection 127.0.0.1:59613-127.0.0.1:59616-0 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:34,821] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:34,828] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:34,828] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer:66)
[2020-01-15 10:21:34,828] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:34,828] DEBUG Closing server socket and selector. (kafka.network.Acceptor:62)
[2020-01-15 10:21:34,829] DEBUG Closing selector - processor 0 (kafka.network.Processor:62)
[2020-01-15 10:21:34,829] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:34,832] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer:66)
[2020-01-15 10:21:34,872] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer:66)
[2020-01-15 10:21:34,872] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:34,872] DEBUG Closing server socket and selector. (kafka.network.Acceptor:62)
[2020-01-15 10:21:34,872] DEBUG Closing selector - processor 0 (kafka.network.Processor:62)
[2020-01-15 10:21:34,872] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:34,876] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer:66)
[2020-01-15 10:21:34,876] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 60000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1500
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/b3/bhnnh3l53jjdfgphtx91qd1h0000gn/T/kafka-5582575098775794524
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections = 2147483647
	max.connections.per.ip = 5
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 1
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 50
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1500
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 300000
	socket.request.max.bytes = 100
	socket.send.buffer.bytes = 300000
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:1
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig:347)
[2020-01-15 10:21:34,881] INFO Awaiting socket connections on localhost:59692. (kafka.network.Acceptor:66)
[2020-01-15 10:21:34,882] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(localhost,0,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:34,882] DEBUG [SocketServer brokerId=0] Wait for authorizer to complete start up on listener ListenerName(PLAINTEXT) (kafka.network.SocketServerTest$TestableSocketServer:62)
[2020-01-15 10:21:34,882] DEBUG [SocketServer brokerId=0] Start processors on listener ListenerName(PLAINTEXT) (kafka.network.SocketServerTest$TestableSocketServer:62)
[2020-01-15 10:21:34,882] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:34,883] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:34,885] DEBUG Accepted connection from /127.0.0.1:59693 on /127.0.0.1:59692 and assigned it to processor 0, sendBufferSize [actual|requested]: [300000|300000] recvBufferSize [actual|requested]: [310308|300000] (kafka.network.Acceptor:62)
[2020-01-15 10:21:34,885] DEBUG Processor 0 listening to new connection from /127.0.0.1:59693 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:34,885] DEBUG Accepted connection from /127.0.0.1:59694 on /127.0.0.1:59692 and assigned it to processor 0, sendBufferSize [actual|requested]: [300000|300000] recvBufferSize [actual|requested]: [310308|300000] (kafka.network.Acceptor:62)
[2020-01-15 10:21:34,887] DEBUG Processor 0 listening to new connection from /127.0.0.1:59694 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:34,887] DEBUG Accepted connection from /127.0.0.1:59695 on /127.0.0.1:59692 and assigned it to processor 0, sendBufferSize [actual|requested]: [300000|300000] recvBufferSize [actual|requested]: [310308|300000] (kafka.network.Acceptor:62)
[2020-01-15 10:21:34,989] DEBUG Processor 0 listening to new connection from /127.0.0.1:59695 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:34,989] DEBUG Accepted connection from /127.0.0.1:59696 on /127.0.0.1:59692 and assigned it to processor 0, sendBufferSize [actual|requested]: [300000|300000] recvBufferSize [actual|requested]: [310308|300000] (kafka.network.Acceptor:62)
[2020-01-15 10:21:35,092] DEBUG Processor 0 listening to new connection from /127.0.0.1:59696 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:35,092] DEBUG Accepted connection from /127.0.0.1:59697 on /127.0.0.1:59692 and assigned it to processor 0, sendBufferSize [actual|requested]: [300000|300000] recvBufferSize [actual|requested]: [310308|300000] (kafka.network.Acceptor:62)
[2020-01-15 10:21:35,093] DEBUG Processor 0 listening to new connection from /127.0.0.1:59697 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:35,189] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:35,189] TRACE Sending PRODUCE response to client  of 26 bytes. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:35,189] TRACE Socket server received response to send to 127.0.0.1:59692-127.0.0.1:59693-0, registering for write and sending data: Response(type=Send, request=Request(processor=0, connectionId=127.0.0.1:59692-127.0.0.1:59693-0, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(PLAINTEXT), securityProtocol=PLAINTEXT, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22]), send=org.apache.kafka.common.network.NetworkSend@1124329b, asString=Some(RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1))) (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:54)
[2020-01-15 10:21:35,189] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:35,190] TRACE Sending PRODUCE response to client  of 26 bytes. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:35,190] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) from connection 127.0.0.1:59692-127.0.0.1:59693-0;totalTime:0.872,requestQueueTime:0.0,localTime:6.1096925794E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.286,sendTime:0.334,securityProtocol:PLAINTEXT,principal:User:ANONYMOUS,listener:PLAINTEXT,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:35,190] TRACE Socket server received response to send to 127.0.0.1:59692-127.0.0.1:59694-1, registering for write and sending data: Response(type=Send, request=Request(processor=0, connectionId=127.0.0.1:59692-127.0.0.1:59694-1, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(PLAINTEXT), securityProtocol=PLAINTEXT, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22]), send=org.apache.kafka.common.network.NetworkSend@28255b5c, asString=Some(RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1))) (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:54)
[2020-01-15 10:21:35,190] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:35,190] TRACE Sending PRODUCE response to client  of 26 bytes. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:35,190] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) from connection 127.0.0.1:59692-127.0.0.1:59694-1;totalTime:0.872,requestQueueTime:0.0,localTime:6.1096926414E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.272,sendTime:0.484,securityProtocol:PLAINTEXT,principal:User:ANONYMOUS,listener:PLAINTEXT,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:35,191] TRACE Socket server received response to send to 127.0.0.1:59692-127.0.0.1:59695-2, registering for write and sending data: Response(type=Send, request=Request(processor=0, connectionId=127.0.0.1:59692-127.0.0.1:59695-2, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(PLAINTEXT), securityProtocol=PLAINTEXT, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22]), send=org.apache.kafka.common.network.NetworkSend@212bd586, asString=Some(RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1))) (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:54)
[2020-01-15 10:21:35,191] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:35,191] TRACE Sending PRODUCE response to client  of 26 bytes. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:35,191] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) from connection 127.0.0.1:59692-127.0.0.1:59695-2;totalTime:1.186,requestQueueTime:0.0,localTime:6.1096927133E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.496,sendTime:0.577,securityProtocol:PLAINTEXT,principal:User:ANONYMOUS,listener:PLAINTEXT,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:35,192] TRACE Socket server received response to send to 127.0.0.1:59692-127.0.0.1:59696-3, registering for write and sending data: Response(type=Send, request=Request(processor=0, connectionId=127.0.0.1:59692-127.0.0.1:59696-3, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(PLAINTEXT), securityProtocol=PLAINTEXT, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22]), send=org.apache.kafka.common.network.NetworkSend@6ea5d456, asString=Some(RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1))) (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:54)
[2020-01-15 10:21:35,192] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:35,192] TRACE Sending PRODUCE response to client  of 26 bytes. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:35,193] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) from connection 127.0.0.1:59692-127.0.0.1:59696-3;totalTime:1.057,requestQueueTime:0.0,localTime:6.10969282E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.372,sendTime:0.51,securityProtocol:PLAINTEXT,principal:User:ANONYMOUS,listener:PLAINTEXT,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:35,193] TRACE Socket server received response to send to 127.0.0.1:59692-127.0.0.1:59697-4, registering for write and sending data: Response(type=Send, request=Request(processor=0, connectionId=127.0.0.1:59692-127.0.0.1:59697-4, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(PLAINTEXT), securityProtocol=PLAINTEXT, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22]), send=org.apache.kafka.common.network.NetworkSend@5e2593f3, asString=Some(RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1))) (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:54)
[2020-01-15 10:21:35,194] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) from connection 127.0.0.1:59692-127.0.0.1:59697-4;totalTime:1.853,requestQueueTime:0.0,localTime:6.109692911E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.672,sendTime:0.993,securityProtocol:PLAINTEXT,principal:User:ANONYMOUS,listener:PLAINTEXT,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:35,294] DEBUG Accepted connection from /127.0.0.1:59711 on /127.0.0.1:59692 and assigned it to processor 0, sendBufferSize [actual|requested]: [300000|300000] recvBufferSize [actual|requested]: [310308|300000] (kafka.network.Acceptor:62)
[2020-01-15 10:21:35,294] DEBUG Processor 0 listening to new connection from /127.0.0.1:59711 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:35,294] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:35,294] TRACE Sending PRODUCE response to client  of 26 bytes. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:35,295] TRACE Socket server received response to send to 127.0.0.1:59692-127.0.0.1:59711-5, registering for write and sending data: Response(type=Send, request=Request(processor=0, connectionId=127.0.0.1:59692-127.0.0.1:59711-5, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(PLAINTEXT), securityProtocol=PLAINTEXT, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22]), send=org.apache.kafka.common.network.NetworkSend@2320a538, asString=Some(RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1))) (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:54)
[2020-01-15 10:21:35,295] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) from connection 127.0.0.1:59692-127.0.0.1:59711-5;totalTime:0.673,requestQueueTime:0.0,localTime:6.1097031182E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.274,sendTime:0.227,securityProtocol:PLAINTEXT,principal:User:ANONYMOUS,listener:PLAINTEXT,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:35,398] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:35,398] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:35,398] DEBUG Closing server socket and selector. (kafka.network.Acceptor:62)
[2020-01-15 10:21:35,398] DEBUG Closing selector - processor 0 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:35,399] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:35,404] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:35,404] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer:66)
[2020-01-15 10:21:35,408] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer:66)
[2020-01-15 10:21:35,528] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 60000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1500
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/b3/bhnnh3l53jjdfgphtx91qd1h0000gn/T/kafka-9030483558138755267
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections = 2147483647
	max.connections.per.ip = 5
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 1
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 50
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1500
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 300000
	socket.request.max.bytes = 100
	socket.send.buffer.bytes = 300000
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:1
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig:347)
[2020-01-15 10:21:35,532] INFO Awaiting socket connections on localhost:59719. (kafka.network.Acceptor:66)
[2020-01-15 10:21:35,533] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(localhost,0,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:35,533] DEBUG [SocketServer brokerId=0] Wait for authorizer to complete start up on listener ListenerName(PLAINTEXT) (kafka.network.SocketServerTest$TestableSocketServer:62)
[2020-01-15 10:21:35,533] DEBUG [SocketServer brokerId=0] Start processors on listener ListenerName(PLAINTEXT) (kafka.network.SocketServerTest$TestableSocketServer:62)
[2020-01-15 10:21:35,533] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:35,534] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:35,536] DEBUG Accepted connection from /127.0.0.1:59720 on /127.0.0.1:59719 and assigned it to processor 0, sendBufferSize [actual|requested]: [300000|300000] recvBufferSize [actual|requested]: [310308|300000] (kafka.network.Acceptor:62)
[2020-01-15 10:21:35,536] DEBUG Processor 0 listening to new connection from /127.0.0.1:59720 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:35,537] DEBUG Accepted connection from /127.0.0.1:59721 on /127.0.0.1:59719 and assigned it to processor 0, sendBufferSize [actual|requested]: [300000|300000] recvBufferSize [actual|requested]: [310308|300000] (kafka.network.Acceptor:62)
[2020-01-15 10:21:35,537] DEBUG Processor 0 listening to new connection from /127.0.0.1:59721 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:35,537] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:35,537] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:35,538] TRACE Sending PRODUCE response to client  of 26 bytes. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:35,538] TRACE Sending PRODUCE response to client  of 26 bytes. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:35,538] TRACE Socket server received response to send to 127.0.0.1:59719-127.0.0.1:59720-0, registering for write and sending data: Response(type=Send, request=Request(processor=0, connectionId=127.0.0.1:59719-127.0.0.1:59720-0, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(PLAINTEXT), securityProtocol=PLAINTEXT, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22]), send=org.apache.kafka.common.network.NetworkSend@68ad5088, asString=Some(RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1))) (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:54)
[2020-01-15 10:21:35,539] TRACE Socket server received response to send to 127.0.0.1:59719-127.0.0.1:59721-1, registering for write and sending data: Response(type=Send, request=Request(processor=0, connectionId=127.0.0.1:59719-127.0.0.1:59721-1, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(PLAINTEXT), securityProtocol=PLAINTEXT, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22]), send=org.apache.kafka.common.network.NetworkSend@2dafc3f9, asString=Some(RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1))) (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:54)
[2020-01-15 10:21:35,539] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) from connection 127.0.0.1:59719-127.0.0.1:59721-1;totalTime:1.459,requestQueueTime:0.0,localTime:6.1097275043E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.3,sendTime:0.246,securityProtocol:PLAINTEXT,principal:User:ANONYMOUS,listener:PLAINTEXT,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:35,539] ERROR Closing socket for 127.0.0.1:59719-127.0.0.1:59721-1 because of error (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:76)
java.lang.IllegalStateException: Test exception during Unmute
	at kafka.network.SocketServerTest$TestableSelector.$anonfun$addFailure$1(SocketServerTest.scala:1797)
	at kafka.network.SocketServerTest$TestableSelector.addFailure(SocketServerTest.scala:1797)
	at kafka.network.SocketServerTest.$anonfun$processCompletedSendException$1(SocketServerTest.scala:1504)
	at kafka.network.SocketServerTest.processCompletedSendException(SocketServerTest.scala:1499)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecutor.runTestClass(JUnitTestClassExecutor.java:110)
	at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecutor.execute(JUnitTestClassExecutor.java:58)
	at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecutor.execute(JUnitTestClassExecutor.java:38)
	at org.gradle.api.internal.tasks.testing.junit.AbstractJUnitTestClassProcessor.processTestClass(AbstractJUnitTestClassProcessor.java:62)
	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.processTestClass(SuiteTestClassProcessor.java:51)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36)
	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)
	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:33)
	at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:94)
	at com.sun.proxy.$Proxy2.processTestClass(Unknown Source)
	at org.gradle.api.internal.tasks.testing.worker.TestWorker.processTestClass(TestWorker.java:118)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36)
	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)
	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:182)
	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:164)
	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:412)
	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:64)
	at org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:48)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at org.gradle.internal.concurrent.ThreadFactoryImpl$ManagedThreadRunnable.run(ThreadFactoryImpl.java:56)
	at java.lang.Thread.run(Thread.java:748)
[2020-01-15 10:21:35,539] DEBUG Closing selector connection 127.0.0.1:59719-127.0.0.1:59721-1 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:35,540] ERROR Exception while processing completed send to 127.0.0.1:59719-127.0.0.1:59721-1 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:76)
java.lang.IllegalStateException: Test exception during Unmute
	at kafka.network.SocketServerTest$TestableSelector.$anonfun$addFailure$1(SocketServerTest.scala:1797)
	at kafka.network.SocketServerTest$TestableSelector.addFailure(SocketServerTest.scala:1797)
	at kafka.network.SocketServerTest.$anonfun$processCompletedSendException$1(SocketServerTest.scala:1504)
	at kafka.network.SocketServerTest.processCompletedSendException(SocketServerTest.scala:1499)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecutor.runTestClass(JUnitTestClassExecutor.java:110)
	at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecutor.execute(JUnitTestClassExecutor.java:58)
	at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecutor.execute(JUnitTestClassExecutor.java:38)
	at org.gradle.api.internal.tasks.testing.junit.AbstractJUnitTestClassProcessor.processTestClass(AbstractJUnitTestClassProcessor.java:62)
	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.processTestClass(SuiteTestClassProcessor.java:51)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36)
	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)
	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:33)
	at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:94)
	at com.sun.proxy.$Proxy2.processTestClass(Unknown Source)
	at org.gradle.api.internal.tasks.testing.worker.TestWorker.processTestClass(TestWorker.java:118)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36)
	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)
	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:182)
	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:164)
	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:412)
	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:64)
	at org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:48)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at org.gradle.internal.concurrent.ThreadFactoryImpl$ManagedThreadRunnable.run(ThreadFactoryImpl.java:56)
	at java.lang.Thread.run(Thread.java:748)
[2020-01-15 10:21:35,540] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) from connection 127.0.0.1:59719-127.0.0.1:59720-0;totalTime:2.901,requestQueueTime:0.0,localTime:6.1097274883E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.246,sendTime:1.538,securityProtocol:PLAINTEXT,principal:User:ANONYMOUS,listener:PLAINTEXT,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:35,639] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:35,639] TRACE Sending PRODUCE response to client  of 26 bytes. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:35,639] TRACE Socket server received response to send to 127.0.0.1:59719-127.0.0.1:59720-0, registering for write and sending data: Response(type=Send, request=Request(processor=0, connectionId=127.0.0.1:59719-127.0.0.1:59720-0, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(PLAINTEXT), securityProtocol=PLAINTEXT, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22]), send=org.apache.kafka.common.network.NetworkSend@1c48ae89, asString=Some(RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1))) (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:54)
[2020-01-15 10:21:35,640] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) from connection 127.0.0.1:59719-127.0.0.1:59720-0;totalTime:0.727,requestQueueTime:0.0,localTime:6.1097375978E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.248,sendTime:0.324,securityProtocol:PLAINTEXT,principal:User:ANONYMOUS,listener:PLAINTEXT,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:35,741] DEBUG Accepted connection from /127.0.0.1:59735 on /127.0.0.1:59719 and assigned it to processor 0, sendBufferSize [actual|requested]: [300000|300000] recvBufferSize [actual|requested]: [310308|300000] (kafka.network.Acceptor:62)
[2020-01-15 10:21:35,741] DEBUG Processor 0 listening to new connection from /127.0.0.1:59735 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:35,742] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:35,742] TRACE Sending PRODUCE response to client  of 26 bytes. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:35,742] TRACE Socket server received response to send to 127.0.0.1:59719-127.0.0.1:59735-2, registering for write and sending data: Response(type=Send, request=Request(processor=0, connectionId=127.0.0.1:59719-127.0.0.1:59735-2, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(PLAINTEXT), securityProtocol=PLAINTEXT, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22]), send=org.apache.kafka.common.network.NetworkSend@4d803cb6, asString=Some(RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1))) (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:54)
[2020-01-15 10:21:35,742] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) from connection 127.0.0.1:59719-127.0.0.1:59735-2;totalTime:0.776,requestQueueTime:0.0,localTime:6.10974785E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.237,sendTime:0.345,securityProtocol:PLAINTEXT,principal:User:ANONYMOUS,listener:PLAINTEXT,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:35,846] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:35,846] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:35,847] DEBUG Closing server socket and selector. (kafka.network.Acceptor:62)
[2020-01-15 10:21:35,847] DEBUG Closing selector - processor 0 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:35,847] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:35,852] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:35,852] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer:66)
[2020-01-15 10:21:35,852] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:35,852] DEBUG Closing server socket and selector. (kafka.network.Acceptor:62)
[2020-01-15 10:21:35,853] DEBUG Closing selector - processor 0 (kafka.network.Processor:62)
[2020-01-15 10:21:35,853] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:35,856] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer:66)
[2020-01-15 10:21:35,924] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 60000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1500
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/b3/bhnnh3l53jjdfgphtx91qd1h0000gn/T/kafka-8585782349849680115
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections = 2147483647
	max.connections.per.ip = 5
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 1
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 50
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1500
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 300000
	socket.request.max.bytes = 100
	socket.send.buffer.bytes = 300000
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:1
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig:347)
[2020-01-15 10:21:35,928] INFO Awaiting socket connections on localhost:59744. (kafka.network.Acceptor:66)
[2020-01-15 10:21:35,929] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(localhost,0,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:35,929] DEBUG [SocketServer brokerId=0] Wait for authorizer to complete start up on listener ListenerName(PLAINTEXT) (kafka.network.SocketServerTest$TestableSocketServer:62)
[2020-01-15 10:21:35,929] DEBUG [SocketServer brokerId=0] Start processors on listener ListenerName(PLAINTEXT) (kafka.network.SocketServerTest$TestableSocketServer:62)
[2020-01-15 10:21:35,930] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:35,930] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:35,931] DEBUG Accepted connection from /127.0.0.1:59747 on /127.0.0.1:59744 and assigned it to processor 0, sendBufferSize [actual|requested]: [300000|300000] recvBufferSize [actual|requested]: [310308|300000] (kafka.network.Acceptor:62)
[2020-01-15 10:21:35,931] DEBUG Processor 0 listening to new connection from /127.0.0.1:59747 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:35,932] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:35,932] TRACE Sending PRODUCE response to client  of 26 bytes. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:35,932] TRACE Socket server received response to send to 127.0.0.1:59744-127.0.0.1:59747-0, registering for write and sending data: Response(type=Send, request=Request(processor=0, connectionId=127.0.0.1:59744-127.0.0.1:59747-0, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(PLAINTEXT), securityProtocol=PLAINTEXT, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22]), send=org.apache.kafka.common.network.NetworkSend@113db28c, asString=Some(RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1))) (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:54)
[2020-01-15 10:21:35,932] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) from connection 127.0.0.1:59744-127.0.0.1:59747-0;totalTime:0.579,requestQueueTime:0.0,localTime:6.1097668616E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.221,sendTime:0.166,securityProtocol:PLAINTEXT,principal:User:ANONYMOUS,listener:PLAINTEXT,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:35,933] ERROR Exception while processing disconnection of notAValidConnectionId (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:76)
java.lang.IllegalStateException: connectionId has unexpected format: notAValidConnectionId
	at kafka.network.Processor.$anonfun$processDisconnected$2(SocketServer.scala:953)
	at kafka.network.Processor.$anonfun$processDisconnected$1(SocketServer.scala:953)
	at kafka.network.Processor.$anonfun$processDisconnected$1$adapted(SocketServer.scala:950)
	at scala.collection.Iterator.foreach(Iterator.scala:941)
	at scala.collection.Iterator.foreach$(Iterator.scala:941)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1429)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at kafka.network.Processor.processDisconnected(SocketServer.scala:950)
	at kafka.network.Processor.run(SocketServer.scala:763)
	at java.lang.Thread.run(Thread.java:748)
[2020-01-15 10:21:36,036] DEBUG Accepted connection from /127.0.0.1:59760 on /127.0.0.1:59744 and assigned it to processor 0, sendBufferSize [actual|requested]: [300000|300000] recvBufferSize [actual|requested]: [310308|300000] (kafka.network.Acceptor:62)
[2020-01-15 10:21:36,036] DEBUG Processor 0 listening to new connection from /127.0.0.1:59760 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:36,037] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:36,037] TRACE Sending PRODUCE response to client  of 26 bytes. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:36,037] TRACE Socket server received response to send to 127.0.0.1:59744-127.0.0.1:59760-1, registering for write and sending data: Response(type=Send, request=Request(processor=0, connectionId=127.0.0.1:59744-127.0.0.1:59760-1, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(PLAINTEXT), securityProtocol=PLAINTEXT, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22]), send=org.apache.kafka.common.network.NetworkSend@1d4f77e3, asString=Some(RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1))) (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:54)
[2020-01-15 10:21:36,037] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) from connection 127.0.0.1:59744-127.0.0.1:59760-1;totalTime:0.679,requestQueueTime:0.0,localTime:6.1097773564E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.266,sendTime:0.227,securityProtocol:PLAINTEXT,principal:User:ANONYMOUS,listener:PLAINTEXT,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:36,142] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:36,142] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:36,142] DEBUG Closing server socket and selector. (kafka.network.Acceptor:62)
[2020-01-15 10:21:36,143] DEBUG Closing selector - processor 0 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:36,144] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:36,151] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:36,151] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer:66)
[2020-01-15 10:21:36,151] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:36,152] DEBUG Closing server socket and selector. (kafka.network.Acceptor:62)
[2020-01-15 10:21:36,152] DEBUG Closing selector - processor 0 (kafka.network.Processor:62)
[2020-01-15 10:21:36,152] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:36,157] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer:66)
[2020-01-15 10:21:36,428] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 60000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1500
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = SSL://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/b3/bhnnh3l53jjdfgphtx91qd1h0000gn/T/kafka-7079789593072027897
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections = 2147483647
	max.connections.per.ip = 5
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 1
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 50
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1500
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = SSL
	security.providers = null
	socket.receive.buffer.bytes = 300000
	socket.request.max.bytes = 100
	socket.send.buffer.bytes = 300000
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = [hidden]
	ssl.keymanager.algorithm = PKIX
	ssl.keystore.location = /var/folders/b3/bhnnh3l53jjdfgphtx91qd1h0000gn/T/serverKS2244298473555922261.jks
	ssl.keystore.password = [hidden]
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = /var/folders/b3/bhnnh3l53jjdfgphtx91qd1h0000gn/T/truststore3431060484476384575.jks
	ssl.truststore.password = [hidden]
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:1
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig:347)
[2020-01-15 10:21:36,434] INFO Awaiting socket connections on localhost:59780. (kafka.network.Acceptor:66)
[2020-01-15 10:21:36,461] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(localhost,0,ListenerName(SSL),SSL) (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:36,461] DEBUG [SocketServer brokerId=0] Wait for authorizer to complete start up on listener ListenerName(SSL) (kafka.network.SocketServerTest$TestableSocketServer:62)
[2020-01-15 10:21:36,461] DEBUG [SocketServer brokerId=0] Start processors on listener ListenerName(SSL) (kafka.network.SocketServerTest$TestableSocketServer:62)
[2020-01-15 10:21:36,462] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:36,462] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:36,463] DEBUG Accepted connection from /127.0.0.1:59785 on /127.0.0.1:59780 and assigned it to processor 0, sendBufferSize [actual|requested]: [300000|300000] recvBufferSize [actual|requested]: [310308|300000] (kafka.network.Acceptor:62)
[2020-01-15 10:21:36,463] DEBUG Processor 0 listening to new connection from /127.0.0.1:59785 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:36,488] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:36,590] TRACE Not sending PRODUCE response to client  as it's not required. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:36,590] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response: from connection 127.0.0.1:59780-127.0.0.1:59785-0;totalTime:102.585,requestQueueTime:0.0,localTime:6.1098326661E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.292,sendTime:0.003,securityProtocol:SSL,principal:User:ANONYMOUS,listener:SSL,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:36,590] TRACE Socket server received empty response to send, registering for read: Response(type=NoOp, request=Request(processor=0, connectionId=127.0.0.1:59780-127.0.0.1:59785-0, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(SSL), securityProtocol=SSL, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22])) (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:54)
[2020-01-15 10:21:36,591] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:36,591] TRACE Not sending PRODUCE response to client  as it's not required. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:36,591] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response: from connection 127.0.0.1:59780-127.0.0.1:59785-0;totalTime:0.325,requestQueueTime:0.0,localTime:6.1098327701E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.229,sendTime:0.001,securityProtocol:SSL,principal:User:ANONYMOUS,listener:SSL,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:36,591] TRACE Socket server received empty response to send, registering for read: Response(type=NoOp, request=Request(processor=0, connectionId=127.0.0.1:59780-127.0.0.1:59785-0, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(SSL), securityProtocol=SSL, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22])) (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:54)
[2020-01-15 10:21:36,591] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:36,591] TRACE Not sending PRODUCE response to client  as it's not required. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:36,592] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response: from connection 127.0.0.1:59780-127.0.0.1:59785-0;totalTime:0.257,requestQueueTime:0.0,localTime:6.1098328267E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.156,sendTime:0.001,securityProtocol:SSL,principal:User:ANONYMOUS,listener:SSL,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:36,592] TRACE Socket server received empty response to send, registering for read: Response(type=NoOp, request=Request(processor=0, connectionId=127.0.0.1:59780-127.0.0.1:59785-0, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(SSL), securityProtocol=SSL, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22])) (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:54)
[2020-01-15 10:21:36,592] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:36,592] TRACE Not sending PRODUCE response to client  as it's not required. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:36,592] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response: from connection 127.0.0.1:59780-127.0.0.1:59785-0;totalTime:0.267,requestQueueTime:0.0,localTime:6.1098328644E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.187,sendTime:0.002,securityProtocol:SSL,principal:User:ANONYMOUS,listener:SSL,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:36,592] TRACE Socket server received empty response to send, registering for read: Response(type=NoOp, request=Request(processor=0, connectionId=127.0.0.1:59780-127.0.0.1:59785-0, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(SSL), securityProtocol=SSL, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22])) (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:54)
[2020-01-15 10:21:36,901] DEBUG Accepted connection from /127.0.0.1:59797 on /127.0.0.1:59780 and assigned it to processor 0, sendBufferSize [actual|requested]: [300000|300000] recvBufferSize [actual|requested]: [310308|300000] (kafka.network.Acceptor:62)
[2020-01-15 10:21:36,901] DEBUG Processor 0 listening to new connection from /127.0.0.1:59797 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:36,909] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:36,909] TRACE Sending PRODUCE response to client  of 26 bytes. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:36,909] TRACE Socket server received response to send to 127.0.0.1:59780-127.0.0.1:59797-1, registering for write and sending data: Response(type=Send, request=Request(processor=0, connectionId=127.0.0.1:59780-127.0.0.1:59797-1, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(SSL), securityProtocol=SSL, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22]), send=org.apache.kafka.common.network.NetworkSend@3addc23e, asString=Some(RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1))) (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:54)
[2020-01-15 10:21:36,910] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) from connection 127.0.0.1:59780-127.0.0.1:59797-1;totalTime:0.594,requestQueueTime:0.0,localTime:6.1098646091E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.236,sendTime:0.188,securityProtocol:SSL,principal:User:ANONYMOUS,listener:SSL,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:37,013] DEBUG Accepted connection from /127.0.0.1:59800 on /127.0.0.1:59780 and assigned it to processor 0, sendBufferSize [actual|requested]: [300000|300000] recvBufferSize [actual|requested]: [310308|300000] (kafka.network.Acceptor:62)
[2020-01-15 10:21:37,013] DEBUG Processor 0 listening to new connection from /127.0.0.1:59800 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:37,024] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:37,024] TRACE Sending PRODUCE response to client  of 26 bytes. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:37,025] TRACE Socket server received response to send to 127.0.0.1:59780-127.0.0.1:59800-2, registering for write and sending data: Response(type=Send, request=Request(processor=0, connectionId=127.0.0.1:59780-127.0.0.1:59800-2, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(SSL), securityProtocol=SSL, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22]), send=org.apache.kafka.common.network.NetworkSend@62adf26d, asString=Some(RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1))) (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:54)
[2020-01-15 10:21:37,025] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) from connection 127.0.0.1:59780-127.0.0.1:59800-2;totalTime:0.781,requestQueueTime:0.0,localTime:6.109876123E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.264,sendTime:0.316,securityProtocol:SSL,principal:User:ANONYMOUS,listener:SSL,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:37,130] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:37,130] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:37,130] DEBUG Closing server socket and selector. (kafka.network.Acceptor:62)
[2020-01-15 10:21:37,131] DEBUG Closing selector - processor 0 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:37,131] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:37,135] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:37,135] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer:66)
[2020-01-15 10:21:37,135] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:37,135] DEBUG Closing server socket and selector. (kafka.network.Acceptor:62)
[2020-01-15 10:21:37,135] DEBUG Closing selector - processor 0 (kafka.network.Processor:62)
[2020-01-15 10:21:37,136] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:37,140] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer:66)
[2020-01-15 10:21:37,158] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 60000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1500
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/b3/bhnnh3l53jjdfgphtx91qd1h0000gn/T/kafka-6246722944441376031
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections = 2147483647
	max.connections.per.ip = 5
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 1
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 50
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1500
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 300000
	socket.request.max.bytes = 100
	socket.send.buffer.bytes = 300000
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:1
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig:347)
[2020-01-15 10:21:37,161] INFO Awaiting socket connections on localhost:59804. (kafka.network.Acceptor:66)
[2020-01-15 10:21:37,162] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(localhost,0,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:37,162] DEBUG [SocketServer brokerId=0] Wait for authorizer to complete start up on listener ListenerName(PLAINTEXT) (kafka.network.SocketServerTest$TestableSocketServer:62)
[2020-01-15 10:21:37,162] DEBUG [SocketServer brokerId=0] Start processors on listener ListenerName(PLAINTEXT) (kafka.network.SocketServerTest$TestableSocketServer:62)
[2020-01-15 10:21:37,163] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:37,163] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:37,165] DEBUG Accepted connection from /127.0.0.1:59805 on /127.0.0.1:59804 and assigned it to processor 0, sendBufferSize [actual|requested]: [300000|300000] recvBufferSize [actual|requested]: [310308|300000] (kafka.network.Acceptor:62)
[2020-01-15 10:21:37,165] DEBUG Accepted connection from /127.0.0.1:59806 on /127.0.0.1:59804 and assigned it to processor 0, sendBufferSize [actual|requested]: [300000|300000] recvBufferSize [actual|requested]: [310308|300000] (kafka.network.Acceptor:62)
[2020-01-15 10:21:37,165] DEBUG Processor 0 listening to new connection from /127.0.0.1:59805 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:37,165] DEBUG Processor 0 listening to new connection from /127.0.0.1:59806 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:37,165] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:37,165] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:37,166] TRACE Sending PRODUCE response to client  of 26 bytes. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:37,166] TRACE Sending PRODUCE response to client  of 26 bytes. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:37,166] TRACE Socket server received response to send to 127.0.0.1:59804-127.0.0.1:59805-0, registering for write and sending data: Response(type=Send, request=Request(processor=0, connectionId=127.0.0.1:59804-127.0.0.1:59805-0, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(PLAINTEXT), securityProtocol=PLAINTEXT, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22]), send=org.apache.kafka.common.network.NetworkSend@ccad1bc, asString=Some(RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1))) (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:54)
[2020-01-15 10:21:37,167] TRACE Socket server received response to send to 127.0.0.1:59804-127.0.0.1:59806-1, registering for write and sending data: Response(type=Send, request=Request(processor=0, connectionId=127.0.0.1:59804-127.0.0.1:59806-1, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(PLAINTEXT), securityProtocol=PLAINTEXT, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22]), send=org.apache.kafka.common.network.NetworkSend@49c85e41, asString=Some(RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1))) (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:54)
[2020-01-15 10:21:37,167] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) from connection 127.0.0.1:59804-127.0.0.1:59806-1;totalTime:1.379,requestQueueTime:0.0,localTime:6.1098902874E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.603,sendTime:0.239,securityProtocol:PLAINTEXT,principal:User:ANONYMOUS,listener:PLAINTEXT,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:37,167] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) from connection 127.0.0.1:59804-127.0.0.1:59805-0;totalTime:1.816,requestQueueTime:0.0,localTime:6.1098902708E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.194,sendTime:1.107,securityProtocol:PLAINTEXT,principal:User:ANONYMOUS,listener:PLAINTEXT,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:37,270] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:37,271] TRACE Sending PRODUCE response to client  of 26 bytes. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:37,271] TRACE Socket server received response to send to 127.0.0.1:59804-127.0.0.1:59806-1, registering for write and sending data: Response(type=Send, request=Request(processor=0, connectionId=127.0.0.1:59804-127.0.0.1:59806-1, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(PLAINTEXT), securityProtocol=PLAINTEXT, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22]), send=org.apache.kafka.common.network.NetworkSend@5a3f696e, asString=Some(RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1))) (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:54)
[2020-01-15 10:21:37,271] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) from connection 127.0.0.1:59804-127.0.0.1:59806-1;totalTime:0.689,requestQueueTime:0.0,localTime:6.1099007481E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.234,sendTime:0.261,securityProtocol:PLAINTEXT,principal:User:ANONYMOUS,listener:PLAINTEXT,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:37,373] DEBUG Accepted connection from /127.0.0.1:59814 on /127.0.0.1:59804 and assigned it to processor 0, sendBufferSize [actual|requested]: [300000|300000] recvBufferSize [actual|requested]: [310308|300000] (kafka.network.Acceptor:62)
[2020-01-15 10:21:37,373] DEBUG Processor 0 listening to new connection from /127.0.0.1:59814 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:37,373] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:37,373] TRACE Sending PRODUCE response to client  of 26 bytes. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:37,374] TRACE Socket server received response to send to 127.0.0.1:59804-127.0.0.1:59814-2, registering for write and sending data: Response(type=Send, request=Request(processor=0, connectionId=127.0.0.1:59804-127.0.0.1:59814-2, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(PLAINTEXT), securityProtocol=PLAINTEXT, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22]), send=org.apache.kafka.common.network.NetworkSend@22d6d943, asString=Some(RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1))) (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:54)
[2020-01-15 10:21:37,374] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) from connection 127.0.0.1:59804-127.0.0.1:59814-2;totalTime:0.716,requestQueueTime:0.0,localTime:6.1099110161E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.219,sendTime:0.236,securityProtocol:PLAINTEXT,principal:User:ANONYMOUS,listener:PLAINTEXT,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:37,474] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:37,474] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:37,475] DEBUG Closing server socket and selector. (kafka.network.Acceptor:62)
[2020-01-15 10:21:37,475] DEBUG Closing selector - processor 0 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:37,475] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:37,480] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:37,480] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer:66)
[2020-01-15 10:21:37,480] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:37,480] DEBUG Closing server socket and selector. (kafka.network.Acceptor:62)
[2020-01-15 10:21:37,481] DEBUG Closing selector - processor 0 (kafka.network.Processor:62)
[2020-01-15 10:21:37,481] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:37,484] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer:66)
[2020-01-15 10:21:37,497] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 60000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1500
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/b3/bhnnh3l53jjdfgphtx91qd1h0000gn/T/kafka-1919751812219868276
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections = 2147483647
	max.connections.per.ip = 5
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 1
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 50
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1500
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 300000
	socket.request.max.bytes = 100
	socket.send.buffer.bytes = 300000
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:1
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig:347)
[2020-01-15 10:21:37,501] INFO Awaiting socket connections on localhost:59823. (kafka.network.Acceptor:66)
[2020-01-15 10:21:37,502] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(localhost,0,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:37,502] DEBUG [SocketServer brokerId=0] Wait for authorizer to complete start up on listener ListenerName(PLAINTEXT) (kafka.network.SocketServerTest$TestableSocketServer:62)
[2020-01-15 10:21:37,502] DEBUG [SocketServer brokerId=0] Start processors on listener ListenerName(PLAINTEXT) (kafka.network.SocketServerTest$TestableSocketServer:62)
[2020-01-15 10:21:37,502] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:37,503] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:37,505] DEBUG Accepted connection from /127.0.0.1:59824 on /127.0.0.1:59823 and assigned it to processor 0, sendBufferSize [actual|requested]: [300000|300000] recvBufferSize [actual|requested]: [310308|300000] (kafka.network.Acceptor:62)
[2020-01-15 10:21:37,505] DEBUG Processor 0 listening to new connection from /127.0.0.1:59824 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:37,505] DEBUG Accepted connection from /127.0.0.1:59825 on /127.0.0.1:59823 and assigned it to processor 0, sendBufferSize [actual|requested]: [300000|300000] recvBufferSize [actual|requested]: [310308|300000] (kafka.network.Acceptor:62)
[2020-01-15 10:21:37,505] DEBUG Processor 0 listening to new connection from /127.0.0.1:59825 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:37,506] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:37,506] ERROR Closing socket for 127.0.0.1:59823-127.0.0.1:59824-0 because of error (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:76)
java.lang.IllegalStateException: Test exception during Mute
	at kafka.network.SocketServerTest$TestableSelector.$anonfun$addFailure$1(SocketServerTest.scala:1797)
	at kafka.network.SocketServerTest$TestableSelector.addFailure(SocketServerTest.scala:1797)
	at kafka.network.SocketServerTest.$anonfun$processCompletedReceiveException$1(SocketServerTest.scala:1476)
	at kafka.network.SocketServerTest.processCompletedReceiveException(SocketServerTest.scala:1470)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecutor.runTestClass(JUnitTestClassExecutor.java:110)
	at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecutor.execute(JUnitTestClassExecutor.java:58)
	at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecutor.execute(JUnitTestClassExecutor.java:38)
	at org.gradle.api.internal.tasks.testing.junit.AbstractJUnitTestClassProcessor.processTestClass(AbstractJUnitTestClassProcessor.java:62)
	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.processTestClass(SuiteTestClassProcessor.java:51)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36)
	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)
	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:33)
	at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:94)
	at com.sun.proxy.$Proxy2.processTestClass(Unknown Source)
	at org.gradle.api.internal.tasks.testing.worker.TestWorker.processTestClass(TestWorker.java:118)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36)
	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)
	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:182)
	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:164)
	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:412)
	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:64)
	at org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:48)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at org.gradle.internal.concurrent.ThreadFactoryImpl$ManagedThreadRunnable.run(ThreadFactoryImpl.java:56)
	at java.lang.Thread.run(Thread.java:748)
[2020-01-15 10:21:37,506] DEBUG Closing selector connection 127.0.0.1:59823-127.0.0.1:59824-0 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:37,507] ERROR Exception while processing request from 127.0.0.1:59823-127.0.0.1:59824-0 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:76)
java.lang.IllegalStateException: Test exception during Mute
	at kafka.network.SocketServerTest$TestableSelector.$anonfun$addFailure$1(SocketServerTest.scala:1797)
	at kafka.network.SocketServerTest$TestableSelector.addFailure(SocketServerTest.scala:1797)
	at kafka.network.SocketServerTest.$anonfun$processCompletedReceiveException$1(SocketServerTest.scala:1476)
	at kafka.network.SocketServerTest.processCompletedReceiveException(SocketServerTest.scala:1470)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecutor.runTestClass(JUnitTestClassExecutor.java:110)
	at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecutor.execute(JUnitTestClassExecutor.java:58)
	at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecutor.execute(JUnitTestClassExecutor.java:38)
	at org.gradle.api.internal.tasks.testing.junit.AbstractJUnitTestClassProcessor.processTestClass(AbstractJUnitTestClassProcessor.java:62)
	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.processTestClass(SuiteTestClassProcessor.java:51)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36)
	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)
	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:33)
	at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:94)
	at com.sun.proxy.$Proxy2.processTestClass(Unknown Source)
	at org.gradle.api.internal.tasks.testing.worker.TestWorker.processTestClass(TestWorker.java:118)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36)
	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)
	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:182)
	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:164)
	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:412)
	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:64)
	at org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:48)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at org.gradle.internal.concurrent.ThreadFactoryImpl$ManagedThreadRunnable.run(ThreadFactoryImpl.java:56)
	at java.lang.Thread.run(Thread.java:748)
[2020-01-15 10:21:37,507] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:37,508] TRACE Sending PRODUCE response to client  of 26 bytes. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:37,508] TRACE Sending PRODUCE response to client  of 26 bytes. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:37,508] TRACE Socket server received response to send to 127.0.0.1:59823-127.0.0.1:59824-0, registering for write and sending data: Response(type=Send, request=Request(processor=0, connectionId=127.0.0.1:59823-127.0.0.1:59824-0, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(PLAINTEXT), securityProtocol=PLAINTEXT, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22]), send=org.apache.kafka.common.network.NetworkSend@6b2b92ea, asString=Some(RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1))) (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:54)
[2020-01-15 10:21:37,508] WARN Attempting to send response via channel for which there is no open connection, connection id 127.0.0.1:59823-127.0.0.1:59824-0 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:70)
[2020-01-15 10:21:37,508] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) from connection 127.0.0.1:59823-127.0.0.1:59824-0;totalTime:2.413,requestQueueTime:0.0,localTime:6.1099244408E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.226,sendTime:0.294,securityProtocol:PLAINTEXT,principal:User:ANONYMOUS,listener:PLAINTEXT,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:37,508] TRACE Socket server received response to send to 127.0.0.1:59823-127.0.0.1:59825-1, registering for write and sending data: Response(type=Send, request=Request(processor=0, connectionId=127.0.0.1:59823-127.0.0.1:59825-1, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(PLAINTEXT), securityProtocol=PLAINTEXT, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22]), send=org.apache.kafka.common.network.NetworkSend@4444751e, asString=Some(RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1))) (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:54)
[2020-01-15 10:21:37,508] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) from connection 127.0.0.1:59823-127.0.0.1:59825-1;totalTime:1.522,requestQueueTime:0.0,localTime:6.1099244603E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.523,sendTime:0.189,securityProtocol:PLAINTEXT,principal:User:ANONYMOUS,listener:PLAINTEXT,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:37,509] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:37,509] TRACE Sending PRODUCE response to client  of 26 bytes. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:37,509] TRACE Socket server received response to send to 127.0.0.1:59823-127.0.0.1:59825-1, registering for write and sending data: Response(type=Send, request=Request(processor=0, connectionId=127.0.0.1:59823-127.0.0.1:59825-1, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(PLAINTEXT), securityProtocol=PLAINTEXT, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22]), send=org.apache.kafka.common.network.NetworkSend@5a0abd57, asString=Some(RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1))) (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:54)
[2020-01-15 10:21:37,509] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) from connection 127.0.0.1:59823-127.0.0.1:59825-1;totalTime:0.613,requestQueueTime:0.0,localTime:6.1099245633E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.202,sendTime:0.299,securityProtocol:PLAINTEXT,principal:User:ANONYMOUS,listener:PLAINTEXT,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:37,610] DEBUG Accepted connection from /127.0.0.1:59829 on /127.0.0.1:59823 and assigned it to processor 0, sendBufferSize [actual|requested]: [300000|300000] recvBufferSize [actual|requested]: [310308|300000] (kafka.network.Acceptor:62)
[2020-01-15 10:21:37,610] DEBUG Processor 0 listening to new connection from /127.0.0.1:59829 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:37,610] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:37,611] TRACE Sending PRODUCE response to client  of 26 bytes. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:37,611] TRACE Socket server received response to send to 127.0.0.1:59823-127.0.0.1:59829-2, registering for write and sending data: Response(type=Send, request=Request(processor=0, connectionId=127.0.0.1:59823-127.0.0.1:59829-2, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(PLAINTEXT), securityProtocol=PLAINTEXT, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22]), send=org.apache.kafka.common.network.NetworkSend@b046da5, asString=Some(RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1))) (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:54)
[2020-01-15 10:21:37,611] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) from connection 127.0.0.1:59823-127.0.0.1:59829-2;totalTime:0.583,requestQueueTime:0.0,localTime:6.1099347392E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.215,sendTime:0.218,securityProtocol:PLAINTEXT,principal:User:ANONYMOUS,listener:PLAINTEXT,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:37,711] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:37,712] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:37,712] DEBUG Closing server socket and selector. (kafka.network.Acceptor:62)
[2020-01-15 10:21:37,713] DEBUG Closing selector - processor 0 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:37,713] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:37,718] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:37,718] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer:66)
[2020-01-15 10:21:37,718] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:37,718] DEBUG Closing server socket and selector. (kafka.network.Acceptor:62)
[2020-01-15 10:21:37,719] DEBUG Closing selector - processor 0 (kafka.network.Processor:62)
[2020-01-15 10:21:37,719] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:37,723] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer:66)
[2020-01-15 10:21:37,805] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 60000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1500
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = SSL://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/b3/bhnnh3l53jjdfgphtx91qd1h0000gn/T/kafka-2325490942247872837
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections = 2147483647
	max.connections.per.ip = 5
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 1
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 50
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1500
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = SSL
	security.providers = null
	socket.receive.buffer.bytes = 300000
	socket.request.max.bytes = 100
	socket.send.buffer.bytes = 300000
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = [hidden]
	ssl.keymanager.algorithm = PKIX
	ssl.keystore.location = /var/folders/b3/bhnnh3l53jjdfgphtx91qd1h0000gn/T/serverKS4821897551109179048.jks
	ssl.keystore.password = [hidden]
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = /var/folders/b3/bhnnh3l53jjdfgphtx91qd1h0000gn/T/truststore7071707496165923427.jks
	ssl.truststore.password = [hidden]
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:1
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig:347)
[2020-01-15 10:21:37,809] INFO Awaiting socket connections on localhost:59839. (kafka.network.Acceptor:66)
[2020-01-15 10:21:37,848] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(localhost,0,ListenerName(SSL),SSL) (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:37,848] DEBUG [SocketServer brokerId=0] Wait for authorizer to complete start up on listener ListenerName(SSL) (kafka.network.SocketServerTest$TestableSocketServer:62)
[2020-01-15 10:21:37,848] DEBUG [SocketServer brokerId=0] Start processors on listener ListenerName(SSL) (kafka.network.SocketServerTest$TestableSocketServer:62)
[2020-01-15 10:21:37,849] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:37,849] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:37,850] DEBUG Accepted connection from /127.0.0.1:59841 on /127.0.0.1:59839 and assigned it to processor 0, sendBufferSize [actual|requested]: [300000|300000] recvBufferSize [actual|requested]: [310308|300000] (kafka.network.Acceptor:62)
[2020-01-15 10:21:37,850] DEBUG Processor 0 listening to new connection from /127.0.0.1:59841 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:37,872] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:37,974] TRACE Not sending PRODUCE response to client  as it's not required. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:37,974] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response: from connection 127.0.0.1:59839-127.0.0.1:59841-0;totalTime:102.351,requestQueueTime:0.0,localTime:6.1099710724E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.369,sendTime:0.002,securityProtocol:SSL,principal:User:ANONYMOUS,listener:SSL,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:37,975] TRACE Socket server received empty response to send, registering for read: Response(type=NoOp, request=Request(processor=0, connectionId=127.0.0.1:59839-127.0.0.1:59841-0, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(SSL), securityProtocol=SSL, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22])) (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:54)
[2020-01-15 10:21:37,975] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:37,976] DEBUG Accepted connection from /127.0.0.1:59848 on /127.0.0.1:59839 and assigned it to processor 0, sendBufferSize [actual|requested]: [300000|300000] recvBufferSize [actual|requested]: [310308|300000] (kafka.network.Acceptor:62)
[2020-01-15 10:21:37,976] DEBUG Processor 0 listening to new connection from /127.0.0.1:59848 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:37,985] TRACE Sending PRODUCE response to client  of 26 bytes. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:37,985] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:37,985] TRACE Sending PRODUCE response to client  of 26 bytes. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:37,985] TRACE Socket server received response to send to 127.0.0.1:59839-127.0.0.1:59841-0, registering for write and sending data: Response(type=Send, request=Request(processor=0, connectionId=127.0.0.1:59839-127.0.0.1:59841-0, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(SSL), securityProtocol=SSL, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22]), send=org.apache.kafka.common.network.NetworkSend@21ac550b, asString=Some(RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1))) (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:54)
[2020-01-15 10:21:37,986] WARN Attempting to send response via channel for which there is no open connection, connection id 127.0.0.1:59839-127.0.0.1:59841-0 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:70)
[2020-01-15 10:21:37,986] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) from connection 127.0.0.1:59839-127.0.0.1:59841-0;totalTime:10.734,requestQueueTime:0.0,localTime:6.1099721829E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.336,sendTime:0.285,securityProtocol:SSL,principal:User:ANONYMOUS,listener:SSL,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:37,986] TRACE Socket server received response to send to 127.0.0.1:59839-127.0.0.1:59848-1, registering for write and sending data: Response(type=Send, request=Request(processor=0, connectionId=127.0.0.1:59839-127.0.0.1:59848-1, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(SSL), securityProtocol=SSL, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22]), send=org.apache.kafka.common.network.NetworkSend@64aecf5a, asString=Some(RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1))) (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:54)
[2020-01-15 10:21:37,986] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) from connection 127.0.0.1:59839-127.0.0.1:59848-1;totalTime:1.114,requestQueueTime:0.0,localTime:6.1099722168E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.423,sendTime:0.383,securityProtocol:SSL,principal:User:ANONYMOUS,listener:SSL,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:37,986] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) from connection 127.0.0.1:59839-127.0.0.1:59841-0;totalTime:11.482,requestQueueTime:0.0,localTime:6.1099721829E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.336,sendTime:1.033,securityProtocol:SSL,principal:User:ANONYMOUS,listener:SSL,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:38,089] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:38,089] TRACE Sending PRODUCE response to client  of 26 bytes. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:38,089] TRACE Socket server received response to send to 127.0.0.1:59839-127.0.0.1:59848-1, registering for write and sending data: Response(type=Send, request=Request(processor=0, connectionId=127.0.0.1:59839-127.0.0.1:59848-1, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(SSL), securityProtocol=SSL, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22]), send=org.apache.kafka.common.network.NetworkSend@6e839252, asString=Some(RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1))) (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:54)
[2020-01-15 10:21:38,089] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) from connection 127.0.0.1:59839-127.0.0.1:59848-1;totalTime:0.854,requestQueueTime:0.0,localTime:6.1099825684E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.27,sendTime:0.344,securityProtocol:SSL,principal:User:ANONYMOUS,listener:SSL,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:38,190] DEBUG Accepted connection from /127.0.0.1:59860 on /127.0.0.1:59839 and assigned it to processor 0, sendBufferSize [actual|requested]: [300000|300000] recvBufferSize [actual|requested]: [310308|300000] (kafka.network.Acceptor:62)
[2020-01-15 10:21:38,190] DEBUG Processor 0 listening to new connection from /127.0.0.1:59860 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:38,197] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:38,198] TRACE Sending PRODUCE response to client  of 26 bytes. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:38,198] TRACE Socket server received response to send to 127.0.0.1:59839-127.0.0.1:59860-2, registering for write and sending data: Response(type=Send, request=Request(processor=0, connectionId=127.0.0.1:59839-127.0.0.1:59860-2, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(SSL), securityProtocol=SSL, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22]), send=org.apache.kafka.common.network.NetworkSend@16c7e988, asString=Some(RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1))) (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:54)
[2020-01-15 10:21:38,198] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) from connection 127.0.0.1:59839-127.0.0.1:59860-2;totalTime:0.759,requestQueueTime:0.0,localTime:6.1099934377E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.33,sendTime:0.213,securityProtocol:SSL,principal:User:ANONYMOUS,listener:SSL,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:38,300] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:38,301] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:38,301] DEBUG Closing server socket and selector. (kafka.network.Acceptor:62)
[2020-01-15 10:21:38,301] DEBUG Closing selector - processor 0 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:38,301] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:38,305] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:38,305] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer:66)
[2020-01-15 10:21:38,305] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:38,306] DEBUG Closing server socket and selector. (kafka.network.Acceptor:62)
[2020-01-15 10:21:38,306] DEBUG Closing selector - processor 0 (kafka.network.Processor:62)
[2020-01-15 10:21:38,306] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:38,312] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer:66)
[2020-01-15 10:21:38,672] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 60000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1500
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = SSL://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/b3/bhnnh3l53jjdfgphtx91qd1h0000gn/T/kafka-2661136210536134636
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections = 2147483647
	max.connections.per.ip = 5
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 1
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 50
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1500
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = SSL
	security.providers = null
	socket.receive.buffer.bytes = 300000
	socket.request.max.bytes = 100
	socket.send.buffer.bytes = 300000
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = [hidden]
	ssl.keymanager.algorithm = PKIX
	ssl.keystore.location = /var/folders/b3/bhnnh3l53jjdfgphtx91qd1h0000gn/T/serverKS3589672167325212031.jks
	ssl.keystore.password = [hidden]
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = /var/folders/b3/bhnnh3l53jjdfgphtx91qd1h0000gn/T/truststore2060378012928680564.jks
	ssl.truststore.password = [hidden]
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:1
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig:347)
[2020-01-15 10:21:38,678] INFO Awaiting socket connections on localhost:59876. (kafka.network.Acceptor:66)
[2020-01-15 10:21:38,706] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(localhost,0,ListenerName(SSL),SSL) (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:38,707] DEBUG [SocketServer brokerId=0] Wait for authorizer to complete start up on listener ListenerName(SSL) (kafka.network.SocketServerTest$TestableSocketServer:62)
[2020-01-15 10:21:38,707] DEBUG [SocketServer brokerId=0] Start processors on listener ListenerName(SSL) (kafka.network.SocketServerTest$TestableSocketServer:62)
[2020-01-15 10:21:38,707] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:38,707] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:38,709] DEBUG Accepted connection from /127.0.0.1:59882 on /127.0.0.1:59876 and assigned it to processor 0, sendBufferSize [actual|requested]: [300000|300000] recvBufferSize [actual|requested]: [310308|300000] (kafka.network.Acceptor:62)
[2020-01-15 10:21:38,709] DEBUG Processor 0 listening to new connection from /127.0.0.1:59882 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:38,737] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:39,749] DEBUG Accepted connection from /127.0.0.1:59920 on /127.0.0.1:59876 and assigned it to processor 0, sendBufferSize [actual|requested]: [300000|300000] recvBufferSize [actual|requested]: [310308|300000] (kafka.network.Acceptor:62)
[2020-01-15 10:21:39,749] DEBUG Processor 0 listening to new connection from /127.0.0.1:59920 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:39,759] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:39,759] TRACE Sending PRODUCE response to client  of 26 bytes. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:39,759] TRACE Socket server received response to send to 127.0.0.1:59876-127.0.0.1:59920-1, registering for write and sending data: Response(type=Send, request=Request(processor=0, connectionId=127.0.0.1:59876-127.0.0.1:59920-1, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(SSL), securityProtocol=SSL, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22]), send=org.apache.kafka.common.network.NetworkSend@3851a3, asString=Some(RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1))) (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:54)
[2020-01-15 10:21:39,760] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) from connection 127.0.0.1:59876-127.0.0.1:59920-1;totalTime:0.0,requestQueueTime:0.0,localTime:6.1101495705E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.325,sendTime:0.297,securityProtocol:SSL,principal:User:ANONYMOUS,listener:SSL,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:39,865] DEBUG Accepted connection from /127.0.0.1:59936 on /127.0.0.1:59876 and assigned it to processor 0, sendBufferSize [actual|requested]: [300000|300000] recvBufferSize [actual|requested]: [310308|300000] (kafka.network.Acceptor:62)
[2020-01-15 10:21:39,865] DEBUG Processor 0 listening to new connection from /127.0.0.1:59936 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:39,873] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:39,873] TRACE Sending PRODUCE response to client  of 26 bytes. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:39,873] TRACE Socket server received response to send to 127.0.0.1:59876-127.0.0.1:59936-2, registering for write and sending data: Response(type=Send, request=Request(processor=0, connectionId=127.0.0.1:59876-127.0.0.1:59936-2, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(SSL), securityProtocol=SSL, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22]), send=org.apache.kafka.common.network.NetworkSend@4ea76316, asString=Some(RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1))) (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:54)
[2020-01-15 10:21:39,874] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) from connection 127.0.0.1:59876-127.0.0.1:59936-2;totalTime:0.0,requestQueueTime:0.0,localTime:6.1101609882E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.196,sendTime:0.221,securityProtocol:SSL,principal:User:ANONYMOUS,listener:SSL,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:39,975] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:39,975] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:39,975] DEBUG Closing server socket and selector. (kafka.network.Acceptor:62)
[2020-01-15 10:21:39,976] DEBUG Closing selector - processor 0 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:39,976] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:39,980] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:39,981] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer:66)
[2020-01-15 10:21:39,981] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:39,981] DEBUG Closing server socket and selector. (kafka.network.Acceptor:62)
[2020-01-15 10:21:39,981] DEBUG Closing selector - processor 0 (kafka.network.Processor:62)
[2020-01-15 10:21:39,982] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:39,985] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer:66)
[2020-01-15 10:21:39,995] DEBUG Accepted connection from /127.0.0.1:59970 on /127.0.0.1:59969 and assigned it to processor 0, sendBufferSize [actual|requested]: [300000|300000] recvBufferSize [actual|requested]: [310308|300000] (kafka.network.Acceptor:62)
[2020-01-15 10:21:39,995] DEBUG Processor 0 listening to new connection from /127.0.0.1:59970 (kafka.network.Processor:62)
[2020-01-15 10:21:39,995] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=0, clientId=, correlationId=0) -- {acks=0,timeout=0,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:39,995] TRACE Sending PRODUCE response to client  of 24 bytes. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:39,995] TRACE Socket server received response to send to 127.0.0.1:59969-127.0.0.1:59970-0, registering for write and sending data: Response(type=Send, request=Request(processor=0, connectionId=127.0.0.1:59969-127.0.0.1:59970-0, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(PLAINTEXT), securityProtocol=PLAINTEXT, buffer=java.nio.HeapByteBuffer[pos=20 lim=42 cap=42]), send=org.apache.kafka.common.network.NetworkSend@552a48f5, asString=Some(RequestHeader(apiKey=PRODUCE, apiVersion=0, clientId=, correlationId=0))) (kafka.network.Processor:54)
[2020-01-15 10:21:39,996] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=0, clientId=, correlationId=0) -- {acks=0,timeout=0,partitionSizes=[]},response:RequestHeader(apiKey=PRODUCE, apiVersion=0, clientId=, correlationId=0) from connection 127.0.0.1:59969-127.0.0.1:59970-0;totalTime:0.539,requestQueueTime:0.0,localTime:6.1101731942E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.206,sendTime:0.204,securityProtocol:PLAINTEXT,principal:User:ANONYMOUS,listener:PLAINTEXT,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:40,198] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer:66)
[2020-01-15 10:21:40,198] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:40,198] DEBUG Closing server socket and selector. (kafka.network.Acceptor:62)
[2020-01-15 10:21:40,199] DEBUG Closing selector - processor 0 (kafka.network.Processor:62)
[2020-01-15 10:21:40,199] DEBUG Closing selector connection 127.0.0.1:59969-127.0.0.1:59970-0 (kafka.network.Processor:62)
[2020-01-15 10:21:40,200] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:40,204] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer:66)
[2020-01-15 10:21:40,204] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer:66)
[2020-01-15 10:21:40,207] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer:66)
[2020-01-15 10:21:40,214] DEBUG Accepted connection from /127.0.0.1:59987 on /127.0.0.1:59986 and assigned it to processor 0, sendBufferSize [actual|requested]: [300000|300000] recvBufferSize [actual|requested]: [310308|300000] (kafka.network.Acceptor:62)
[2020-01-15 10:21:40,214] DEBUG Processor 0 listening to new connection from /127.0.0.1:59987 (kafka.network.Processor:62)
[2020-01-15 10:21:40,215] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:40,215] TRACE Notifying channel throttling has started for client  for PRODUCE (kafka.network.RequestChannel:54)
[2020-01-15 10:21:40,215] TRACE Not sending PRODUCE response to client  as it's not required. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:40,215] TRACE Channel throttled for: 100 ms (kafka.server.ThrottledChannel:54)
[2020-01-15 10:21:40,215] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response: from connection 127.0.0.1:59986-127.0.0.1:59987-0;totalTime:0.57,requestQueueTime:0.0,localTime:6.1101951701E7,remoteTime:0.2,throttleTime:0.0,responseQueueTime:0.2,sendTime:0.001,securityProtocol:PLAINTEXT,principal:User:ANONYMOUS,listener:PLAINTEXT,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:40,215] TRACE Notifying channel throttling has ended for client  for PRODUCE (kafka.network.RequestChannel:54)
[2020-01-15 10:21:40,215] TRACE Socket server received empty response to send, registering for read: Response(type=NoOp, request=Request(processor=0, connectionId=127.0.0.1:59986-127.0.0.1:59987-0, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(PLAINTEXT), securityProtocol=PLAINTEXT, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22])) (kafka.network.Processor:54)
[2020-01-15 10:21:40,319] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer:66)
[2020-01-15 10:21:40,319] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:40,319] DEBUG Closing server socket and selector. (kafka.network.Acceptor:62)
[2020-01-15 10:21:40,320] DEBUG Closing selector - processor 0 (kafka.network.Processor:62)
[2020-01-15 10:21:40,320] DEBUG Closing selector connection 127.0.0.1:59986-127.0.0.1:59987-0 (kafka.network.Processor:62)
[2020-01-15 10:21:40,320] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:40,324] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer:66)
[2020-01-15 10:21:40,332] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 60000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1500
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/b3/bhnnh3l53jjdfgphtx91qd1h0000gn/T/kafka-8628537960181707576
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections = 2147483647
	max.connections.per.ip = 5
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 1
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 50
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1500
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 300000
	socket.request.max.bytes = 100
	socket.send.buffer.bytes = 300000
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:1
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig:347)
[2020-01-15 10:21:40,336] INFO Awaiting socket connections on localhost:59998. (kafka.network.Acceptor:66)
[2020-01-15 10:21:40,337] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(localhost,0,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:40,337] DEBUG [SocketServer brokerId=0] Wait for authorizer to complete start up on listener ListenerName(PLAINTEXT) (kafka.network.SocketServerTest$TestableSocketServer:62)
[2020-01-15 10:21:40,338] DEBUG [SocketServer brokerId=0] Start processors on listener ListenerName(PLAINTEXT) (kafka.network.SocketServerTest$TestableSocketServer:62)
[2020-01-15 10:21:40,338] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:40,339] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:40,340] DEBUG Accepted connection from /127.0.0.1:59999 on /127.0.0.1:59998 and assigned it to processor 0, sendBufferSize [actual|requested]: [300000|300000] recvBufferSize [actual|requested]: [310308|300000] (kafka.network.Acceptor:62)
[2020-01-15 10:21:40,340] DEBUG Processor 0 listening to new connection from /127.0.0.1:59999 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:40,340] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:40,340] TRACE Sending PRODUCE response to client  of 26 bytes. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:40,341] TRACE Socket server received response to send to 127.0.0.1:59998-127.0.0.1:59999-0, registering for write and sending data: Response(type=Send, request=Request(processor=0, connectionId=127.0.0.1:59998-127.0.0.1:59999-0, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(PLAINTEXT), securityProtocol=PLAINTEXT, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22]), send=org.apache.kafka.common.network.NetworkSend@7f9fe427, asString=Some(RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1))) (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:54)
[2020-01-15 10:21:40,342] ERROR Processor 0 poll failed (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:76)
java.lang.IllegalStateException: Test exception during Poll
	at kafka.network.SocketServerTest$TestableSelector.$anonfun$addFailure$1(SocketServerTest.scala:1797)
	at kafka.network.SocketServerTest$TestableSelector.addFailure(SocketServerTest.scala:1797)
	at kafka.network.SocketServerTest.$anonfun$pollException$1(SocketServerTest.scala:1549)
	at kafka.network.SocketServerTest.pollException(SocketServerTest.scala:1545)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecutor.runTestClass(JUnitTestClassExecutor.java:110)
	at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecutor.execute(JUnitTestClassExecutor.java:58)
	at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecutor.execute(JUnitTestClassExecutor.java:38)
	at org.gradle.api.internal.tasks.testing.junit.AbstractJUnitTestClassProcessor.processTestClass(AbstractJUnitTestClassProcessor.java:62)
	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.processTestClass(SuiteTestClassProcessor.java:51)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36)
	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)
	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:33)
	at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:94)
	at com.sun.proxy.$Proxy2.processTestClass(Unknown Source)
	at org.gradle.api.internal.tasks.testing.worker.TestWorker.processTestClass(TestWorker.java:118)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36)
	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)
	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:182)
	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:164)
	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:412)
	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:64)
	at org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:48)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at org.gradle.internal.concurrent.ThreadFactoryImpl$ManagedThreadRunnable.run(ThreadFactoryImpl.java:56)
	at java.lang.Thread.run(Thread.java:748)
[2020-01-15 10:21:40,343] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) from connection 127.0.0.1:59998-127.0.0.1:59999-0;totalTime:2.236,requestQueueTime:0.0,localTime:6.110207724E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.228,sendTime:1.853,securityProtocol:PLAINTEXT,principal:User:ANONYMOUS,listener:PLAINTEXT,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:40,648] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:40,648] TRACE Sending PRODUCE response to client  of 26 bytes. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:40,649] TRACE Socket server received response to send to 127.0.0.1:59998-127.0.0.1:59999-0, registering for write and sending data: Response(type=Send, request=Request(processor=0, connectionId=127.0.0.1:59998-127.0.0.1:59999-0, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(PLAINTEXT), securityProtocol=PLAINTEXT, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22]), send=org.apache.kafka.common.network.NetworkSend@fd61556, asString=Some(RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1))) (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:54)
[2020-01-15 10:21:40,649] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) from connection 127.0.0.1:59998-127.0.0.1:59999-0;totalTime:0.871,requestQueueTime:0.0,localTime:6.1102385136E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.305,sendTime:0.318,securityProtocol:PLAINTEXT,principal:User:ANONYMOUS,listener:PLAINTEXT,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:40,749] DEBUG Accepted connection from /127.0.0.1:60053 on /127.0.0.1:59998 and assigned it to processor 0, sendBufferSize [actual|requested]: [300000|300000] recvBufferSize [actual|requested]: [310308|300000] (kafka.network.Acceptor:62)
[2020-01-15 10:21:40,749] DEBUG Processor 0 listening to new connection from /127.0.0.1:60053 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:40,750] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:40,750] TRACE Sending PRODUCE response to client  of 26 bytes. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:40,750] TRACE Socket server received response to send to 127.0.0.1:59998-127.0.0.1:60053-1, registering for write and sending data: Response(type=Send, request=Request(processor=0, connectionId=127.0.0.1:59998-127.0.0.1:60053-1, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(PLAINTEXT), securityProtocol=PLAINTEXT, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22]), send=org.apache.kafka.common.network.NetworkSend@5e8d1153, asString=Some(RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1))) (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:54)
[2020-01-15 10:21:40,750] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) from connection 127.0.0.1:59998-127.0.0.1:60053-1;totalTime:0.471,requestQueueTime:0.0,localTime:6.110248659E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.211,sendTime:0.14,securityProtocol:PLAINTEXT,principal:User:ANONYMOUS,listener:PLAINTEXT,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:40,851] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:40,852] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:40,852] DEBUG Closing server socket and selector. (kafka.network.Acceptor:62)
[2020-01-15 10:21:40,852] DEBUG Closing selector - processor 0 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:40,852] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:40,857] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:40,858] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer:66)
[2020-01-15 10:21:40,858] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:40,859] DEBUG Closing server socket and selector. (kafka.network.Acceptor:62)
[2020-01-15 10:21:40,859] DEBUG Closing selector - processor 0 (kafka.network.Processor:62)
[2020-01-15 10:21:40,859] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:40,862] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer:66)
[2020-01-15 10:21:40,912] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 60000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1500
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = SSL://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/b3/bhnnh3l53jjdfgphtx91qd1h0000gn/T/kafka-6711701776892354360
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections = 2147483647
	max.connections.per.ip = 5
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 1
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 50
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1500
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = SSL
	security.providers = null
	socket.receive.buffer.bytes = 300000
	socket.request.max.bytes = 100
	socket.send.buffer.bytes = 300000
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = [hidden]
	ssl.keymanager.algorithm = PKIX
	ssl.keystore.location = /var/folders/b3/bhnnh3l53jjdfgphtx91qd1h0000gn/T/serverKS5867536660058262166.jks
	ssl.keystore.password = [hidden]
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = /var/folders/b3/bhnnh3l53jjdfgphtx91qd1h0000gn/T/truststore1597842278681806630.jks
	ssl.truststore.password = [hidden]
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:1
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig:347)
[2020-01-15 10:21:40,915] INFO Awaiting socket connections on localhost:60061. (kafka.network.Acceptor:66)
[2020-01-15 10:21:40,934] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(localhost,0,ListenerName(SSL),SSL) (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:40,934] DEBUG [SocketServer brokerId=0] Wait for authorizer to complete start up on listener ListenerName(SSL) (kafka.network.SocketServerTest$TestableSocketServer:62)
[2020-01-15 10:21:40,934] DEBUG [SocketServer brokerId=0] Start processors on listener ListenerName(SSL) (kafka.network.SocketServerTest$TestableSocketServer:62)
[2020-01-15 10:21:40,934] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:40,935] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:40,936] DEBUG Accepted connection from /127.0.0.1:60063 on /127.0.0.1:60061 and assigned it to processor 0, sendBufferSize [actual|requested]: [300000|300000] recvBufferSize [actual|requested]: [310308|300000] (kafka.network.Acceptor:62)
[2020-01-15 10:21:40,936] DEBUG Processor 0 listening to new connection from /127.0.0.1:60063 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:40,961] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:41,066] TRACE Not sending PRODUCE response to client  as it's not required. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:41,067] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response: from connection 127.0.0.1:60061-127.0.0.1:60063-0;totalTime:105.29,requestQueueTime:0.0,localTime:6.110280294E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.433,sendTime:0.001,securityProtocol:SSL,principal:User:ANONYMOUS,listener:SSL,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:41,067] TRACE Socket server received empty response to send, registering for read: Response(type=NoOp, request=Request(processor=0, connectionId=127.0.0.1:60061-127.0.0.1:60063-0, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(SSL), securityProtocol=SSL, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22])) (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:54)
[2020-01-15 10:21:41,067] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:41,067] TRACE Not sending PRODUCE response to client  as it's not required. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:41,068] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response: from connection 127.0.0.1:60061-127.0.0.1:60063-0;totalTime:0.407,requestQueueTime:0.0,localTime:6.1102804106E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.281,sendTime:0.0,securityProtocol:SSL,principal:User:ANONYMOUS,listener:SSL,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:41,068] TRACE Socket server received empty response to send, registering for read: Response(type=NoOp, request=Request(processor=0, connectionId=127.0.0.1:60061-127.0.0.1:60063-0, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(SSL), securityProtocol=SSL, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22])) (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:54)
[2020-01-15 10:21:41,068] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:41,068] TRACE Sending PRODUCE response to client  of 26 bytes. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:41,068] TRACE Socket server received response to send to 127.0.0.1:60061-127.0.0.1:60063-0, registering for write and sending data: Response(type=Send, request=Request(processor=0, connectionId=127.0.0.1:60061-127.0.0.1:60063-0, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(SSL), securityProtocol=SSL, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22]), send=org.apache.kafka.common.network.NetworkSend@2f7215ee, asString=Some(RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1))) (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:54)
[2020-01-15 10:21:41,069] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) from connection 127.0.0.1:60061-127.0.0.1:60063-0;totalTime:0.886,requestQueueTime:0.0,localTime:6.1102804749E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.259,sendTime:0.479,securityProtocol:SSL,principal:User:ANONYMOUS,listener:SSL,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:41,171] DEBUG Accepted connection from /127.0.0.1:60072 on /127.0.0.1:60061 and assigned it to processor 0, sendBufferSize [actual|requested]: [300000|300000] recvBufferSize [actual|requested]: [310308|300000] (kafka.network.Acceptor:62)
[2020-01-15 10:21:41,171] DEBUG Processor 0 listening to new connection from /127.0.0.1:60072 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:41,179] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:41,179] TRACE Sending PRODUCE response to client  of 26 bytes. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:41,179] TRACE Socket server received response to send to 127.0.0.1:60061-127.0.0.1:60072-1, registering for write and sending data: Response(type=Send, request=Request(processor=0, connectionId=127.0.0.1:60061-127.0.0.1:60072-1, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(SSL), securityProtocol=SSL, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22]), send=org.apache.kafka.common.network.NetworkSend@6e4f1fd5, asString=Some(RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1))) (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:54)
[2020-01-15 10:21:41,179] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) from connection 127.0.0.1:60061-127.0.0.1:60072-1;totalTime:0.695,requestQueueTime:0.0,localTime:6.1102915721E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.277,sendTime:0.203,securityProtocol:SSL,principal:User:ANONYMOUS,listener:SSL,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:41,285] DEBUG Processor 0 listening to new connection from /127.0.0.1:60081 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:41,285] DEBUG Accepted connection from /127.0.0.1:60081 on /127.0.0.1:60061 and assigned it to processor 0, sendBufferSize [actual|requested]: [300000|300000] recvBufferSize [actual|requested]: [310308|300000] (kafka.network.Acceptor:62)
[2020-01-15 10:21:41,293] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:41,294] TRACE Sending PRODUCE response to client  of 26 bytes. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:41,294] TRACE Socket server received response to send to 127.0.0.1:60061-127.0.0.1:60081-2, registering for write and sending data: Response(type=Send, request=Request(processor=0, connectionId=127.0.0.1:60061-127.0.0.1:60081-2, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(SSL), securityProtocol=SSL, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22]), send=org.apache.kafka.common.network.NetworkSend@5f6b5181, asString=Some(RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1))) (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:54)
[2020-01-15 10:21:41,294] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) from connection 127.0.0.1:60061-127.0.0.1:60081-2;totalTime:0.891,requestQueueTime:0.0,localTime:6.1103030344E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.338,sendTime:0.365,securityProtocol:SSL,principal:User:ANONYMOUS,listener:SSL,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:41,399] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:41,400] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:41,400] DEBUG Closing server socket and selector. (kafka.network.Acceptor:62)
[2020-01-15 10:21:41,400] DEBUG Closing selector - processor 0 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:41,400] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:41,404] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:41,404] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer:66)
[2020-01-15 10:21:41,404] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:41,404] DEBUG Closing server socket and selector. (kafka.network.Acceptor:62)
[2020-01-15 10:21:41,404] DEBUG Closing selector - processor 0 (kafka.network.Processor:62)
[2020-01-15 10:21:41,405] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:41,408] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer:66)
[2020-01-15 10:21:41,681] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 60000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1500
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = SSL://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/b3/bhnnh3l53jjdfgphtx91qd1h0000gn/T/kafka-6899837107237477113
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections = 2147483647
	max.connections.per.ip = 5
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 1
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 50
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1500
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = SSL
	security.providers = null
	socket.receive.buffer.bytes = 300000
	socket.request.max.bytes = 100
	socket.send.buffer.bytes = 300000
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = [hidden]
	ssl.keymanager.algorithm = PKIX
	ssl.keystore.location = /var/folders/b3/bhnnh3l53jjdfgphtx91qd1h0000gn/T/serverKS2959890861682483157.jks
	ssl.keystore.password = [hidden]
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = /var/folders/b3/bhnnh3l53jjdfgphtx91qd1h0000gn/T/truststore4391696544698153325.jks
	ssl.truststore.password = [hidden]
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:1
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig:347)
[2020-01-15 10:21:41,685] INFO Awaiting socket connections on localhost:60106. (kafka.network.Acceptor:66)
[2020-01-15 10:21:41,705] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(localhost,0,ListenerName(SSL),SSL) (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:41,705] DEBUG [SocketServer brokerId=0] Wait for authorizer to complete start up on listener ListenerName(SSL) (kafka.network.SocketServerTest$TestableSocketServer:62)
[2020-01-15 10:21:41,705] DEBUG [SocketServer brokerId=0] Start processors on listener ListenerName(SSL) (kafka.network.SocketServerTest$TestableSocketServer:62)
[2020-01-15 10:21:41,705] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:41,706] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:41,706] DEBUG Accepted connection from /127.0.0.1:60108 on /127.0.0.1:60106 and assigned it to processor 0, sendBufferSize [actual|requested]: [300000|300000] recvBufferSize [actual|requested]: [310308|300000] (kafka.network.Acceptor:62)
[2020-01-15 10:21:41,706] DEBUG Processor 0 listening to new connection from /127.0.0.1:60108 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:41,728] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:41,829] TRACE Not sending PRODUCE response to client  as it's not required. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:41,830] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response: from connection 127.0.0.1:60106-127.0.0.1:60108-0;totalTime:101.761,requestQueueTime:0.0,localTime:6.1103566011E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.402,sendTime:0.022,securityProtocol:SSL,principal:User:ANONYMOUS,listener:SSL,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:41,830] TRACE Socket server received empty response to send, registering for read: Response(type=NoOp, request=Request(processor=0, connectionId=127.0.0.1:60106-127.0.0.1:60108-0, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(SSL), securityProtocol=SSL, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22])) (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:54)
[2020-01-15 10:21:41,830] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:41,831] TRACE Not sending PRODUCE response to client  as it's not required. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:41,831] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response: from connection 127.0.0.1:60106-127.0.0.1:60108-0;totalTime:0.418,requestQueueTime:0.0,localTime:6.1103567373E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.254,sendTime:0.001,securityProtocol:SSL,principal:User:ANONYMOUS,listener:SSL,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:41,831] TRACE Socket server received empty response to send, registering for read: Response(type=NoOp, request=Request(processor=0, connectionId=127.0.0.1:60106-127.0.0.1:60108-0, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(SSL), securityProtocol=SSL, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22])) (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:54)
[2020-01-15 10:21:41,831] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:41,831] TRACE Not sending PRODUCE response to client  as it's not required. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:41,831] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response: from connection 127.0.0.1:60106-127.0.0.1:60108-0;totalTime:0.319,requestQueueTime:0.0,localTime:6.1103568045E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.212,sendTime:0.001,securityProtocol:SSL,principal:User:ANONYMOUS,listener:SSL,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:41,832] TRACE Socket server received empty response to send, registering for read: Response(type=NoOp, request=Request(processor=0, connectionId=127.0.0.1:60106-127.0.0.1:60108-0, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(SSL), securityProtocol=SSL, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22])) (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:54)
[2020-01-15 10:21:41,832] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:41,832] TRACE Not sending PRODUCE response to client  as it's not required. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:41,832] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response: from connection 127.0.0.1:60106-127.0.0.1:60108-0;totalTime:0.251,requestQueueTime:0.0,localTime:6.1103568503E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.177,sendTime:0.0,securityProtocol:SSL,principal:User:ANONYMOUS,listener:SSL,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:41,832] TRACE Socket server received empty response to send, registering for read: Response(type=NoOp, request=Request(processor=0, connectionId=127.0.0.1:60106-127.0.0.1:60108-0, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(SSL), securityProtocol=SSL, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22])) (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:54)
[2020-01-15 10:21:41,937] DEBUG Accepted connection from /127.0.0.1:60121 on /127.0.0.1:60106 and assigned it to processor 0, sendBufferSize [actual|requested]: [300000|300000] recvBufferSize [actual|requested]: [310308|300000] (kafka.network.Acceptor:62)
[2020-01-15 10:21:41,937] DEBUG Processor 0 listening to new connection from /127.0.0.1:60121 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:41,945] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:41,945] TRACE Sending PRODUCE response to client  of 26 bytes. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:41,945] TRACE Socket server received response to send to 127.0.0.1:60106-127.0.0.1:60121-1, registering for write and sending data: Response(type=Send, request=Request(processor=0, connectionId=127.0.0.1:60106-127.0.0.1:60121-1, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(SSL), securityProtocol=SSL, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22]), send=org.apache.kafka.common.network.NetworkSend@5097b81d, asString=Some(RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1))) (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:54)
[2020-01-15 10:21:41,945] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) from connection 127.0.0.1:60106-127.0.0.1:60121-1;totalTime:0.928,requestQueueTime:0.0,localTime:6.1103681602E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.318,sendTime:0.338,securityProtocol:SSL,principal:User:ANONYMOUS,listener:SSL,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:42,048] DEBUG Accepted connection from /127.0.0.1:60125 on /127.0.0.1:60106 and assigned it to processor 0, sendBufferSize [actual|requested]: [300000|300000] recvBufferSize [actual|requested]: [310308|300000] (kafka.network.Acceptor:62)
[2020-01-15 10:21:42,048] DEBUG Processor 0 listening to new connection from /127.0.0.1:60125 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:42,059] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:42,059] TRACE Sending PRODUCE response to client  of 26 bytes. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:42,059] TRACE Socket server received response to send to 127.0.0.1:60106-127.0.0.1:60125-2, registering for write and sending data: Response(type=Send, request=Request(processor=0, connectionId=127.0.0.1:60106-127.0.0.1:60125-2, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(SSL), securityProtocol=SSL, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22]), send=org.apache.kafka.common.network.NetworkSend@31c5710f, asString=Some(RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1))) (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:54)
[2020-01-15 10:21:42,060] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) from connection 127.0.0.1:60106-127.0.0.1:60125-2;totalTime:0.746,requestQueueTime:0.0,localTime:6.1103795547E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.3,sendTime:0.261,securityProtocol:SSL,principal:User:ANONYMOUS,listener:SSL,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:42,163] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:42,163] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:42,164] DEBUG Closing server socket and selector. (kafka.network.Acceptor:62)
[2020-01-15 10:21:42,164] DEBUG Closing selector - processor 0 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:42,164] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:42,168] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:42,168] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer:66)
[2020-01-15 10:21:42,169] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:42,169] DEBUG Closing server socket and selector. (kafka.network.Acceptor:62)
[2020-01-15 10:21:42,169] DEBUG Closing selector - processor 0 (kafka.network.Processor:62)
[2020-01-15 10:21:42,169] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:42,173] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer:66)
[2020-01-15 10:21:42,313] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 60000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1500
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = SSL://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/b3/bhnnh3l53jjdfgphtx91qd1h0000gn/T/kafka-6081393740477904744
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections = 2147483647
	max.connections.per.ip = 5
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 1
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 50
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1500
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = SSL
	security.providers = null
	socket.receive.buffer.bytes = 300000
	socket.request.max.bytes = 100
	socket.send.buffer.bytes = 300000
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = [hidden]
	ssl.keymanager.algorithm = PKIX
	ssl.keystore.location = /var/folders/b3/bhnnh3l53jjdfgphtx91qd1h0000gn/T/serverKS1254096300473928972.jks
	ssl.keystore.password = [hidden]
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = /var/folders/b3/bhnnh3l53jjdfgphtx91qd1h0000gn/T/truststore6791947025858703204.jks
	ssl.truststore.password = [hidden]
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:1
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig:347)
[2020-01-15 10:21:42,317] INFO Awaiting socket connections on localhost:60136. (kafka.network.Acceptor:66)
[2020-01-15 10:21:42,335] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(localhost,0,ListenerName(SSL),SSL) (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:42,335] DEBUG [SocketServer brokerId=0] Wait for authorizer to complete start up on listener ListenerName(SSL) (kafka.network.SocketServerTest$TestableSocketServer:62)
[2020-01-15 10:21:42,335] DEBUG [SocketServer brokerId=0] Start processors on listener ListenerName(SSL) (kafka.network.SocketServerTest$TestableSocketServer:62)
[2020-01-15 10:21:42,335] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:42,336] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:42,337] DEBUG Accepted connection from /127.0.0.1:60138 on /127.0.0.1:60136 and assigned it to processor 0, sendBufferSize [actual|requested]: [300000|300000] recvBufferSize [actual|requested]: [310308|300000] (kafka.network.Acceptor:62)
[2020-01-15 10:21:42,337] DEBUG Processor 0 listening to new connection from /127.0.0.1:60138 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:42,359] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:42,461] TRACE Not sending PRODUCE response to client  as it's not required. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:42,461] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response: from connection 127.0.0.1:60136-127.0.0.1:60138-0;totalTime:102.413,requestQueueTime:0.0,localTime:6.1104197762E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.323,sendTime:0.0,securityProtocol:SSL,principal:User:ANONYMOUS,listener:SSL,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:42,462] TRACE Socket server received empty response to send, registering for read: Response(type=NoOp, request=Request(processor=0, connectionId=127.0.0.1:60136-127.0.0.1:60138-0, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(SSL), securityProtocol=SSL, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22])) (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:54)
[2020-01-15 10:21:42,462] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:42,462] TRACE Not sending PRODUCE response to client  as it's not required. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:42,462] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response: from connection 127.0.0.1:60136-127.0.0.1:60138-0;totalTime:0.383,requestQueueTime:0.0,localTime:6.1104198823E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.269,sendTime:0.0,securityProtocol:SSL,principal:User:ANONYMOUS,listener:SSL,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:42,462] TRACE Socket server received empty response to send, registering for read: Response(type=NoOp, request=Request(processor=0, connectionId=127.0.0.1:60136-127.0.0.1:60138-0, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(SSL), securityProtocol=SSL, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22])) (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:54)
[2020-01-15 10:21:42,462] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:42,462] TRACE Not sending PRODUCE response to client  as it's not required. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:42,463] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response: from connection 127.0.0.1:60136-127.0.0.1:60138-0;totalTime:0.225,requestQueueTime:0.0,localTime:6.1104199328E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.158,sendTime:0.0,securityProtocol:SSL,principal:User:ANONYMOUS,listener:SSL,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:42,463] TRACE Socket server received empty response to send, registering for read: Response(type=NoOp, request=Request(processor=0, connectionId=127.0.0.1:60136-127.0.0.1:60138-0, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(SSL), securityProtocol=SSL, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22])) (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:54)
[2020-01-15 10:21:42,463] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:42,463] TRACE Not sending PRODUCE response to client  as it's not required. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:42,463] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response: from connection 127.0.0.1:60136-127.0.0.1:60138-0;totalTime:0.331,requestQueueTime:0.0,localTime:6.1104199824E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.151,sendTime:0.0,securityProtocol:SSL,principal:User:ANONYMOUS,listener:SSL,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:42,463] TRACE Socket server received empty response to send, registering for read: Response(type=NoOp, request=Request(processor=0, connectionId=127.0.0.1:60136-127.0.0.1:60138-0, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(SSL), securityProtocol=SSL, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22])) (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:54)
[2020-01-15 10:21:42,564] DEBUG Accepted connection from /127.0.0.1:60152 on /127.0.0.1:60136 and assigned it to processor 0, sendBufferSize [actual|requested]: [300000|300000] recvBufferSize [actual|requested]: [310308|300000] (kafka.network.Acceptor:62)
[2020-01-15 10:21:42,564] DEBUG Processor 0 listening to new connection from /127.0.0.1:60152 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:42,574] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:42,574] TRACE Sending PRODUCE response to client  of 26 bytes. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:42,575] TRACE Socket server received response to send to 127.0.0.1:60136-127.0.0.1:60152-1, registering for write and sending data: Response(type=Send, request=Request(processor=0, connectionId=127.0.0.1:60136-127.0.0.1:60152-1, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(SSL), securityProtocol=SSL, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22]), send=org.apache.kafka.common.network.NetworkSend@61b1d14a, asString=Some(RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1))) (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:54)
[2020-01-15 10:21:42,575] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) from connection 127.0.0.1:60136-127.0.0.1:60152-1;totalTime:1.097,requestQueueTime:0.0,localTime:6.1104311093E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.404,sendTime:0.289,securityProtocol:SSL,principal:User:ANONYMOUS,listener:SSL,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:42,676] DEBUG Accepted connection from /127.0.0.1:60165 on /127.0.0.1:60136 and assigned it to processor 0, sendBufferSize [actual|requested]: [300000|300000] recvBufferSize [actual|requested]: [310308|300000] (kafka.network.Acceptor:62)
[2020-01-15 10:21:42,676] DEBUG Processor 0 listening to new connection from /127.0.0.1:60165 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:42,687] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:42,687] TRACE Sending PRODUCE response to client  of 26 bytes. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:42,687] TRACE Socket server received response to send to 127.0.0.1:60136-127.0.0.1:60165-2, registering for write and sending data: Response(type=Send, request=Request(processor=0, connectionId=127.0.0.1:60136-127.0.0.1:60165-2, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(SSL), securityProtocol=SSL, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22]), send=org.apache.kafka.common.network.NetworkSend@28da5de, asString=Some(RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1))) (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:54)
[2020-01-15 10:21:42,688] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) from connection 127.0.0.1:60136-127.0.0.1:60165-2;totalTime:4.329,requestQueueTime:0.0,localTime:6.1104423905E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.234,sendTime:0.372,securityProtocol:SSL,principal:User:ANONYMOUS,listener:SSL,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:42,791] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:42,791] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:42,791] DEBUG Closing server socket and selector. (kafka.network.Acceptor:62)
[2020-01-15 10:21:42,792] DEBUG Closing selector - processor 0 (kafka.network.SocketServerTest$TestableSocketServer$$anon$8:62)
[2020-01-15 10:21:42,792] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:42,795] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServerTest$TestableSocketServer:66)
[2020-01-15 10:21:42,795] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer:66)
[2020-01-15 10:21:42,795] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:42,796] DEBUG Closing server socket and selector. (kafka.network.Acceptor:62)
[2020-01-15 10:21:42,796] DEBUG Closing selector - processor 0 (kafka.network.Processor:62)
[2020-01-15 10:21:42,796] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:42,799] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer:66)
[2020-01-15 10:21:43,363] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1500
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = SSL://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/b3/bhnnh3l53jjdfgphtx91qd1h0000gn/T/kafka-5085556978532282573
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1500
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = SSL
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = [hidden]
	ssl.keymanager.algorithm = PKIX
	ssl.keystore.location = /var/folders/b3/bhnnh3l53jjdfgphtx91qd1h0000gn/T/serverKS6417720272790194184.jks
	ssl.keystore.password = [hidden]
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = /var/folders/b3/bhnnh3l53jjdfgphtx91qd1h0000gn/T/truststore1353610333736020212.jks
	ssl.truststore.password = [hidden]
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:1
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig:347)
[2020-01-15 10:21:43,368] INFO Awaiting socket connections on localhost:60188. (kafka.network.Acceptor:66)
[2020-01-15 10:21:43,434] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(localhost,0,ListenerName(SSL),SSL) (kafka.network.SocketServer:66)
[2020-01-15 10:21:43,435] DEBUG [SocketServer brokerId=0] Wait for authorizer to complete start up on listener ListenerName(SSL) (kafka.network.SocketServer:62)
[2020-01-15 10:21:43,435] DEBUG [SocketServer brokerId=0] Start processors on listener ListenerName(SSL) (kafka.network.SocketServer:62)
[2020-01-15 10:21:43,435] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServer:66)
[2020-01-15 10:21:43,435] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer:66)
[2020-01-15 10:21:43,436] DEBUG Accepted connection from /127.0.0.1:60192 on /127.0.0.1:60188 and assigned it to processor 0, sendBufferSize [actual|requested]: [102400|102400] recvBufferSize [actual|requested]: [375636|102400] (kafka.network.Acceptor:62)
[2020-01-15 10:21:43,436] DEBUG Processor 0 listening to new connection from /127.0.0.1:60192 (kafka.network.Processor:62)
[2020-01-15 10:21:43,445] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:43,445] TRACE Sending PRODUCE response to client  of 26 bytes. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:43,445] TRACE Socket server received response to send to 127.0.0.1:60188-127.0.0.1:60192-0, registering for write and sending data: Response(type=Send, request=Request(processor=0, connectionId=127.0.0.1:60188-127.0.0.1:60192-0, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(SSL), securityProtocol=SSL, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22]), send=org.apache.kafka.common.network.NetworkSend@34644203, asString=Some(RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1))) (kafka.network.Processor:54)
[2020-01-15 10:21:43,446] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer:66)
[2020-01-15 10:21:43,446] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:43,446] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) from connection 127.0.0.1:60188-127.0.0.1:60192-0;totalTime:0.726,requestQueueTime:0.0,localTime:6.1105181987E7,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.26,sendTime:0.257,securityProtocol:SSL,principal:User:ANONYMOUS,listener:SSL,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:43,446] DEBUG Closing server socket and selector. (kafka.network.Acceptor:62)
[2020-01-15 10:21:43,446] DEBUG Closing selector - processor 0 (kafka.network.Processor:62)
[2020-01-15 10:21:43,447] DEBUG Closing selector - processor 1 (kafka.network.Processor:62)
[2020-01-15 10:21:43,447] DEBUG Closing selector - processor 2 (kafka.network.Processor:62)
[2020-01-15 10:21:43,447] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:43,451] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer:66)
[2020-01-15 10:21:43,451] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer:66)
[2020-01-15 10:21:43,451] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:43,451] DEBUG Closing server socket and selector. (kafka.network.Acceptor:62)
[2020-01-15 10:21:43,451] DEBUG Closing selector - processor 0 (kafka.network.Processor:62)
[2020-01-15 10:21:43,452] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:43,454] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer:66)
[2020-01-15 10:21:43,461] DEBUG Accepted connection from /127.0.0.1:60194 on /127.0.0.1:60193 and assigned it to processor 0, sendBufferSize [actual|requested]: [300000|300000] recvBufferSize [actual|requested]: [310308|300000] (kafka.network.Acceptor:62)
[2020-01-15 10:21:43,461] DEBUG Processor 0 listening to new connection from /127.0.0.1:60194 (kafka.network.Processor:62)
[2020-01-15 10:21:43,461] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer:66)
[2020-01-15 10:21:43,461] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:43,462] DEBUG Closing server socket and selector. (kafka.network.Acceptor:62)
[2020-01-15 10:21:43,462] DEBUG Closing selector - processor 0 (kafka.network.Processor:62)
[2020-01-15 10:21:43,462] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:43,466] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer:66)
[2020-01-15 10:21:43,472] DEBUG Accepted connection from /127.0.0.1:60196 on /127.0.0.1:60195 and assigned it to processor 0, sendBufferSize [actual|requested]: [300000|300000] recvBufferSize [actual|requested]: [310308|300000] (kafka.network.Acceptor:62)
[2020-01-15 10:21:43,472] DEBUG Processor 0 listening to new connection from /127.0.0.1:60196 (kafka.network.Processor:62)
[2020-01-15 10:21:43,473] TRACE Processor 0 received request: RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]} (kafka.network.RequestChannel$:39)
[2020-01-15 10:21:43,473] TRACE Notifying channel throttling has started for client  for PRODUCE (kafka.network.RequestChannel:54)
[2020-01-15 10:21:43,473] TRACE Not sending PRODUCE response to client  as it's not required. (kafka.network.RequestChannel:54)
[2020-01-15 10:21:43,473] DEBUG Completed request:RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=, correlationId=-1) -- {acks=0,timeout=10000,partitionSizes=[]},response: from connection 127.0.0.1:60195-127.0.0.1:60196-0;totalTime:0.485,requestQueueTime:0.0,localTime:6.1105209681E7,remoteTime:0.15,throttleTime:0.0,responseQueueTime:0.191,sendTime:0.0,securityProtocol:PLAINTEXT,principal:User:ANONYMOUS,listener:PLAINTEXT,clientInformation:ClientInformation(softwareName=unknown, softwareVersion=unknown) (kafka.request.logger:205)
[2020-01-15 10:21:43,473] TRACE Socket server received empty response to send, registering for read: Response(type=NoOp, request=Request(processor=0, connectionId=127.0.0.1:60195-127.0.0.1:60196-0, session=Session(User:ANONYMOUS,/127.0.0.1), listenerName=ListenerName(PLAINTEXT), securityProtocol=PLAINTEXT, buffer=java.nio.HeapByteBuffer[pos=22 lim=22 cap=22])) (kafka.network.Processor:54)
[2020-01-15 10:21:43,576] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer:66)
[2020-01-15 10:21:43,577] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:43,577] DEBUG Closing server socket and selector. (kafka.network.Acceptor:62)
[2020-01-15 10:21:43,577] DEBUG Closing selector - processor 0 (kafka.network.Processor:62)
[2020-01-15 10:21:43,577] DEBUG Closing selector connection 127.0.0.1:60195-127.0.0.1:60196-0 (kafka.network.Processor:62)
[2020-01-15 10:21:43,578] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer:66)
[2020-01-15 10:21:43,581] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer:66)
]]></system-out>
  <system-err><![CDATA[]]></system-err>
</testsuite>
